{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Solution 1.2 Pima Indians exercise Α.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"collapsed":true,"id":"Yxvq-hnA8Iz-","colab_type":"text"},"source":["# Άσκηση: Συγκρίνετε dummy classifiers και Gaussian Naive Bayes στο Pima Indians Diabetes Data Set \n","![1889 Photograph shows half-length portrait of two Pima Indians, facing front, wearing bead necklaces.](https://i.pinimg.com/236x/60/05/76/600576905d4ad5bb1a9c3e3387b397ca--pima-indians-native-american-indians.jpg \"1889 Photograph shows half-length portrait of two Pima Indians, facing front, wearing bead necklaces.\")\n","\n","Το \"Pima Indians Diabetes data set (ή Pima)\" περιλαμβάνει 768 δείγματα από γυναίκες άνω των 21 με καταγωγή από τους ινδιάνους Pima (Pima people). Με βάση 8 βιολογικά χαρακτηριστικά προσπαθούμε να αποφασίσουμε αν ένα άτομο είναι διαβητικό ή όχι.\n","Κατεβάστε το αρχείο csv από [εδώ](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv). Κάντε δεξί κλικ και \"Save As\".\n","Η τελευταία (έννατη) τιμή είναι η κατηγορία, 0 μη διαβητική, 1 διαβητική.\n","\n","1. Ανεβάστε το pima-indians-diabetes.data\" στο notebook σας και διαβάστε το σε ένα numpy array. Χρησιμοποιήστε τον κώδικα από το Classification 1.1 για το cloud που χρησιμοποιείτε.\n","2. Ποιά είναι η κατανομή (συχνότητα) των δύο κλάσεων; Τί ποσοστό επί τοις εκατό του dataset είναι η κάθε κλάση; Με δεδομένο ότι το ποσοστό των κλάσεων στο Wisconcin ήταν 37.3% - 62.7% πιο dataset είναι πιο ισορροπημένο (κοντά στην ίση κατανομή των δύο κλάσεων); Σημείωση, για να δουλέψει η bincount πρέπει να κάνουμε τα labels int με .astype(int)\n","3. Χωρίστε τα δείγματα κατά 60% training set και 40% test set.\n","4. Ορίστε ένα λεξικό \"pima_accuracy\". Εκπαιδεύστε πέντε dummy classifiers με τις εξής στρατηγικές: “uniform”, “constant 0”, “constant 1”, “most_frequent”, “stratified”. Εκπαιδεύστε τους στο training set και αποθηκεύστε για τον καθένα στο \"pima_accuracy\" το όνομά του στο κλειδί και την πιστότητά του στο test set του 40%.\n","5. Εκτυπώστε το \"pima_accuracy\" με αύξουσα σειρά πιστότητας.\n","6. Εκπαιδεύστε έναν Gaussian Naive Bayes στο ίδιο split του dataset και προσθέστε το όνομα και την πιστότητά του στο \"pima_accuracy\". Εκτυπώστε το \"pima_accuracy\" ξανά με αύξουσα σειρά πιστότητας.\n","7. Πώς σχολιάζετε τις επιδόσεις των ταξινομητών; Δοκιμάστε μερικά runs του Pima και του Wisconsin και παρατηρήστε τη συγκριτική απόδοση του uniform και του stratified. Που μπορεί να οφείλεται;\n","8. Τί παρατηρείτε για την επίδοση του Gaussian Naive Bayes στο Pima σε σχέση με την επίδοση του στο Wisconsin Breast Cancer; Τί μπορεί να σημαίνει αυτό για τον Gaussian NB και για κάθε dataset;"]},{"cell_type":"markdown","metadata":{"id":"IePh9t79ES-x","colab_type":"text"},"source":["# 1"]},{"cell_type":"code","metadata":{"id":"rRieb2R6_tv_","colab_type":"code","outputId":"b452aa81-0221-42e9-9e52-955a7a7a3390","executionInfo":{"status":"ok","timestamp":1571558767391,"user_tz":-180,"elapsed":2754,"user":{"displayName":"Giorgos Siolas","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB6ToY_PpcM4Wge8olGDnZvgO-dOS0W1Of6aRU95dE=s64","userId":"10127542075805046236"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["!ls"],"execution_count":1,"outputs":[{"output_type":"stream","text":["pima-indians-diabetes.data  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z4sjicWC_6Ou","colab_type":"code","outputId":"41d85e9b-d3bb-4319-f502-541dcb6e76a0","executionInfo":{"status":"ok","timestamp":1571558771889,"user_tz":-180,"elapsed":906,"user":{"displayName":"Giorgos Siolas","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB6ToY_PpcM4Wge8olGDnZvgO-dOS0W1Of6aRU95dE=s64","userId":"10127542075805046236"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["import pandas as pd\n","\n","df = pd.read_csv(\"pima-indians-diabetes.data\", header=None)\n","df.head()"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6</td>\n","      <td>148</td>\n","      <td>72</td>\n","      <td>35</td>\n","      <td>0</td>\n","      <td>33.6</td>\n","      <td>0.627</td>\n","      <td>50</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>85</td>\n","      <td>66</td>\n","      <td>29</td>\n","      <td>0</td>\n","      <td>26.6</td>\n","      <td>0.351</td>\n","      <td>31</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8</td>\n","      <td>183</td>\n","      <td>64</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>23.3</td>\n","      <td>0.672</td>\n","      <td>32</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>89</td>\n","      <td>66</td>\n","      <td>23</td>\n","      <td>94</td>\n","      <td>28.1</td>\n","      <td>0.167</td>\n","      <td>21</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>137</td>\n","      <td>40</td>\n","      <td>35</td>\n","      <td>168</td>\n","      <td>43.1</td>\n","      <td>2.288</td>\n","      <td>33</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   0    1   2   3    4     5      6   7  8\n","0  6  148  72  35    0  33.6  0.627  50  1\n","1  1   85  66  29    0  26.6  0.351  31  0\n","2  8  183  64   0    0  23.3  0.672  32  1\n","3  1   89  66  23   94  28.1  0.167  21  0\n","4  0  137  40  35  168  43.1  2.288  33  1"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"Prz6dWkmEf9Z","colab_type":"text"},"source":["# 2"]},{"cell_type":"code","metadata":{"id":"J8jTwZbZAOMG","colab_type":"code","outputId":"58be2751-46be-43fc-8960-76995b21b429","executionInfo":{"status":"ok","timestamp":1571558780748,"user_tz":-180,"elapsed":936,"user":{"displayName":"Giorgos Siolas","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB6ToY_PpcM4Wge8olGDnZvgO-dOS0W1Of6aRU95dE=s64","userId":"10127542075805046236"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["import numpy as np\n","\n","np_data = df.values # δεν έχουμε διαφορετικούς τύπους δεδομένων στο dataframe οπότε μπορούμε να το μετατρέψουμε απευθείας σε numpy array\n","features = np_data[:,0:-1]\n","print(features.shape)\n","labels = np_data[:,-1].astype(int) # για να δουλέψει η bincount πρέπει να κάνουμε cast τα labels από float σε int\n","# TypeError: Cannot cast array data from dtype('float64') to dtype('int64') according to the rule 'safe'\n","print(labels.shape)\n","frequencies = np.bincount(labels)\n","print(\"class frequencies: \", frequencies)\n","total_samples = frequencies.sum()\n","print(\"total samples: \", total_samples)\n","percentage = (frequencies / total_samples) * 100\n","print(\"class percentage: \", percentage)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["(768, 8)\n","(768,)\n","class frequencies:  [500 268]\n","total samples:  768\n","class percentage:  [65.10416667 34.89583333]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5TIoG9euD-3K","colab_type":"text"},"source":["To pima είναι ελαφρώς λιγότερο ισορροπημένο."]},{"cell_type":"markdown","metadata":{"id":"3FMEl_6sE4UZ","colab_type":"text"},"source":["# 3-5"]},{"cell_type":"code","metadata":{"id":"VT9DvWhKE8Vo","colab_type":"code","outputId":"0ce29768-7420-48da-e823-366b66a00ea2","executionInfo":{"status":"ok","timestamp":1571558794256,"user_tz":-180,"elapsed":1805,"user":{"displayName":"Giorgos Siolas","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB6ToY_PpcM4Wge8olGDnZvgO-dOS0W1Of6aRU95dE=s64","userId":"10127542075805046236"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["from sklearn.model_selection import train_test_split\n","train, test, train_labels, test_labels = train_test_split(features, labels, test_size=0.4)\n","\n","from sklearn.dummy import DummyClassifier\n","\n","dc_uniform = DummyClassifier(strategy=\"uniform\")\n","dc_constant_0 = DummyClassifier(strategy=\"constant\", constant=0)\n","dc_constant_1 = DummyClassifier(strategy=\"constant\", constant=1)\n","dc_most_frequent = DummyClassifier(strategy=\"most_frequent\")\n","dc_stratified = DummyClassifier(strategy=\"stratified\")\n","\n","pima_accuracy = {}\n","model = dc_uniform.fit(train, train_labels)\n","pima_accuracy['uniform (random)'] = dc_uniform.score(test, test_labels)\n","model = dc_constant_0.fit(train, train_labels)\n","pima_accuracy['constant 0'] = dc_constant_0.score(test, test_labels)\n","model = dc_constant_1.fit(train, train_labels)\n","pima_accuracy['constant 1'] = dc_constant_1.score(test, test_labels)\n","model = dc_most_frequent.fit(train, train_labels)\n","pima_accuracy['most frequent label'] = dc_most_frequent.score(test, test_labels)\n","model = dc_stratified.fit(train, train_labels)\n","pima_accuracy['stratified'] = dc_stratified.score(test, test_labels)\n","                                                  \n","                                                  \n","print(\"Classification Accuracy on the Pima Indians Dataset (40% test set)\\n\")\n","sorted_accuracy = [(k, pima_accuracy[k]) for k in sorted(pima_accuracy, key=pima_accuracy.get, reverse=False)]\n","for k, v in sorted_accuracy:\n","  print(k,v)                                "],"execution_count":4,"outputs":[{"output_type":"stream","text":["Classification Accuracy on the Pima Indians Dataset (40% test set)\n","\n","constant 1 0.36688311688311687\n","uniform (random) 0.512987012987013\n","stratified 0.5227272727272727\n","constant 0 0.6331168831168831\n","most frequent label 0.6331168831168831\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wubxLud18I0p","colab_type":"text"},"source":["# 6"]},{"cell_type":"code","metadata":{"id":"BcVpDERDGch6","colab_type":"code","outputId":"f6ec845e-ba48-4179-966f-89f76ebf9f71","executionInfo":{"status":"ok","timestamp":1571558799526,"user_tz":-180,"elapsed":594,"user":{"displayName":"Giorgos Siolas","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB6ToY_PpcM4Wge8olGDnZvgO-dOS0W1Of6aRU95dE=s64","userId":"10127542075805046236"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from sklearn.naive_bayes import GaussianNB\n","gnb = GaussianNB()\n","model = gnb.fit(train, train_labels)\n","pima_accuracy['gaussian naive bayes'] = gnb.score(train, train_labels)\n","sorted_accuracy = [(k, pima_accuracy[k]) for k in sorted(pima_accuracy, key=pima_accuracy.get, reverse=False)]\n","for k, v in sorted_accuracy:\n","  print(k,v)                                "],"execution_count":5,"outputs":[{"output_type":"stream","text":["constant 1 0.36688311688311687\n","uniform (random) 0.512987012987013\n","stratified 0.5227272727272727\n","constant 0 0.6331168831168831\n","most frequent label 0.6331168831168831\n","gaussian naive bayes 0.7652173913043478\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5JJxNniHGrsx","colab_type":"text"},"source":["# 7\n","* Μεταξύ των dummy ταξινομητών, η καλύτερη στρατηγική είναι να διαλέγουμε πάντοτε την πιο συχνή κλάση (ή ισοδύναμα σταθερά την κλάση που είναι η πιο συχνή). \n","* Εαν δοκιμάσουμε πολλά runs, θα παρατηρήσουμε ότι επιλογή stratified, δηλαδή να επιλέγουμε τυχαία κλάση διατηρώντας την κατανομή των κλάσεων στο training set, είναι τόσο πιο συχνά καλύτερη από την τυχαία (uniform) επιλογή, όσο περισσότερο μη ισορροπημένες είναι οι συχνότητες των κλάσεων στο dataset. To Pima είναι λιγότερο ισορροπημένο από το Wisconsin και συνεπώς η στρατηγική stratified θα αποδίδει καλύτερα από τη random πιο συχνά. "]},{"cell_type":"markdown","metadata":{"id":"Ok-TcEaUGxEx","colab_type":"text"},"source":["# 8\n","Ο Gaussian ΝΒ είναι σημαντικά καλύτερος από τους dummy και στο Pima αλλά σημαντικά αναποτελεσματικότερος σε ορθότητα (15%-20% λιγότερο) απότι στο Wisconsin. Αυτό μπορεί να σημαίνει κάτι, κάποια ή όλα από τα παρακάτω: \n","* η βασική υπόθεση του NB ότι τα χαρακτηριστικά είναι ανεξάρτητα μεταξύ τους ισχύει λιγότερο στο Pima απότι στο Wisconsin \n","* ότι στο Pima η κατανομές των χαρακτηριστικών ακολουθούν λιγότερο την υπόθεση της gaussian κατανομής \n","* συνολικά το Pima είναι ένα δυσκολότερο dataset από το Wisconsin."]}]}