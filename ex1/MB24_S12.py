# -*- coding: utf-8 -*-
"""ΜΒ24-S12.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IeELHo-oHoyk4vVw3Df-X3e4UptVU_zC

# Neural Networks & Intelligent Computer Systems | 1st Assignment
Team ΜΒ-24 | Small Dataset S12

## Section A: Our Team

<table align="left">
    <tr align="left"><th>Surname</th><th>Name</th><th>Student ID</th></tr>
    <tr><td>Korkovili</td><td>Ioanna</td><td>03115078</td></tr>
    <tr><td>Xanthi</td><td>Eleni</td><td>03115054</td></tr>
    <tr><td>Tsagkarakis</td><td>Stylianos</td><td>03115180</td></tr>
</table>

## Section B: Introduction to the dataset

**LSVT Voice Rehabilitation Data Set**

This dataset is composed of a range of biomedical speech signal processing algorithms from 14 people who have been diagnosed with Parkinson's disease undergoing LSVT (a program assisting voice rehabilitation). 

The original study used 309 algorithms to characterize 126 speech signals from 14 people, a robust feature selection mechanism to determine the most parsimonious feature subset, and Support Vector Machines (SVM) and Random Forests (RF) to predict the binary response (acceptable vs unacceptable phonation during rehabilitation). Both cross-validation (10-fold cross validation with 100 repetitions for statistical confidence) and leave one subject out methods were used for the validation of the findings. In both cases we denostrated a near 90% accurate replication of the clinicians' assessment.

### Upgrade hosted runtime
"""

!pip install --upgrade pip           #upgrade pip package installer
!pip install --upgrade scikit-learn  #upgrade scikit-learn package
!pip install --upgrade numpy         #upgrade numpy package
!pip install --upgrade pandas        #upgrade #upgrade pandas package
!pip install --upgrade joblib
!pip install --upgrade imbalanced-learn

"""### Retrieve dataset"""

import pandas as pd
import numpy as np
import ast
import io
import requests
import matplotlib.pyplot as plt
from urllib.error import HTTPError

# responsefile = "lsvt_binary_response.csv"
# datafile = "lsvt_data.csv"
# demographicsfile = "lsvt_demographics.csv"

try:
    #data without headers for better manipulation
    binary_csv_url = "https://raw.githubusercontent.com/steliostss/neural_networks_ntua/master/ex1/lsvt_binary_response.csv?token=AH57CIKFAWBUCP4KSDDKT4C576IO6"
    binary_response = pd.read_csv(binary_csv_url, header=None)

    # data_csv_url = "https://raw.githubusercontent.com/steliostss/neural_networks_ntua/master/ex1/lsvt_data_2.csv?token=AH57CINQWC5N4TIH7QQGZXC5753RE"
    data_csv_url = "https://raw.githubusercontent.com/steliostss/neural_networks_ntua/master/ex1/lsvt_data.csv?token=AH57CIN4KNS65U7AGYDJX5K576HEE"
    data = pd.read_csv(data_csv_url, header=None)

    demographics_csv_url = "https://raw.githubusercontent.com/steliostss/neural_networks_ntua/master/ex1/lsvt_demographics.csv?token=AH57CIJAK62CQJZTPBS22JK57475Q"
    demographics = pd.read_csv(demographics_csv_url, header=None)

    #data with headers for better visualizing
    demographics_headers = pd.read_csv(demographics_csv_url)
    data_headers = pd.read_csv(data_csv_url)
    binary_response_headers = pd.read_csv(binary_csv_url)

    print("Succesful file processing!")

except HTTPError:
    print("URL not working.")

"""### Printing for validation / visualization"""

#print for better visualization
data_headers.head(3)

#print for better visualization
demographics_headers.head(3)

#print for better visualization
binary_response_headers.head(3)

"""### Custom functions"""

## GATHER ALL FUNCTIONS FOR SECTION-B HERE

# evaluate type of value in the given variable
def tryeval(np_samples):
    for row in range(len(np_samples)): 
        for col in range(len(np_samples[row])):
            try: 
                np_samples[row][col] = ast.literal_eval(np_samples[row][col])
            except ValueError:
                pass
    return np_samples

def tryeval1D(np_samples):
    for row in range(len(np_samples)): 
        try: 
            np_samples[row] = ast.literal_eval(np_samples[row])
        except ValueError:
            pass
    return np_samples

# define if all features have the same type
def features_datatypes(features):
    datatypes = list()
    for row in range(len(features)):
        for col in range(len(features[row])):
            current_type = type(features[row][col])
            if current_type not in datatypes:
                datatypes.append(current_type)

    return datatypes
# define all class labels
def class_labels(labels):
    cLabels = list()
    for col in range(len(labels)):
        current_val = labels[col]
        if current_val not in cLabels:
            cLabels.append(current_val)
    return cLabels

"""### Manage datafile, get desired data

Get #features, #samples, type of features
"""

# gather data features in a table
data_features = data.iloc[[0],0:]
( _ , number_of_features ) = data_features.shape
print("Q2: Number of features = ", number_of_features)
# print(data_features.shape) # uncomment if you want to check the results

# gather data samples in a table
data_samples = data.iloc[1:,0:]
( number_of_samples , _ ) = data_samples.shape
print("Q2: Number of samples = ", number_of_samples)
# print(data_samples.shape) # uncomment if you want to check the results

# transform the gathered data in numpy arrays
np_features = data_features.values
np_samples = data_samples.values

# # convert the type of samples to the correct type
np_samples = tryeval(np_samples)
datatypes = features_datatypes(np_samples)

print("Q2: Type of features =", end=' ')
print(*datatypes, sep=' & ')

"""- Q3: There are headers in the first line

- Q3: There is no line numbering
"""

# gather class labels in a table
binary_class_labels = binary_response.iloc[0:,:] 
np_labels_temp = binary_class_labels.values.flatten()

np_labels = list()
for item in np_labels_temp:
    np_labels.append(item)

np_labels = np.array(np_labels)

np_labels = tryeval1D(np_labels)

np_labels

"""### Classification Labels"""

# make a list with all different labels
list_of_labels = class_labels(np_labels)
print("Q4: Classification Labels =", end=' ')
print(*list_of_labels, sep = " & ")

label_names = list()
for i in range(len(list_of_labels)):
    label_names.append(str(list_of_labels[i]))
# label_names = ('1','2')
label_names

"""### Modifications on the datafile
- Q5: There were some modifications on the data. 
    - We replaced **" , "** with **" . "**
    - We removed the headers on the binary response file.

### Check Empty dataset
"""

# check if dataset has empty values
# and if, how many of them
!ls
!echo "For binary_response file, empty values: "
!cat lsvt_binary_response.csv | grep "?" | wc -l
!echo "For data file, empty values: "
!cat lsvt_data.csv | grep "?" | wc -l
!echo "For demographics file, empty values: "
!cat lsvt_demographics.csv | grep "?" | wc -l

"""### Label frequencies"""

print("frequencies:", np.bincount(np_labels))
freq = np.bincount(np_labels)
for i in range(len(freq)):
    if i == 0: continue
    print("For label:", i, "percentage is", "{:.2%}".format(freq[i]/number_of_samples))

"""Το παραπάνω dataset όπως φαίνεται από τις συχνότητες δεν είναι ισορροπημένο.
Καθώς το δείγμα είναι μικρό επιλέγουμε να κανουμε oversampling για να μη χάσουμε κρίσιμη πληροφορία.

### Split to test and train set

After spliting, we oversample the train set to be balanced
"""

from sklearn.linear_model import LogisticRegression 
from sklearn.preprocessing import StandardScaler 
from sklearn.metrics import confusion_matrix, classification_report 
from imblearn.over_sampling import RandomOverSampler
from imblearn.over_sampling import SMOTE

from sklearn.model_selection import train_test_split

# Split our data
train, test, train_labels, test_labels = train_test_split(np_samples, 
                                                          np_labels, 
                                                          test_size=0.2)

sampler = SMOTE()
train, train_labels = sampler.fit_sample(np_samples, np_labels)

train_set_length = len(train)
# print length of train set to validate oversampling
print("#samples in train set =", train_set_length, '\n')

"""**Q8**: Our samples are **ordered tuples** since each number corresponds to a specific attribute.

## Section C: Baseline Classification

### Custom functions
"""

from sklearn.dummy import DummyClassifier
from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics import classification_report
from matplotlib import pyplot as plt

def print_precision_recall_fscore_support(method, test_labels, pred, label_names):
    print(method, end = '\n\n')
    (none, micro, macro, weighted) = get_PRFS(method, test_labels, pred, label_names)
    # εκτυπώνουμε 4 πίνακες, precision, recall, F1 και support. Support είναι ο συνολικός αριθμός προβλέψεων σε κάθε κλάση
    # το πρώτο στοιχείο του κάθε πίνακα είναι η κλάση 1 και το δεύτερο η κλάσση 2
    print("none     :", none )
    # εκτυπώνουμε τa precision, recall και F1 λαμβάνοντας υπόψη συνολικά (αθροίζοντας εκτός κλάσεων) τα δείγματα (average = micro).
    print("micro    :", micro )
    # εκτυπώνουμε το μέσο όρο των precision, recall και F1 θεωρόντας ότι οι κλάσεις έχουν το ίδιο βάρος (average = macro)
    print("macro    :", macro )
    # εκτυπώνουμε τa precision, recall και F1 λαμβάνοντας. Με average = weighted κάθε κλάση μετρά στο μέσο όρο ανάλογα με το support της.
    print("weighted :", weighted, end = '\n\n')
    # η classification_report τυπώνει πιο ωραία οπτικά σε string τα αποτελέσματα
    # πρώτα για κάθε κλάση και μετά με μέσους όρους
    print(classification_report(test_labels, pred, target_names=label_names), end = '\n\n')

    ( _ , _ , microF1    , _ ) = micro
    ( _ , _ , macroF1    , _ ) = macro
    ( _ , _ , weightedF1 , _ ) = weighted

    barplotF1 = (microF1, macroF1, weightedF1)
    xaxis = ("microF1", "macroF1", "weightedF1")
    plt.figure(figsize=(10,5))
    plt.bar(xaxis, barplotF1)
    plt.show()
    print("---------------------------------------------------------------------------------------------------------------------", end = '\n')
    print("---------------------------------------------------------------------------------------------------------------------", end = '\n\n')

# get_precision_recall_fscore_support
def get_PRFS(method, test_labels, pred, label_names):
    none = precision_recall_fscore_support(test_labels, pred, average=None)
    micro = precision_recall_fscore_support(test_labels, pred, average='micro')
    macro = precision_recall_fscore_support(test_labels, pred, average='macro')
    weighted = precision_recall_fscore_support(test_labels, pred, average='weighted')
    return (none, micro, macro, weighted)

"""### Dummy Classifier"""

dc_uniform = DummyClassifier(strategy="uniform")
dc_constant_1 = DummyClassifier(strategy="constant", constant=1)
dc_constant_2 = DummyClassifier(strategy="constant", constant=2)
dc_most_frequent = DummyClassifier(strategy="most_frequent")
dc_stratified = DummyClassifier(strategy="stratified")

# με τη μέθοδο fit "εκπαιδεύουμε" τον ταξινομητή στο σύνολο εκπαίδευσης (τα χαρακτηριστικά και τις ετικέτες τους)
from sklearn.metrics import accuracy_score

# με τη μέθοδο predict παράγουμε προβλέψεις για τα δεδομένα ελέγχου (είσοδος τα χαρακτηριστικά μόνο)
predictions = {}
lsvt_accuracy = {}

model = dc_uniform.fit(train, train_labels)
preds = dc_uniform.predict(test)
predictions['dc_uniform'] = preds
lsvt_accuracy['uniform (random)'] = accuracy_score(test_labels, preds)


model = dc_constant_1.fit(train, train_labels)
preds = dc_constant_1.predict(test)
predictions['dc_constant_1'] = preds
lsvt_accuracy['constant 1'] = accuracy_score(test_labels, preds)

model = dc_constant_2.fit(train, train_labels)
preds = dc_constant_2.predict(test)
predictions['dc_constant_2'] = preds
lsvt_accuracy['constant 2'] = accuracy_score(test_labels, preds)

model = dc_most_frequent.fit(train, train_labels)
preds = dc_most_frequent.predict(test)
predictions['dc_most_frequent'] = preds
lsvt_accuracy['most frequent label'] = accuracy_score(test_labels, preds)

model = dc_stratified.fit(train, train_labels)
preds = dc_stratified.predict(test)
predictions['dc_stratified'] = preds
lsvt_accuracy['stratified'] = accuracy_score(test_labels, preds)

for i in predictions:
    print("Prediction for", i, '=', predictions[i])

print()
    
print("Classification Accuracy on the LSVT Voice Rehabilitation Dataset (20% test set)\n")
sorted_accuracy = [(k, lsvt_accuracy[k]) for k in sorted(lsvt_accuracy, key=lsvt_accuracy.get, reverse=True)]

print("----------Results are sorted----------")
print("** Strategy (score, accuracy_score) **\n")
for k,v in sorted_accuracy:
    print(k,v)

from sklearn.metrics import confusion_matrix
# Compute confusion matrix

print("Confusion matrices\n")
for i in predictions:
    # τυπώνουμε το confusion matrix
    cnf_matrix = confusion_matrix(test_labels, predictions[i])
    print(i)
    print(cnf_matrix, end='\n\n')

for i in predictions:
    print_precision_recall_fscore_support(i, test_labels, predictions[i], label_names)

"""##### Comments on the diagrams
- Among the Dummy Classifiers, it is visible that the best strategy is 'constant 2' since class 2 is the most frequent one. Moreover, if we run the classification multiple times, we notice that 'stratified' strategy results in better accuracy more often than the 'uniform' strategy. This is because our dataset is not balanced and 'stratified' is more effiecient than the random strategy.

### k Nearest Neighbors Classifier (kNN)
"""

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=2)

knn.fit(train, train_labels)

pred = knn.predict(test)

cnf_matrix = confusion_matrix(test_labels, pred)

print("kNN Confusion matrix:\n\n", cnf_matrix, '\n')

print_precision_recall_fscore_support("KNeighborsClassifier", test_labels, pred, label_names)

"""#### Comments on the diagrams
- We see that kNN did manage to guess the whole class '1' and around half of the class '2', that's why it reaches a weighted average of 75%, better than the Dummy's results.

## Section D: Optimizing Classifiers

### Split to Training/Test Set
"""

from sklearn.model_selection import train_test_split

# Split our data
train, test, train_labels, test_labels = train_test_split(np_samples, 
                                                          np_labels, 
                                                          test_size=0.2)

"""### Balance Dataset - Oversampling"""

sampler = SMOTE()
train, train_labels = sampler.fit_sample(np_samples, np_labels)

train_set_length = len(train)
# print length of train set to validate oversampling
print("#samples in train set =", train_set_length, '\n')

"""### Pre-Processing

#### Selection - Variance Threshold
"""

from sklearn.feature_selection import VarianceThreshold

selector = VarianceThreshold(threshold=0.5)
# όπως κάναμε και με τους ταξινομητές τον κάνουμε fit στα δεδομένα εκπαίδευσης
train_reduced = selector.fit_transform(train)
mask = selector.get_support()
test_reduced = test[:,mask]

selector = None
selector = VarianceThreshold(threshold=15000)
# όπως κάναμε και με τους ταξινομητές τον κάνουμε fit στα δεδομένα εκπαίδευσης
train_reduced_20k = selector.fit_transform(train)
mask = selector.get_support()
test_reduced_20k = test[:,mask]

print("0.5", train_reduced.shape)
print("0.5", test_reduced.shape)
print("20000", train_reduced_20k.shape)
print("20000", test_reduced_20k.shape)
print(train_labels.shape)

"""#### Standardization"""

from sklearn import preprocessing

# όριζουμε ένα αντικείμενο scaler και το κάνουμε fit στο train set
scaler = preprocessing.StandardScaler().fit(train)
# standardization των features του training set
train_scaled = scaler.transform(train)
# εφαρμόζουμε τον scaler στα δεδομένα test
test_scaled = scaler.transform(test)

"""### Hyperparameter Optimization
Custom GridsearchCV
"""

def make_tuples(arr):
    results = list()
    for i in range(0, len(arr), 2):
        results.append((arr[i], arr[i+1]))
    return results

def _gridsearch(test_set, test_set_labels, train_set, train_set_labels, KMAX, label_names):
    # test every value for k
    # append the result to a list
    # sort the list
    # return the list and keep the best
    gridsearch_results = list()

    for i in range(1, KMAX):
        method = "KNeighborsClassifier"
        knn = KNeighborsClassifier(n_neighbors=i)
        knn.fit(train_set, train_set_labels)
        pred = knn.predict(test_set)
        accuracy = accuracy_score(test_set_labels, pred)

        gridsearch_results.extend( (accuracy, i) )

    return gridsearch_results

def get_next_fold(_splitted_train, _train_labels, iter):
    counter = 0
    total_size = 0
    first_time = True
    for ( _data , _labels ) in zip(_splitted_train, _train_labels):
        if ( counter == iter ): # if current fold is test fold
            __test = _data
            __test_labels = _labels
        elif ( first_time ): # initialize train and train_labels
            __train = _data
            __train_labels = _labels
            first_time = False
        else: # everything else is the train fold
            __train = np.concatenate((__train, _data), axis=0)
            __train_labels = np.concatenate((__train_labels, _labels), axis=0)
        counter += 1
    return( __test, __test_labels, __train, __train_labels )


def _Kfold_cv(_train, _train_labels, _label_names, _folds=10):
    # split the train set and labels in 10 parts 
    split_train = np.array_split(_train, _folds)
    split_labels = np.array_split(_train_labels, _folds)

    # for i in range(_folds):
    #     print (len(split_train[i]), ",", len(split_labels[i]))
    knn_results = list()
    # print(KMAX)

    for iter in range(_folds):
        KMAX = len(split_train[iter]) # because there is no reason to search for more neighbors if they do no exist

        # do every possible fold out of 10
        (test_set, test_set_labels, train_set, train_set_labels) = get_next_fold(split_train, split_labels, iter)
    
        # and test every k for kNN and save results
        fold_results = _gridsearch(test_set, test_set_labels, train_set, train_set_labels, KMAX, _label_names)
        knn_results.extend((fold_results))

    return knn_results

"""### Final Classification - Regression Model"""

# print(test_labels)
# print(len(train), len(train_labels), len(label_names))

# classic dataset
results = _Kfold_cv(train, train_labels, label_names)
results = make_tuples(results)
results = sorted(results, key=lambda x:x[0], reverse=True)

#reduced with variance threshold = 0.5 
results_reduced = _Kfold_cv(train_reduced, train_labels, label_names)
results_reduced = make_tuples(results_reduced)
results_reduced = sorted(results_reduced, key=lambda x:x[0], reverse=True)

#reduced with variance threshold = 20000 
results_reduced_20k = _Kfold_cv(train_reduced_20k, train_labels, label_names)
results_reduced_20k = make_tuples(results_reduced_20k)
results_reduced_20k = sorted(results_reduced_20k, key=lambda x:x[0], reverse=True)

best_k = results[0][1]
best_k_reduced = results_reduced[0][1]
best_k_reduced_20k = results_reduced_20k[0][1]
print("Initial trainset, bestK = ", best_k)
print("Variance = 0.5 trainset, bestK = ", best_k_reduced)
print("Variance = 20000  trainset, bestK = ", best_k_reduced_20k)

#reduced with variance threshold = 20000 
results_scaled = _Kfold_cv(train_scaled, train_labels, label_names)
results_scaled = make_tuples(results_scaled)
results_scaled = sorted(results_scaled, key=lambda x:x[0], reverse=True)

best_k_scaled = results_scaled[0][1]
print("Scaling trainset, bestK = ", best_k_scaled)

def knn_fit_predict_print(_classifier, _train, _train_labels, _test, _test_labels, _label_names):
    _classifier.fit(_train, _train_labels)
    pred = _classifier.predict(_test)
    accuracy = accuracy_score(_test_labels, pred)
    print(accuracy) 
    # print_precision_recall_fscore_support("kNearestNeighbors", _test_labels, pred, _label_names)

"""### Print results"""

knn = None
print("Initial Variance")
knn = KNeighborsClassifier(n_neighbors = best_k)
print("accuracy = ", end=" ")
knn_fit_predict_print(knn, train, train_labels, test, test_labels, label_names)

print("\nVariance Threshold = 0.5")
knn = None
knn = KNeighborsClassifier(n_neighbors = best_k_reduced)
print("accuracy = ", end=" ")
knn_fit_predict_print(knn, train_reduced, train_labels, test_reduced, test_labels, label_names)

print("\nVariance Threshold = 20000")
knn = None
knn = KNeighborsClassifier(n_neighbors = best_k_reduced_20k)
print("accuracy = ", end=" ")
knn_fit_predict_print(knn, train_reduced_20k, train_labels, test_reduced_20k, test_labels, label_names)

print("\nScaled Trainset")
knn = None
knn = KNeighborsClassifier(n_neighbors = best_k_scaled)
print("accuracy = ", end=" ")
knn_fit_predict_print(knn, train_scaled, train_labels, test_scaled, test_labels, label_names)

"""#### Comments on Pre-Processing results

- Variance Threshold
    - We see that there is no effect on the results of the kNN algorithm if we use pre-processing selection with VarianceThreshold Selector.
    - You can see in the above cell that we tried with different values in the range (0.1 , 20000) and the results didn't change. 
    - Our data even though it had a small ratio of $\frac{samples}{features}$, Variance Threshold didn't achieve anything. We conclude from this, that there were specific features that helped the estimator reach a conclusion fast, without needing the other features. 
- Standardization
    - It seems that scaling the data is crucial for the classification since we have 100% accuracy on the test set.

### Conclusion

Since **we achieved 100% accuracy** on the test set, there is no need to perform any more transformations on the train and test set.
"""