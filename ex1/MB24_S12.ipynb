{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ΜΒ24-S12.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "oqcJEQwRnDdO",
        "cMIDOr19nKo6",
        "Sl0vfsrYc-4m",
        "45120CfmgzJb",
        "oQaikIfGcvw1",
        "cr8f1_Axc4fI",
        "xebU-h0ldN58",
        "X_sKL3VPdjK2",
        "YRdxqG4kd3DC",
        "-Ym4ULdPd6o-",
        "PhcQ_caxeGDx",
        "uFh5NnUGQ9SO",
        "WbTMUToWm1d3",
        "2UHYkaYtMuDC",
        "dMrUL--3G_F0",
        "GFDUwXAoOmpD",
        "kyJbkdYzeImt",
        "KW93Qn_MdKfa",
        "PYNgFvG6cxCJ",
        "kYuRVpvYWjHB",
        "TnH4aeVDWqj4",
        "d1GK08jOdZH_",
        "dm_DxswmdfZc",
        "dHITnSyXS2Yo"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEMtmB2UOx3_",
        "colab_type": "text"
      },
      "source": [
        "# Neural Networks & Intelligent Computer Systems | 1st Assignment\n",
        "Team ΜΒ-24 | Small Dataset S12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqcJEQwRnDdO",
        "colab_type": "text"
      },
      "source": [
        "## Section A: Our Team"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwUJsjVJPqLp",
        "colab_type": "text"
      },
      "source": [
        "<table align=\"left\">\n",
        "    <tr align=\"left\"><th>Surname</th><th>Name</th><th>Student ID</th></tr>\n",
        "    <tr><td>Korkovili</td><td>Ioanna</td><td>03115078</td></tr>\n",
        "    <tr><td>Xanthi</td><td>Eleni</td><td>03115054</td></tr>\n",
        "    <tr><td>Tsagkarakis</td><td>Stylianos</td><td>03115180</td></tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMIDOr19nKo6",
        "colab_type": "text"
      },
      "source": [
        "## Section B: Introduction to the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oxX8zE04NHEV"
      },
      "source": [
        "**LSVT Voice Rehabilitation Data Set**\n",
        "\n",
        "This dataset is composed of a range of biomedical speech signal processing algorithms from 14 people who have been diagnosed with Parkinson's disease undergoing LSVT (a program assisting voice rehabilitation). \n",
        "\n",
        "The original study used 309 algorithms to characterize 126 speech signals from 14 people, a robust feature selection mechanism to determine the most parsimonious feature subset, and Support Vector Machines (SVM) and Random Forests (RF) to predict the binary response (acceptable vs unacceptable phonation during rehabilitation). Both cross-validation (10-fold cross validation with 100 repetitions for statistical confidence) and leave one subject out methods were used for the validation of the findings. In both cases we denostrated a near 90% accurate replication of the clinicians' assessment.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl0vfsrYc-4m",
        "colab_type": "text"
      },
      "source": [
        "### Upgrade hosted runtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1rh_BRrITBs",
        "colab_type": "code",
        "outputId": "17cf4bcd-b4cf-4d54-ec90-2999d997f575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!pip install --upgrade pip           #upgrade pip package installer\n",
        "!pip install --upgrade scikit-learn  #upgrade scikit-learn package\n",
        "!pip install --upgrade numpy         #upgrade numpy package\n",
        "!pip install --upgrade pandas        #upgrade #upgrade pandas package\n",
        "!pip install --upgrade joblib\n",
        "!pip install --upgrade imbalanced-learn"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (19.3.1)\n",
            "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.3.3)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.17.4)\n",
            "Requirement already up-to-date: numpy in /usr/local/lib/python3.6/dist-packages (1.17.4)\n",
            "Requirement already up-to-date: pandas in /usr/local/lib/python3.6/dist-packages (0.25.3)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
            "Requirement already up-to-date: joblib in /usr/local/lib/python3.6/dist-packages (0.14.1)\n",
            "Requirement already up-to-date: imbalanced-learn in /usr/local/lib/python3.6/dist-packages (0.6.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.22 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.22)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.3.3)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.14.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45120CfmgzJb",
        "colab_type": "text"
      },
      "source": [
        "### Retrieve dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFxCg9zSR5v0",
        "colab_type": "code",
        "outputId": "833875bb-28e2-4eab-9ded-5827f9b4bf7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import io\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "from urllib.error import HTTPError\n",
        "\n",
        "# responsefile = \"lsvt_binary_response.csv\"\n",
        "# datafile = \"lsvt_data.csv\"\n",
        "# demographicsfile = \"lsvt_demographics.csv\"\n",
        "\n",
        "try:\n",
        "    #data without headers for better manipulation\n",
        "    binary_csv_url = \"https://raw.githubusercontent.com/steliostss/neural_networks_ntua/master/ex1/lsvt_binary_response.csv?token=AH57CIKFAWBUCP4KSDDKT4C576IO6\"\n",
        "    binary_response = pd.read_csv(binary_csv_url, header=None)\n",
        "\n",
        "    # data_csv_url = \"https://raw.githubusercontent.com/steliostss/neural_networks_ntua/master/ex1/lsvt_data_2.csv?token=AH57CINQWC5N4TIH7QQGZXC5753RE\"\n",
        "    data_csv_url = \"https://raw.githubusercontent.com/steliostss/neural_networks_ntua/master/ex1/lsvt_data.csv?token=AH57CIN4KNS65U7AGYDJX5K576HEE\"\n",
        "    data = pd.read_csv(data_csv_url, header=None)\n",
        "\n",
        "    demographics_csv_url = \"https://raw.githubusercontent.com/steliostss/neural_networks_ntua/master/ex1/lsvt_demographics.csv?token=AH57CIJAK62CQJZTPBS22JK57475Q\"\n",
        "    demographics = pd.read_csv(demographics_csv_url, header=None)\n",
        "\n",
        "    #data with headers for better visualizing\n",
        "    demographics_headers = pd.read_csv(demographics_csv_url)\n",
        "    data_headers = pd.read_csv(data_csv_url)\n",
        "    binary_response_headers = pd.read_csv(binary_csv_url)\n",
        "\n",
        "    print(\"Succesful file processing!\")\n",
        "\n",
        "except HTTPError:\n",
        "    print(\"URL not working.\")\n"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Succesful file processing!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQaikIfGcvw1",
        "colab_type": "text"
      },
      "source": [
        "### Printing for validation / visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9P8e258R-DQ",
        "colab_type": "code",
        "outputId": "a7177c17-9dd6-4622-9347-30bd50414754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "#print for better visualization\n",
        "data_headers.head(3)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Jitter-&gt;F0_abs_dif</th>\n",
              "      <th>Jitter-&gt;F0_dif_percent</th>\n",
              "      <th>Jitter-&gt;F0_PQ5_classical_Schoentgen</th>\n",
              "      <th>Jitter-&gt;F0_PQ5_classical_Baken</th>\n",
              "      <th>Jitter-&gt;F0_PQ5_generalised_Schoentgen</th>\n",
              "      <th>Jitter-&gt;F0_abs0th_perturb</th>\n",
              "      <th>Jitter-&gt;F0_CV</th>\n",
              "      <th>Jitter-&gt;F0_TKEO_mean</th>\n",
              "      <th>Jitter-&gt;F0_TKEO_std</th>\n",
              "      <th>Jitter-&gt;F0_TKEO_prc5</th>\n",
              "      <th>Jitter-&gt;F0_TKEO_prc25</th>\n",
              "      <th>Jitter-&gt;F0_TKEO_prc75</th>\n",
              "      <th>Jitter-&gt;F0_TKEO_prc95</th>\n",
              "      <th>Jitter-&gt;F0_FM</th>\n",
              "      <th>Jitter-&gt;F0range_5_95_perc</th>\n",
              "      <th>Jitter-&gt;pitch_abs</th>\n",
              "      <th>Jitter-&gt;pitch_percent</th>\n",
              "      <th>Jitter-&gt;pitch_PQ5_classical_Schoentgen</th>\n",
              "      <th>Jitter-&gt;pitch_PQ5_classical_Baken</th>\n",
              "      <th>Jitter-&gt;pitch_PQ5_generalised_Schoentgen</th>\n",
              "      <th>Jitter-&gt;pitch_abs0th_perturb</th>\n",
              "      <th>Jitter-&gt;pitch_CV</th>\n",
              "      <th>Jitter-&gt;pitch_TKEO_mean</th>\n",
              "      <th>Jitter-&gt;pitch_TKEO_std</th>\n",
              "      <th>Jitter-&gt;pitch_TKEO_prc5</th>\n",
              "      <th>Jitter-&gt;pitch_TKEO_prc25</th>\n",
              "      <th>Jitter-&gt;pitch_TKEO_prc75</th>\n",
              "      <th>Jitter-&gt;pitch_TKEO_prc95</th>\n",
              "      <th>Jitter-&gt;pitch_FM</th>\n",
              "      <th>Jitter-&gt;pitch_range_5_95_perc</th>\n",
              "      <th>Shimmer-&gt;Ampl_abs_dif</th>\n",
              "      <th>Shimmer-&gt;Ampl_dif_percent</th>\n",
              "      <th>Shimmer-&gt;Ampl_PQ3_classical_Schoentgen</th>\n",
              "      <th>Shimmer-&gt;Ampl_PQ3_classical_Baken</th>\n",
              "      <th>Shimmer-&gt;Ampl_PQ3_generalised_Schoentgen</th>\n",
              "      <th>Shimmer-&gt;Ampl_PQ5_classical_Schoentgen</th>\n",
              "      <th>Shimmer-&gt;Ampl_PQ5_classical_Baken</th>\n",
              "      <th>Shimmer-&gt;Ampl_PQ5_generalised_Schoentgen</th>\n",
              "      <th>Shimmer-&gt;Ampl_PQ11_classical_Schoentgen</th>\n",
              "      <th>Shimmer-&gt;Ampl_PQ11_classical_Baken</th>\n",
              "      <th>...</th>\n",
              "      <th>entropy_shannon4_1_coef</th>\n",
              "      <th>entropy_shannon4_2_coef</th>\n",
              "      <th>entropy_shannon4_3_coef</th>\n",
              "      <th>entropy_shannon4_4_coef</th>\n",
              "      <th>entropy_shannon4_5_coef</th>\n",
              "      <th>entropy_shannon4_6_coef</th>\n",
              "      <th>entropy_shannon4_7_coef</th>\n",
              "      <th>entropy_shannon4_8_coef</th>\n",
              "      <th>entropy_shannon4_9_coef</th>\n",
              "      <th>entropy_shannon4_10_coef</th>\n",
              "      <th>entropy_log4_1_coef</th>\n",
              "      <th>entropy_log4_2_coef</th>\n",
              "      <th>entropy_log4_3_coef</th>\n",
              "      <th>entropy_log4_4_coef</th>\n",
              "      <th>entropy_log4_5_coef</th>\n",
              "      <th>entropy_log4_6_coef</th>\n",
              "      <th>entropy_log4_7_coef</th>\n",
              "      <th>entropy_log4_8_coef</th>\n",
              "      <th>entropy_log4_9_coef</th>\n",
              "      <th>entropy_log4_10_coef</th>\n",
              "      <th>det_TKEO_mean4_1_coef</th>\n",
              "      <th>det_TKEO_mean4_2_coef</th>\n",
              "      <th>det_TKEO_mean4_3_coef</th>\n",
              "      <th>det_TKEO_mean4_4_coef</th>\n",
              "      <th>det_TKEO_mean4_5_coef</th>\n",
              "      <th>det_TKEO_mean4_6_coef</th>\n",
              "      <th>det_TKEO_mean4_7_coef</th>\n",
              "      <th>det_TKEO_mean4_8_coef</th>\n",
              "      <th>det_TKEO_mean4_9_coef</th>\n",
              "      <th>det_TKEO_mean4_10_coef</th>\n",
              "      <th>det_TKEO_std4_1_coef</th>\n",
              "      <th>det_TKEO_std4_2_coef</th>\n",
              "      <th>det_TKEO_std4_3_coef</th>\n",
              "      <th>det_TKEO_std4_4_coef</th>\n",
              "      <th>det_TKEO_std4_5_coef</th>\n",
              "      <th>det_TKEO_std4_6_coef</th>\n",
              "      <th>det_TKEO_std4_7_coef</th>\n",
              "      <th>det_TKEO_std4_8_coef</th>\n",
              "      <th>det_TKEO_std4_9_coef</th>\n",
              "      <th>det_TKEO_std4_10_coef</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.088112</td>\n",
              "      <td>0.041697</td>\n",
              "      <td>0.000480</td>\n",
              "      <td>-3.723304e-06</td>\n",
              "      <td>0.000422</td>\n",
              "      <td>2.458381</td>\n",
              "      <td>6.332164e-07</td>\n",
              "      <td>47.021079</td>\n",
              "      <td>1366.430390</td>\n",
              "      <td>-7.103323</td>\n",
              "      <td>-2.687924</td>\n",
              "      <td>-0.035674</td>\n",
              "      <td>2.849068</td>\n",
              "      <td>0.042287</td>\n",
              "      <td>9.116401</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.041920</td>\n",
              "      <td>0.000482</td>\n",
              "      <td>4.354061e-06</td>\n",
              "      <td>0.000440</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>6.856367e-07</td>\n",
              "      <td>2.536591e-08</td>\n",
              "      <td>7.412680e-07</td>\n",
              "      <td>-3.524844e-09</td>\n",
              "      <td>-1.382237e-09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.367104e-09</td>\n",
              "      <td>0.042287</td>\n",
              "      <td>0.000204</td>\n",
              "      <td>0.069838</td>\n",
              "      <td>11.566415</td>\n",
              "      <td>0.077160</td>\n",
              "      <td>-0.000064</td>\n",
              "      <td>0.081880</td>\n",
              "      <td>0.092070</td>\n",
              "      <td>-0.000057</td>\n",
              "      <td>0.081880</td>\n",
              "      <td>0.100744</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>...</td>\n",
              "      <td>-233661.1245</td>\n",
              "      <td>-277726.2665</td>\n",
              "      <td>-327634.1744</td>\n",
              "      <td>-390417.4249</td>\n",
              "      <td>-481323.9141</td>\n",
              "      <td>-633245.6446</td>\n",
              "      <td>-9.018569e+05</td>\n",
              "      <td>-1.433921e+06</td>\n",
              "      <td>-2528415.988</td>\n",
              "      <td>-4819157.284</td>\n",
              "      <td>4076.864063</td>\n",
              "      <td>2422.969509</td>\n",
              "      <td>1429.320757</td>\n",
              "      <td>851.745520</td>\n",
              "      <td>525.181116</td>\n",
              "      <td>345.610973</td>\n",
              "      <td>246.183529</td>\n",
              "      <td>195.776526</td>\n",
              "      <td>172.652511</td>\n",
              "      <td>164.557388</td>\n",
              "      <td>0.112549</td>\n",
              "      <td>0.443874</td>\n",
              "      <td>1.728619</td>\n",
              "      <td>6.539524</td>\n",
              "      <td>23.606344</td>\n",
              "      <td>79.049121</td>\n",
              "      <td>242.544297</td>\n",
              "      <td>661.679929</td>\n",
              "      <td>1618.318338</td>\n",
              "      <td>3643.234312</td>\n",
              "      <td>2.527583</td>\n",
              "      <td>7.088978</td>\n",
              "      <td>19.753255</td>\n",
              "      <td>54.335046</td>\n",
              "      <td>145.528630</td>\n",
              "      <td>375.097397</td>\n",
              "      <td>921.296579</td>\n",
              "      <td>2137.079844</td>\n",
              "      <td>4697.131077</td>\n",
              "      <td>9931.208257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.161798</td>\n",
              "      <td>0.057364</td>\n",
              "      <td>0.000677</td>\n",
              "      <td>5.466365e-06</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>2.592066</td>\n",
              "      <td>7.228518e-07</td>\n",
              "      <td>93.557936</td>\n",
              "      <td>2582.922776</td>\n",
              "      <td>-23.284761</td>\n",
              "      <td>-7.533801</td>\n",
              "      <td>-0.347630</td>\n",
              "      <td>7.457385</td>\n",
              "      <td>0.042783</td>\n",
              "      <td>11.568865</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.057055</td>\n",
              "      <td>0.000673</td>\n",
              "      <td>-5.419147e-06</td>\n",
              "      <td>0.000205</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>7.013483e-07</td>\n",
              "      <td>1.408057e-08</td>\n",
              "      <td>3.872420e-07</td>\n",
              "      <td>-3.561551e-09</td>\n",
              "      <td>-1.164851e-09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.195081e-09</td>\n",
              "      <td>0.042783</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.047107</td>\n",
              "      <td>7.202769</td>\n",
              "      <td>0.047907</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>0.055919</td>\n",
              "      <td>0.052175</td>\n",
              "      <td>0.000542</td>\n",
              "      <td>0.055919</td>\n",
              "      <td>0.072145</td>\n",
              "      <td>0.000223</td>\n",
              "      <td>...</td>\n",
              "      <td>-266292.2262</td>\n",
              "      <td>-315357.3478</td>\n",
              "      <td>-371033.9862</td>\n",
              "      <td>-441256.8092</td>\n",
              "      <td>-543227.8848</td>\n",
              "      <td>-713976.6286</td>\n",
              "      <td>-1.015830e+06</td>\n",
              "      <td>-1.613896e+06</td>\n",
              "      <td>-2843879.522</td>\n",
              "      <td>-5416842.350</td>\n",
              "      <td>4182.699168</td>\n",
              "      <td>2476.698050</td>\n",
              "      <td>1456.995087</td>\n",
              "      <td>866.391724</td>\n",
              "      <td>533.314567</td>\n",
              "      <td>350.486711</td>\n",
              "      <td>249.368427</td>\n",
              "      <td>198.116666</td>\n",
              "      <td>174.570294</td>\n",
              "      <td>166.263182</td>\n",
              "      <td>0.126734</td>\n",
              "      <td>0.499301</td>\n",
              "      <td>1.941236</td>\n",
              "      <td>7.344723</td>\n",
              "      <td>26.518497</td>\n",
              "      <td>88.784513</td>\n",
              "      <td>272.216266</td>\n",
              "      <td>742.338942</td>\n",
              "      <td>1814.494579</td>\n",
              "      <td>4082.136146</td>\n",
              "      <td>2.841881</td>\n",
              "      <td>7.977363</td>\n",
              "      <td>22.203504</td>\n",
              "      <td>60.993338</td>\n",
              "      <td>163.560972</td>\n",
              "      <td>421.010306</td>\n",
              "      <td>1036.092589</td>\n",
              "      <td>2404.072562</td>\n",
              "      <td>5284.082128</td>\n",
              "      <td>11165.095660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.554508</td>\n",
              "      <td>0.642913</td>\n",
              "      <td>0.007576</td>\n",
              "      <td>-7.443871e-07</td>\n",
              "      <td>0.006488</td>\n",
              "      <td>12.691326</td>\n",
              "      <td>6.946246e-04</td>\n",
              "      <td>52.988422</td>\n",
              "      <td>466.682635</td>\n",
              "      <td>-45.308680</td>\n",
              "      <td>-5.175259</td>\n",
              "      <td>-0.359585</td>\n",
              "      <td>4.549093</td>\n",
              "      <td>0.471729</td>\n",
              "      <td>39.079991</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.563163</td>\n",
              "      <td>0.006659</td>\n",
              "      <td>7.576645e-07</td>\n",
              "      <td>0.004372</td>\n",
              "      <td>0.001604</td>\n",
              "      <td>2.103274e-04</td>\n",
              "      <td>6.191656e-07</td>\n",
              "      <td>4.898115e-06</td>\n",
              "      <td>-8.230807e-07</td>\n",
              "      <td>-9.233181e-08</td>\n",
              "      <td>6.432232e-09</td>\n",
              "      <td>1.350863e-07</td>\n",
              "      <td>0.471729</td>\n",
              "      <td>0.005443</td>\n",
              "      <td>0.190733</td>\n",
              "      <td>34.449823</td>\n",
              "      <td>0.229084</td>\n",
              "      <td>-0.001374</td>\n",
              "      <td>0.259091</td>\n",
              "      <td>0.276145</td>\n",
              "      <td>0.001280</td>\n",
              "      <td>0.259091</td>\n",
              "      <td>0.315005</td>\n",
              "      <td>0.001812</td>\n",
              "      <td>...</td>\n",
              "      <td>-146466.6898</td>\n",
              "      <td>-176648.5331</td>\n",
              "      <td>-210656.5286</td>\n",
              "      <td>-253144.2859</td>\n",
              "      <td>-314304.4696</td>\n",
              "      <td>-416010.0510</td>\n",
              "      <td>-5.956926e+05</td>\n",
              "      <td>-9.520312e+05</td>\n",
              "      <td>-1686351.172</td>\n",
              "      <td>-3224775.436</td>\n",
              "      <td>3699.830964</td>\n",
              "      <td>2231.698375</td>\n",
              "      <td>1330.932885</td>\n",
              "      <td>799.805232</td>\n",
              "      <td>496.476954</td>\n",
              "      <td>328.515054</td>\n",
              "      <td>235.080823</td>\n",
              "      <td>187.675057</td>\n",
              "      <td>166.054276</td>\n",
              "      <td>158.705559</td>\n",
              "      <td>0.080899</td>\n",
              "      <td>0.318113</td>\n",
              "      <td>1.228114</td>\n",
              "      <td>4.615947</td>\n",
              "      <td>16.650282</td>\n",
              "      <td>55.476114</td>\n",
              "      <td>169.270664</td>\n",
              "      <td>461.248613</td>\n",
              "      <td>1125.194320</td>\n",
              "      <td>2523.348299</td>\n",
              "      <td>1.806103</td>\n",
              "      <td>5.078616</td>\n",
              "      <td>14.135923</td>\n",
              "      <td>38.641654</td>\n",
              "      <td>103.466808</td>\n",
              "      <td>264.654626</td>\n",
              "      <td>649.657090</td>\n",
              "      <td>1507.384591</td>\n",
              "      <td>3315.804236</td>\n",
              "      <td>6974.600636</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 310 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Jitter->F0_abs_dif  ...  det_TKEO_std4_10_coef\n",
              "0            0.088112  ...            9931.208257\n",
              "1            0.161798  ...           11165.095660\n",
              "2            0.554508  ...            6974.600636\n",
              "\n",
              "[3 rows x 310 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fhcg2Jv0jZHT",
        "colab_type": "code",
        "outputId": "c80da686-be30-45bb-aff9-254b349c4b31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "#print for better visualization\n",
        "demographics_headers.head(3)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Subject_index</th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender, 0-&gt;Male, 1-&gt;Female</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>68</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>68</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>68</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Subject_index  Age  Gender, 0->Male, 1->Female\n",
              "0              1   68                           1\n",
              "1              1   68                           1\n",
              "2              1   68                           1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F28WDEwQjd98",
        "colab_type": "code",
        "outputId": "9b47e28a-2722-47d5-a2a2-35d33cd69361",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "#print for better visualization\n",
        "binary_response_headers.head(3)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   1\n",
              "0  2\n",
              "1  2\n",
              "2  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr8f1_Axc4fI",
        "colab_type": "text"
      },
      "source": [
        "### Custom functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqedVc1YuZ_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## GATHER ALL FUNCTIONS FOR SECTION-B HERE\n",
        "\n",
        "# evaluate type of value in the given variable\n",
        "def tryeval(np_samples):\n",
        "    for row in range(len(np_samples)): \n",
        "        for col in range(len(np_samples[row])):\n",
        "            try: \n",
        "                np_samples[row][col] = ast.literal_eval(np_samples[row][col])\n",
        "            except ValueError:\n",
        "                pass\n",
        "    return np_samples\n",
        "\n",
        "def tryeval1D(np_samples):\n",
        "    for row in range(len(np_samples)): \n",
        "        try: \n",
        "            np_samples[row] = ast.literal_eval(np_samples[row])\n",
        "        except ValueError:\n",
        "            pass\n",
        "    return np_samples\n",
        "\n",
        "# define if all features have the same type\n",
        "def features_datatypes(features):\n",
        "    datatypes = list()\n",
        "    for row in range(len(features)):\n",
        "        for col in range(len(features[row])):\n",
        "            current_type = type(features[row][col])\n",
        "            if current_type not in datatypes:\n",
        "                datatypes.append(current_type)\n",
        "\n",
        "    return datatypes\n",
        "# define all class labels\n",
        "def class_labels(labels):\n",
        "    cLabels = list()\n",
        "    for col in range(len(labels)):\n",
        "        current_val = labels[col]\n",
        "        if current_val not in cLabels:\n",
        "            cLabels.append(current_val)\n",
        "    return cLabels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xebU-h0ldN58",
        "colab_type": "text"
      },
      "source": [
        "### Manage datafile, get desired data\n",
        "\n",
        "Get #features, #samples, type of features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK69s1JQXlRp",
        "colab_type": "code",
        "outputId": "d3f5f20a-ef18-49da-ee52-dd3dbbf79357",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# gather data features in a table\n",
        "data_features = data.iloc[[0],0:]\n",
        "( _ , number_of_features ) = data_features.shape\n",
        "print(\"Q2: Number of features = \", number_of_features)\n",
        "# print(data_features.shape) # uncomment if you want to check the results\n",
        "\n",
        "# gather data samples in a table\n",
        "data_samples = data.iloc[1:,0:]\n",
        "( number_of_samples , _ ) = data_samples.shape\n",
        "print(\"Q2: Number of samples = \", number_of_samples)\n",
        "# print(data_samples.shape) # uncomment if you want to check the results\n",
        "\n",
        "# transform the gathered data in numpy arrays\n",
        "np_features = data_features.values\n",
        "np_samples = data_samples.values\n",
        "\n",
        "# # convert the type of samples to the correct type\n",
        "np_samples = tryeval(np_samples)\n",
        "datatypes = features_datatypes(np_samples)\n",
        "\n",
        "print(\"Q2: Type of features =\", end=' ')\n",
        "print(*datatypes, sep=' & ')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q2: Number of features =  310\n",
            "Q2: Number of samples =  126\n",
            "Q2: Type of features = <class 'float'> & <class 'int'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJ5SyhuoCnYE",
        "colab_type": "text"
      },
      "source": [
        "- Q3: There are headers in the first line\n",
        "\n",
        "- Q3: There is no line numbering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T01BLPCTqzlU",
        "colab_type": "code",
        "outputId": "e4c63369-6d9f-46b0-aa42-99b789e66ae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# gather class labels in a table\n",
        "binary_class_labels = binary_response.iloc[0:,:] \n",
        "np_labels_temp = binary_class_labels.values.flatten()\n",
        "\n",
        "np_labels = list()\n",
        "for item in np_labels_temp:\n",
        "    np_labels.append(item)\n",
        "\n",
        "np_labels = np.array(np_labels)\n",
        "\n",
        "np_labels = tryeval1D(np_labels)\n",
        "\n",
        "np_labels"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1,\n",
              "       2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2,\n",
              "       2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2,\n",
              "       1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1,\n",
              "       2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2,\n",
              "       2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_sKL3VPdjK2",
        "colab_type": "text"
      },
      "source": [
        "### Classification Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "choIDcboiKGE",
        "colab_type": "code",
        "outputId": "c194788e-4069-4a45-8b4e-0cf363da3696",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# make a list with all different labels\n",
        "list_of_labels = class_labels(np_labels)\n",
        "print(\"Q4: Classification Labels =\", end=' ')\n",
        "print(*list_of_labels, sep = \" & \")\n",
        "\n",
        "label_names = list()\n",
        "for i in range(len(list_of_labels)):\n",
        "    label_names.append(str(list_of_labels[i]))\n",
        "# label_names = ('1','2')\n",
        "label_names"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q4: Classification Labels = 1 & 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1', '2']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aMVqYiNCv8k",
        "colab_type": "text"
      },
      "source": [
        "### Modifications on the datafile\n",
        "- Q5: There were some modifications on the data. \n",
        "    - We replaced **\" , \"** with **\" . \"**\n",
        "    - We removed the headers on the binary response file.\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRdxqG4kd3DC",
        "colab_type": "text"
      },
      "source": [
        "### Check Empty dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms5TCwkoS_AU",
        "colab_type": "code",
        "outputId": "b91a377b-8f44-41d0-bbbc-66254e5ea04e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# check if dataset has empty values\n",
        "# and if, how many of them\n",
        "!ls\n",
        "!echo \"For binary_response file, empty values: \"\n",
        "!cat lsvt_binary_response.csv | grep \"?\" | wc -l\n",
        "!echo \"For data file, empty values: \"\n",
        "!cat lsvt_data.csv | grep \"?\" | wc -l\n",
        "!echo \"For demographics file, empty values: \"\n",
        "!cat lsvt_demographics.csv | grep \"?\" | wc -l"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lsvt_binary_response.csv  lsvt_data.csv  lsvt_demographics.csv\tsample_data\n",
            "For binary_response file, empty values: \n",
            "0\n",
            "For data file, empty values: \n",
            "0\n",
            "For demographics file, empty values: \n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ym4ULdPd6o-",
        "colab_type": "text"
      },
      "source": [
        "### Label frequencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRqXg0dzI5Va",
        "colab_type": "code",
        "outputId": "dd4b0b1c-5201-4ac3-c646-1b8d0c452b2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "print(\"frequencies:\", np.bincount(np_labels))\n",
        "freq = np.bincount(np_labels)\n",
        "for i in range(len(freq)):\n",
        "    if i == 0: continue\n",
        "    print(\"For label:\", i, \"percentage is\", \"{:.2%}\".format(freq[i]/number_of_samples))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frequencies: [ 0 42 84]\n",
            "For label: 1 percentage is 33.33%\n",
            "For label: 2 percentage is 66.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FY5CeA09SZBc",
        "colab_type": "text"
      },
      "source": [
        "Το παραπάνω dataset όπως φαίνεται από τις συχνότητες δεν είναι ισορροπημένο.\n",
        "Καθώς το δείγμα είναι μικρό επιλέγουμε να κανουμε oversampling για να μη χάσουμε κρίσιμη πληροφορία. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhcQ_caxeGDx",
        "colab_type": "text"
      },
      "source": [
        "### Split to test and train set\n",
        "\n",
        "After spliting, we oversample the train set to be balanced"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMx9wyt8SzfP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.metrics import confusion_matrix, classification_report \n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.over_sampling import SMOTE "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qndH6YbP8wy",
        "colab_type": "code",
        "outputId": "8c74bd4a-2804-4a2b-a5cd-62907b1ed151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split our data\n",
        "train, test, train_labels, test_labels = train_test_split(np_samples, \n",
        "                                                          np_labels, \n",
        "                                                          test_size=0.2)\n",
        "\n",
        "sampler = SMOTE()\n",
        "train, train_labels = sampler.fit_sample(np_samples, np_labels)\n",
        "\n",
        "train_set_length = len(train)\n",
        "# print length of train set to validate oversampling\n",
        "print(\"#samples in train set =\", train_set_length, '\\n')"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#samples in train set = 168 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAmCcm6dVUTo",
        "colab_type": "text"
      },
      "source": [
        "**Q8**: Our samples are **ordered tuples** since each number corresponds to a specific attribute."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFh5NnUGQ9SO",
        "colab_type": "text"
      },
      "source": [
        "## Section C: Baseline Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbTMUToWm1d3",
        "colab_type": "text"
      },
      "source": [
        "### Custom functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vfYRlvnHQ7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import classification_report\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def print_precision_recall_fscore_support(method, test_labels, pred, label_names):\n",
        "    print(method, end = '\\n\\n')\n",
        "    (none, micro, macro, weighted) = get_PRFS(method, test_labels, pred, label_names)\n",
        "    # εκτυπώνουμε 4 πίνακες, precision, recall, F1 και support. Support είναι ο συνολικός αριθμός προβλέψεων σε κάθε κλάση\n",
        "    # το πρώτο στοιχείο του κάθε πίνακα είναι η κλάση 1 και το δεύτερο η κλάσση 2\n",
        "    print(\"none     :\", none )\n",
        "    # εκτυπώνουμε τa precision, recall και F1 λαμβάνοντας υπόψη συνολικά (αθροίζοντας εκτός κλάσεων) τα δείγματα (average = micro).\n",
        "    print(\"micro    :\", micro )\n",
        "    # εκτυπώνουμε το μέσο όρο των precision, recall και F1 θεωρόντας ότι οι κλάσεις έχουν το ίδιο βάρος (average = macro)\n",
        "    print(\"macro    :\", macro )\n",
        "    # εκτυπώνουμε τa precision, recall και F1 λαμβάνοντας. Με average = weighted κάθε κλάση μετρά στο μέσο όρο ανάλογα με το support της.\n",
        "    print(\"weighted :\", weighted, end = '\\n\\n')\n",
        "    # η classification_report τυπώνει πιο ωραία οπτικά σε string τα αποτελέσματα\n",
        "    # πρώτα για κάθε κλάση και μετά με μέσους όρους\n",
        "    print(classification_report(test_labels, pred, target_names=label_names), end = '\\n\\n')\n",
        "\n",
        "    ( _ , _ , microF1    , _ ) = micro\n",
        "    ( _ , _ , macroF1    , _ ) = macro\n",
        "    ( _ , _ , weightedF1 , _ ) = weighted\n",
        "\n",
        "    barplotF1 = (microF1, macroF1, weightedF1)\n",
        "    xaxis = (\"microF1\", \"macroF1\", \"weightedF1\")\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.bar(xaxis, barplotF1)\n",
        "    plt.show()\n",
        "    print(\"---------------------------------------------------------------------------------------------------------------------\", end = '\\n')\n",
        "    print(\"---------------------------------------------------------------------------------------------------------------------\", end = '\\n\\n')\n",
        "\n",
        "# get_precision_recall_fscore_support\n",
        "def get_PRFS(method, test_labels, pred, label_names):\n",
        "    none = precision_recall_fscore_support(test_labels, pred, average=None)\n",
        "    micro = precision_recall_fscore_support(test_labels, pred, average='micro')\n",
        "    macro = precision_recall_fscore_support(test_labels, pred, average='macro')\n",
        "    weighted = precision_recall_fscore_support(test_labels, pred, average='weighted')\n",
        "    return (none, micro, macro, weighted)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UHYkaYtMuDC",
        "colab_type": "text"
      },
      "source": [
        "### Dummy Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnWtPk3JQqFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dc_uniform = DummyClassifier(strategy=\"uniform\")\n",
        "dc_constant_1 = DummyClassifier(strategy=\"constant\", constant=1)\n",
        "dc_constant_2 = DummyClassifier(strategy=\"constant\", constant=2)\n",
        "dc_most_frequent = DummyClassifier(strategy=\"most_frequent\")\n",
        "dc_stratified = DummyClassifier(strategy=\"stratified\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFpM-0ZMYr4q",
        "colab_type": "code",
        "outputId": "ce672b39-8fee-475f-bc48-1ac8a560d9b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# με τη μέθοδο fit \"εκπαιδεύουμε\" τον ταξινομητή στο σύνολο εκπαίδευσης (τα χαρακτηριστικά και τις ετικέτες τους)\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# με τη μέθοδο predict παράγουμε προβλέψεις για τα δεδομένα ελέγχου (είσοδος τα χαρακτηριστικά μόνο)\n",
        "predictions = {}\n",
        "lsvt_accuracy = {}\n",
        "\n",
        "model = dc_uniform.fit(train, train_labels)\n",
        "preds = dc_uniform.predict(test)\n",
        "predictions['dc_uniform'] = preds\n",
        "lsvt_accuracy['uniform (random)'] = accuracy_score(test_labels, preds)\n",
        "\n",
        "\n",
        "model = dc_constant_1.fit(train, train_labels)\n",
        "preds = dc_constant_1.predict(test)\n",
        "predictions['dc_constant_1'] = preds\n",
        "lsvt_accuracy['constant 1'] = accuracy_score(test_labels, preds)\n",
        "\n",
        "model = dc_constant_2.fit(train, train_labels)\n",
        "preds = dc_constant_2.predict(test)\n",
        "predictions['dc_constant_2'] = preds\n",
        "lsvt_accuracy['constant 2'] = accuracy_score(test_labels, preds)\n",
        "\n",
        "model = dc_most_frequent.fit(train, train_labels)\n",
        "preds = dc_most_frequent.predict(test)\n",
        "predictions['dc_most_frequent'] = preds\n",
        "lsvt_accuracy['most frequent label'] = accuracy_score(test_labels, preds)\n",
        "\n",
        "model = dc_stratified.fit(train, train_labels)\n",
        "preds = dc_stratified.predict(test)\n",
        "predictions['dc_stratified'] = preds\n",
        "lsvt_accuracy['stratified'] = accuracy_score(test_labels, preds)\n",
        "\n",
        "for i in predictions:\n",
        "    print(\"Prediction for\", i, '=', predictions[i])\n",
        "\n",
        "print()\n",
        "    \n",
        "print(\"Classification Accuracy on the LSVT Voice Rehabilitation Dataset (20% test set)\\n\")\n",
        "sorted_accuracy = [(k, lsvt_accuracy[k]) for k in sorted(lsvt_accuracy, key=lsvt_accuracy.get, reverse=True)]\n",
        "\n",
        "print(\"----------Results are sorted----------\")\n",
        "print(\"** Strategy (score, accuracy_score) **\\n\")\n",
        "for k,v in sorted_accuracy:\n",
        "    print(k,v)\n"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction for dc_uniform = [1 2 2 1 1 1 1 1 2 1 2 1 2 1 1 2 2 2 1 1 1 1 2 2 1 2]\n",
            "Prediction for dc_constant_1 = [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Prediction for dc_constant_2 = [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Prediction for dc_most_frequent = [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Prediction for dc_stratified = [2 2 1 1 1 2 1 1 1 2 2 2 2 2 2 1 2 2 1 2 2 2 1 2 2 2]\n",
            "\n",
            "Classification Accuracy on the LSVT Voice Rehabilitation Dataset (20% test set)\n",
            "\n",
            "----------Results are sorted----------\n",
            "** Strategy (score, accuracy_score) **\n",
            "\n",
            "stratified 0.7307692307692307\n",
            "constant 2 0.6923076923076923\n",
            "uniform (random) 0.4230769230769231\n",
            "constant 1 0.3076923076923077\n",
            "most frequent label 0.3076923076923077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuLFQ5lCZSsv",
        "colab_type": "code",
        "outputId": "c548f9b2-9e18-4539-9f85-86c75605d4bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "# Compute confusion matrix\n",
        "\n",
        "print(\"Confusion matrices\\n\")\n",
        "for i in predictions:\n",
        "    # τυπώνουμε το confusion matrix\n",
        "    cnf_matrix = confusion_matrix(test_labels, predictions[i])\n",
        "    print(i)\n",
        "    print(cnf_matrix, end='\\n\\n')"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrices\n",
            "\n",
            "dc_uniform\n",
            "[[ 4  4]\n",
            " [11  7]]\n",
            "\n",
            "dc_constant_1\n",
            "[[ 8  0]\n",
            " [18  0]]\n",
            "\n",
            "dc_constant_2\n",
            "[[ 0  8]\n",
            " [ 0 18]]\n",
            "\n",
            "dc_most_frequent\n",
            "[[ 8  0]\n",
            " [18  0]]\n",
            "\n",
            "dc_stratified\n",
            "[[ 5  3]\n",
            " [ 4 14]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhmZs3Z_pPGZ",
        "colab_type": "code",
        "outputId": "9b254e43-2924-4d13-de99-61fe87612c69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "for i in predictions:\n",
        "    print_precision_recall_fscore_support(i, test_labels, predictions[i], label_names)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dc_uniform\n",
            "\n",
            "none     : (array([0.26666667, 0.63636364]), array([0.5       , 0.38888889]), array([0.34782609, 0.48275862]), array([ 8, 18]))\n",
            "micro    : (0.4230769230769231, 0.4230769230769231, 0.4230769230769231, None)\n",
            "macro    : (0.45151515151515154, 0.4444444444444444, 0.4152923538230885, None)\n",
            "weighted : (0.5226107226107226, 0.4230769230769231, 0.44124091800253723, None)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.27      0.50      0.35         8\n",
            "           2       0.64      0.39      0.48        18\n",
            "\n",
            "    accuracy                           0.42        26\n",
            "   macro avg       0.45      0.44      0.42        26\n",
            "weighted avg       0.52      0.42      0.44        26\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAEvCAYAAABhSUTPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------------------------------------------------------------------\n",
            "---------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "dc_constant_1\n",
            "\n",
            "none     : (array([0.30769231, 0.        ]), array([1., 0.]), array([0.47058824, 0.        ]), array([ 8, 18]))\n",
            "micro    : (0.3076923076923077, 0.3076923076923077, 0.3076923076923077, None)\n",
            "macro    : (0.15384615384615385, 0.5, 0.23529411764705882, None)\n",
            "weighted : (0.09467455621301776, 0.3076923076923077, 0.14479638009049772, None)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.31      1.00      0.47         8\n",
            "           2       0.00      0.00      0.00        18\n",
            "\n",
            "    accuracy                           0.31        26\n",
            "   macro avg       0.15      0.50      0.24        26\n",
            "weighted avg       0.09      0.31      0.14        26\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAAEvCAYAAAB2a9QGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nELIAAAb4f5btKkzT9kllAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------------------------------------------------------------------\n",
            "---------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "dc_constant_2\n",
            "\n",
            "none     : (array([0.        , 0.69230769]), array([0., 1.]), array([0.        , 0.81818182]), array([ 8, 18]))\n",
            "micro    : (0.6923076923076923, 0.6923076923076923, 0.6923076923076923, None)\n",
            "macro    : (0.34615384615384615, 0.5, 0.40909090909090906, None)\n",
            "weighted : (0.47928994082840237, 0.6923076923076923, 0.5664335664335665, None)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         8\n",
            "           2       0.69      1.00      0.82        18\n",
            "\n",
            "    accuracy                           0.69        26\n",
            "   macro avg       0.35      0.50      0.41        26\n",
            "weighted avg       0.48      0.69      0.57        26\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAEvCAYAAABhSUTPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUwAAA8QUAMAAMQUAMOD/AxRtm/SSdm+9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------------------------------------------------------------------\n",
            "---------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "dc_most_frequent\n",
            "\n",
            "none     : (array([0.30769231, 0.        ]), array([1., 0.]), array([0.47058824, 0.        ]), array([ 8, 18]))\n",
            "micro    : (0.3076923076923077, 0.3076923076923077, 0.3076923076923077, None)\n",
            "macro    : (0.15384615384615385, 0.5, 0.23529411764705882, None)\n",
            "weighted : (0.09467455621301776, 0.3076923076923077, 0.14479638009049772, None)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.31      1.00      0.47         8\n",
            "           2       0.00      0.00      0.00        18\n",
            "\n",
            "    accuracy                           0.31        26\n",
            "   macro avg       0.15      0.50      0.24        26\n",
            "weighted avg       0.09      0.31      0.14        26\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAAEvCAYAAAB2a9QGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nELIAAAb4f5btKkzT9kllAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------------------------------------------------------------------\n",
            "---------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "dc_stratified\n",
            "\n",
            "none     : (array([0.55555556, 0.82352941]), array([0.625     , 0.77777778]), array([0.58823529, 0.8       ]), array([ 8, 18]))\n",
            "micro    : (0.7307692307692307, 0.7307692307692307, 0.7307692307692306, None)\n",
            "macro    : (0.6895424836601307, 0.7013888888888888, 0.6941176470588235, None)\n",
            "weighted : (0.7410759175465057, 0.7307692307692307, 0.734841628959276, None)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.56      0.62      0.59         8\n",
            "           2       0.82      0.78      0.80        18\n",
            "\n",
            "    accuracy                           0.73        26\n",
            "   macro avg       0.69      0.70      0.69        26\n",
            "weighted avg       0.74      0.73      0.73        26\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAEvCAYAAABhSUTPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhMjwhi8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------------------------------------------------------------------\n",
            "---------------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moeExYNt9QmW",
        "colab_type": "text"
      },
      "source": [
        "##### Comments on the diagrams\n",
        "- Among the Dummy Classifiers, it is visible that the best strategy is 'constant 2' since class 2 is the most frequent one. Moreover, if we run the classification multiple times, we notice that 'stratified' strategy results in better accuracy more often than the 'uniform' strategy. This is because our dataset is not balanced and 'stratified' is more effiecient than the random strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMrUL--3G_F0",
        "colab_type": "text"
      },
      "source": [
        "### k Nearest Neighbors Classifier (kNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fequNH8Y--ul",
        "colab_type": "code",
        "outputId": "13b19163-256f-4ecc-a865-cd5c43697d69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=2)\n",
        "\n",
        "knn.fit(train, train_labels)\n",
        "\n",
        "pred = knn.predict(test)\n",
        "\n",
        "cnf_matrix = confusion_matrix(test_labels, pred)\n",
        "\n",
        "print(\"kNN Confusion matrix:\\n\\n\", cnf_matrix, '\\n')\n",
        "\n",
        "print_precision_recall_fscore_support(\"KNeighborsClassifier\", test_labels, pred, label_names)\n"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kNN Confusion matrix:\n",
            "\n",
            " [[ 8  0]\n",
            " [ 8 10]] \n",
            "\n",
            "KNeighborsClassifier\n",
            "\n",
            "none     : (array([0.5, 1. ]), array([1.        , 0.55555556]), array([0.66666667, 0.71428571]), array([ 8, 18]))\n",
            "micro    : (0.6923076923076923, 0.6923076923076923, 0.6923076923076923, None)\n",
            "macro    : (0.75, 0.7777777777777778, 0.6904761904761905, None)\n",
            "weighted : (0.8461538461538461, 0.6923076923076923, 0.6996336996336996, None)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.50      1.00      0.67         8\n",
            "           2       1.00      0.56      0.71        18\n",
            "\n",
            "    accuracy                           0.69        26\n",
            "   macro avg       0.75      0.78      0.69        26\n",
            "weighted avg       0.85      0.69      0.70        26\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAEvCAYAAABhSUTPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0l6dAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------------------------------------------------------------------\n",
            "---------------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsSSRw_P_m1I",
        "colab_type": "text"
      },
      "source": [
        "#### Comments on the diagrams\n",
        "- We see that kNN did manage to guess the whole class '1' and around half of the class '2', that's why it reaches a weighted average of 75%, better than the Dummy's results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFDUwXAoOmpD",
        "colab_type": "text"
      },
      "source": [
        "## Section D: Optimizing Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyJbkdYzeImt",
        "colab_type": "text"
      },
      "source": [
        "### Split to Training/Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F-PScZbY7ia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split our data\n",
        "train, test, train_labels, test_labels = train_test_split(np_samples, \n",
        "                                                          np_labels, \n",
        "                                                          test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW93Qn_MdKfa",
        "colab_type": "text"
      },
      "source": [
        "### Balance Dataset - Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHyJ-O2vdJG8",
        "colab_type": "code",
        "outputId": "8105e05c-ff58-4fd4-f569-9f2d475d8ef3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "sampler = SMOTE()\n",
        "train, train_labels = sampler.fit_sample(np_samples, np_labels)\n",
        "\n",
        "train_set_length = len(train)\n",
        "# print length of train set to validate oversampling\n",
        "print(\"#samples in train set =\", train_set_length, '\\n')"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#samples in train set = 168 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYNgFvG6cxCJ",
        "colab_type": "text"
      },
      "source": [
        "### Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYuRVpvYWjHB",
        "colab_type": "text"
      },
      "source": [
        "#### Selection - Variance Threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5PpUxhbcKng",
        "colab_type": "code",
        "outputId": "34274110-e55a-484e-88ae-4acaf711b57a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "selector = VarianceThreshold(threshold=0.5)\n",
        "# όπως κάναμε και με τους ταξινομητές τον κάνουμε fit στα δεδομένα εκπαίδευσης\n",
        "train_reduced = selector.fit_transform(train)\n",
        "mask = selector.get_support()\n",
        "test_reduced = test[:,mask]\n",
        "\n",
        "selector = None\n",
        "selector = VarianceThreshold(threshold=15000)\n",
        "# όπως κάναμε και με τους ταξινομητές τον κάνουμε fit στα δεδομένα εκπαίδευσης\n",
        "train_reduced_20k = selector.fit_transform(train)\n",
        "mask = selector.get_support()\n",
        "test_reduced_20k = test[:,mask]\n",
        "\n",
        "print(\"0.5\", train_reduced.shape)\n",
        "print(\"0.5\", test_reduced.shape)\n",
        "print(\"20000\", train_reduced_20k.shape)\n",
        "print(\"20000\", test_reduced_20k.shape)\n",
        "print(train_labels.shape)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5 (168, 179)\n",
            "0.5 (26, 179)\n",
            "20000 (168, 93)\n",
            "20000 (26, 93)\n",
            "(168,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnH4aeVDWqj4",
        "colab_type": "text"
      },
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCPB0JzwXBSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "# όριζουμε ένα αντικείμενο scaler και το κάνουμε fit στο train set\n",
        "scaler = preprocessing.StandardScaler().fit(train)\n",
        "# standardization των features του training set\n",
        "train_scaled = scaler.transform(train)\n",
        "# εφαρμόζουμε τον scaler στα δεδομένα test\n",
        "test_scaled = scaler.transform(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1GK08jOdZH_",
        "colab_type": "text"
      },
      "source": [
        "### Hyperparameter Optimization\n",
        "Custom GridsearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVdqIZ3cqIWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_tuples(arr):\n",
        "    results = list()\n",
        "    for i in range(0, len(arr), 2):\n",
        "        results.append((arr[i], arr[i+1]))\n",
        "    return results\n",
        "\n",
        "def _gridsearch(test_set, test_set_labels, train_set, train_set_labels, KMAX, label_names):\n",
        "    # test every value for k\n",
        "    # append the result to a list\n",
        "    # sort the list\n",
        "    # return the list and keep the best\n",
        "    gridsearch_results = list()\n",
        "\n",
        "    for i in range(1, KMAX):\n",
        "        method = \"KNeighborsClassifier\"\n",
        "        knn = KNeighborsClassifier(n_neighbors=i)\n",
        "        knn.fit(train_set, train_set_labels)\n",
        "        pred = knn.predict(test_set)\n",
        "        accuracy = accuracy_score(test_set_labels, pred)\n",
        "\n",
        "        gridsearch_results.extend( (accuracy, i) )\n",
        "\n",
        "    return gridsearch_results\n",
        "\n",
        "def get_next_fold(_splitted_train, _train_labels, iter):\n",
        "    counter = 0\n",
        "    total_size = 0\n",
        "    first_time = True\n",
        "    for ( _data , _labels ) in zip(_splitted_train, _train_labels):\n",
        "        if ( counter == iter ): # if current fold is test fold\n",
        "            __test = _data\n",
        "            __test_labels = _labels\n",
        "        elif ( first_time ): # initialize train and train_labels\n",
        "            __train = _data\n",
        "            __train_labels = _labels\n",
        "            first_time = False\n",
        "        else: # everything else is the train fold\n",
        "            __train = np.concatenate((__train, _data), axis=0)\n",
        "            __train_labels = np.concatenate((__train_labels, _labels), axis=0)\n",
        "        counter += 1\n",
        "    return( __test, __test_labels, __train, __train_labels )\n",
        "\n",
        "\n",
        "def _Kfold_cv(_train, _train_labels, _label_names, _folds=10):\n",
        "    # split the train set and labels in 10 parts \n",
        "    split_train = np.array_split(_train, _folds)\n",
        "    split_labels = np.array_split(_train_labels, _folds)\n",
        "\n",
        "    # for i in range(_folds):\n",
        "    #     print (len(split_train[i]), \",\", len(split_labels[i]))\n",
        "    knn_results = list()\n",
        "    # print(KMAX)\n",
        "\n",
        "    for iter in range(_folds):\n",
        "        KMAX = len(split_train[iter]) # because there is no reason to search for more neighbors if they do no exist\n",
        "\n",
        "        # do every possible fold out of 10\n",
        "        (test_set, test_set_labels, train_set, train_set_labels) = get_next_fold(split_train, split_labels, iter)\n",
        "    \n",
        "        # and test every k for kNN and save results\n",
        "        fold_results = _gridsearch(test_set, test_set_labels, train_set, train_set_labels, KMAX, _label_names)\n",
        "        knn_results.extend((fold_results))\n",
        "\n",
        "    return knn_results\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm_DxswmdfZc",
        "colab_type": "text"
      },
      "source": [
        "### Final Classification - Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqcxpomBY9S8",
        "colab_type": "code",
        "outputId": "c6036799-a2ee-4165-bfad-c911f67fbf0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "\n",
        "# print(test_labels)\n",
        "# print(len(train), len(train_labels), len(label_names))\n",
        "\n",
        "# classic dataset\n",
        "results = _Kfold_cv(train, train_labels, label_names)\n",
        "results = make_tuples(results)\n",
        "results = sorted(results, key=lambda x:x[0], reverse=True)\n",
        "\n",
        "#reduced with variance threshold = 0.5 \n",
        "results_reduced = _Kfold_cv(train_reduced, train_labels, label_names)\n",
        "results_reduced = make_tuples(results_reduced)\n",
        "results_reduced = sorted(results_reduced, key=lambda x:x[0], reverse=True)\n",
        "\n",
        "#reduced with variance threshold = 20000 \n",
        "results_reduced_20k = _Kfold_cv(train_reduced_20k, train_labels, label_names)\n",
        "results_reduced_20k = make_tuples(results_reduced_20k)\n",
        "results_reduced_20k = sorted(results_reduced_20k, key=lambda x:x[0], reverse=True)\n",
        "\n",
        "best_k = results[0][1]\n",
        "best_k_reduced = results_reduced[0][1]\n",
        "best_k_reduced_20k = results_reduced_20k[0][1]\n",
        "print(\"Initial trainset, bestK = \", best_k)\n",
        "print(\"Variance = 0.5 trainset, bestK = \", best_k_reduced)\n",
        "print(\"Variance = 20000  trainset, bestK = \", best_k_reduced_20k)\n",
        "\n",
        "#reduced with variance threshold = 20000 \n",
        "results_scaled = _Kfold_cv(train_scaled, train_labels, label_names)\n",
        "results_scaled = make_tuples(results_scaled)\n",
        "results_scaled = sorted(results_scaled, key=lambda x:x[0], reverse=True)\n",
        "\n",
        "best_k_scaled = results_scaled[0][1]\n",
        "print(\"Scaling trainset, bestK = \", best_k_scaled)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial trainset, bestK =  4\n",
            "Variance = 0.5 trainset, bestK =  4\n",
            "Variance = 20000  trainset, bestK =  4\n",
            "Scaling trainset, bestK =  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRb4ZatPw--l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def knn_fit_predict_print(_classifier, _train, _train_labels, _test, _test_labels, _label_names):\n",
        "    _classifier.fit(_train, _train_labels)\n",
        "    pred = _classifier.predict(_test)\n",
        "    accuracy = accuracy_score(_test_labels, pred)\n",
        "    print(accuracy) \n",
        "    # print_precision_recall_fscore_support(\"kNearestNeighbors\", _test_labels, pred, _label_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHITnSyXS2Yo",
        "colab_type": "text"
      },
      "source": [
        "### Print results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsFKW_3sbMwI",
        "colab_type": "code",
        "outputId": "fa9ca831-dfef-4f2b-c96b-61b5b18a6504",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "knn = None\n",
        "print(\"Initial Variance\")\n",
        "knn = KNeighborsClassifier(n_neighbors = best_k)\n",
        "print(\"accuracy = \", end=\" \")\n",
        "knn_fit_predict_print(knn, train, train_labels, test, test_labels, label_names)\n",
        "\n",
        "print(\"\\nVariance Threshold = 0.5\")\n",
        "knn = None\n",
        "knn = KNeighborsClassifier(n_neighbors = best_k_reduced)\n",
        "print(\"accuracy = \", end=\" \")\n",
        "knn_fit_predict_print(knn, train_reduced, train_labels, test_reduced, test_labels, label_names)\n",
        "\n",
        "print(\"\\nVariance Threshold = 20000\")\n",
        "knn = None\n",
        "knn = KNeighborsClassifier(n_neighbors = best_k_reduced_20k)\n",
        "print(\"accuracy = \", end=\" \")\n",
        "knn_fit_predict_print(knn, train_reduced_20k, train_labels, test_reduced_20k, test_labels, label_names)\n",
        "\n",
        "print(\"\\nScaled Trainset\")\n",
        "knn = None\n",
        "knn = KNeighborsClassifier(n_neighbors = best_k_scaled)\n",
        "print(\"accuracy = \", end=\" \")\n",
        "knn_fit_predict_print(knn, train_scaled, train_labels, test_scaled, test_labels, label_names)\n"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Variance\n",
            "accuracy =  0.6153846153846154\n",
            "\n",
            "Variance Threshold = 0.5\n",
            "accuracy =  0.6153846153846154\n",
            "\n",
            "Variance Threshold = 20000\n",
            "accuracy =  0.6153846153846154\n",
            "\n",
            "Scaled Trainset\n",
            "accuracy =  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-cTcuEQLo-m",
        "colab_type": "text"
      },
      "source": [
        "#### Comments on Pre-Processing results\n",
        "\n",
        "- Variance Threshold\n",
        "    - We see that there is no effect on the results of the kNN algorithm if we use pre-processing selection with VarianceThreshold Selector.\n",
        "    - You can see in the above cell that we tried with different values in the range (0.1 , 20000) and the results didn't change. \n",
        "    - Our data even though it had a small ratio of $\\frac{samples}{features}$, Variance Threshold didn't achieve anything. We conclude from this, that there were specific features that helped the estimator reach a conclusion fast, without needing the other features. \n",
        "- Standardization\n",
        "    - It seems that scaling the data is crucial for the classification since we have 100% accuracy on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZsOH-ub-xpU",
        "colab_type": "text"
      },
      "source": [
        "### Conclusion\n",
        "\n",
        "Since **we achieved 100% accuracy** on the test set, there is no need to perform any more transformations on the train and test set."
      ]
    }
  ]
}