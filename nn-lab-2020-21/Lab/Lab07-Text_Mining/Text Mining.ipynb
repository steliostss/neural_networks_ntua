{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Text Mining.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"QJNKuWwUYzsJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225336748,"user_tz":-120,"elapsed":14418,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"09f02afc-235b-4ac6-a82d-7b50515d7c25"},"source":["!pip install --upgrade scikit-learn\n","!pip install --upgrade numpy\n","!pip install --upgrade scipy\n","!pip install --upgrade nltk\n","!pip install --upgrade matplotlib\n","%matplotlib inline"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.23.2)\n","Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.5.4)\n","Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.19.4)\n","Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (2.1.0)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.17.0)\n","Requirement already up-to-date: numpy in /usr/local/lib/python3.6/dist-packages (1.19.4)\n","Requirement already up-to-date: scipy in /usr/local/lib/python3.6/dist-packages (1.5.4)\n","Requirement already satisfied, skipping upgrade: numpy>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.19.4)\n","Requirement already up-to-date: nltk in /usr/local/lib/python3.6/dist-packages (3.5)\n","Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from nltk) (2019.12.20)\n","Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk) (4.41.1)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from nltk) (7.1.2)\n","Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from nltk) (0.17.0)\n","Requirement already up-to-date: matplotlib in /usr/local/lib/python3.6/dist-packages (3.3.3)\n","Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n","Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n","Requirement already satisfied, skipping upgrade: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.19.4)\n","Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.3.1)\n","Requirement already satisfied, skipping upgrade: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (7.0.0)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"j3AJwwzFsa6f"},"source":["\n","# Εξόρυξη κειμένου (Text Mining)\n","\n","To Text Mining είναι ένα σύνολο αυτόματων (μηχανικών) τεχνικών που στοχεύουν στην εξαγωγή υψηλής ποιότητας πληροφορίας από κειμενική πληροφορία. Ο ασυμπτωτικός ορίζοντας του text mining είναι η συνολική σημασιολογική κατανόηση του ανθρώπινου λόγου, κάτι όμως που ανήκει στους δύσκολους στόχους της λεγόμενης **Ισχυρής Τεχνητής Νοημοσύνης** (*Strong AI*). Στο δρόμο για την επίτευξη αυτού του στόχου η έρευνα στο text mining επικεντρώνεται σε μια σειρά πιο συγκεκριμένων και άρα περισσότερο προσιτών στόχων - tasks (*Weak AI*) όπως (μεταξύ άλλων):\n","- **Κατηγοριοποίηση κειμένων** (*text categorization*) - Ταξινόμηση με βάση το περιεχόμενο σε συγκεκριμένες θεματικές κατηγορίες\n","- **Συσταδοποίηση** (*text clustering*) - Συσταδοποίηση \"κοντινών\" σημασιολογικά κειμένων\n","- **Εξαγωγή θεμάτων** (*topic extraction*) - Ανακάλυψη των θεμάτων που περιέχει ένα κείμενο\n","- **Εξαγωγή εννοιών και οντοτήτων** (*concept/entity extraction*) - Σε ποιες έννοιες και οντότητες του φυσικού κόσμου αναφέρεται το κείμενο.\n","- **Ανάλυση συναισθήματος** (*sentiment analysis*) - Χαρακτηρισμός του συναισθήματος\n","- **Αυτόματη περίληψη** (*document summarization*) - Δημιουργία αυτόματης περίληψης\n","- **Μοντελοποιηση σχέσεων μεταξύ οντοτήτων** (*entity relation modeling*) - Ποιες σχέσεις διέπουν τις οντότητες που εντοπίζονται εντός του κειμένου.\n","- **Απάντηση ερωτήσεων** *(question answering*) - απάντηση ερώτησης και τα δύο σε φυσική γλώσσα\n","\n","\n","Στην εξόρυξη κειμένου συνδυάζονται τεχνικές και προσεγγίσεις που προέρχονται από τη θεωρία της πληροφορίας και τη στατιστική, την αναγνώριση προτύπων, την εξόρυξη δεδομένων, τη μηχανική μάθηση, την ανάκτηση πληροφορίας, την επεξεργασία φυσικής γλώσσας (Natural Language Processing - NLP), τη γλωσσολογία, την αναπαράσταση γνώσεων, τις οντολογίες κ.α."]},{"cell_type":"markdown","metadata":{"id":"fmKJbF4UVJOL"},"source":["Για την εξόρυξη κειμένου και την επεξεργασία φυσικής γλώσσας θα βασιστούμε στο [Natural Language Toolkit](http://www.nltk.org/) της Python\n","\n","Περισσότερα θα δείτε στο [nltk book](http://www.nltk.org/book/)"]},{"cell_type":"code","metadata":{"id":"64d0RcciVJOM"},"source":["import numpy as np\n","import nltk"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a_RhBsaIVJOR"},"source":["## Εισαγωγή κειμένων στο notebook\n","\n","\n","Το NLTK από μόνο του έχει μόνο τις πολύ βασικές λειτουργίες. Για πιο σύνθετα πράγματα (τα οποία θα χρειαστούμε) χρειάζεται να κατεβάσουμε επιπλέον δυνατότητες της βιβλιοθήκης. Όταν τρέχουμε τοπικά την Python, αυτό μπορούμε να το κάνουμε μέσω της εντολής `nltk.download()`, η οποία ανοίγει ένα παράθυρο όπου επιλέγουμε ποιες λειτουργίες μας ενδιαφέρει να κατεβάσουμε. Σε κάποιες cloud πλατφόρμες αυτό δεν είναι δυνατό, γι' αυτό πρέπει να τα κατεβάζουμε ένα ένα τα επιπλέον πακέτα, όπως θα δούμε παρακάτω."]},{"cell_type":"markdown","metadata":{"id":"yoaSYPnWoL5C"},"source":["\n","\n","### Από βιβλιοθήκες της Python\n","\n","Στα πλαίσια της άσκησης θα χρησιμοποιήσουμε το [reuters dataset](https://archive.ics.uci.edu/ml/datasets/reuters-21578+text+categorization+collection). \n","\n","Το σώμα (corpus) κειμένων Reuters περιέχει 10788 κείμενα ειδήσεων. Κάθε κείμενο (document) ανήκει σε μία ή περισσότερες από 90 θεματικές κατηγορίες ειδήσεων που έχουν να κάνουν κυρίως με εμπορικά και χρηματιστηριακά αγαθά και υπηρεσίες (πχ \"fuel\", \"cotton\", \"ship\" κλπ). To Reuters είναι ήδη χωρισμένο σε train και test set.\n","Μπορούμε να εισάγουμε το Reuters μέσω του NLTK:\n"]},{"cell_type":"code","metadata":{"id":"RWZXceaPVJOR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225336752,"user_tz":-120,"elapsed":14405,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"be59c386-abab-498b-8e9d-b2b8430195a5"},"source":["nltk.download('reuters') # κατεβάζουμε το dataset\n","\n","from nltk.corpus import reuters # το κάνουμε import\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package reuters to /root/nltk_data...\n","[nltk_data]   Package reuters is already up-to-date!\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"MK0sHMNDc9Br"},"source":["\n","και τυπώνουμε κάποια βασικά χαρακτηριστικά:\n","\n"]},{"cell_type":"code","metadata":{"id":"Yp4tsAJLclo6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225336754,"user_tz":-120,"elapsed":14398,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"194dd4a2-b05b-43e1-bff1-2d1743507e2a"},"source":["def collection_stats():\n","    # List of documents\n","    documents = reuters.fileids()\n","    print(str(len(documents)) + \" documents\");\n"," \n","    train_docs = list(filter(lambda doc: doc.startswith(\"train\"),\n","                        documents));\n","    print(str(len(train_docs)) + \" total train documents\");\n"," \n","    test_docs = list(filter(lambda doc: doc.startswith(\"test\"),\n","                       documents));\n","    print(str(len(test_docs)) + \" total test documents\");\n"," \n","    # List of categories\n","    categories = reuters.categories();\n","    print(str(len(categories)) + \" categories\");\n","\n","collection_stats()\n","print(reuters.categories()[:20], '...')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["10788 documents\n","7769 total train documents\n","3019 total test documents\n","90 categories\n","['acq', 'alum', 'barley', 'bop', 'carcass', 'castor-oil', 'cocoa', 'coconut', 'coconut-oil', 'coffee', 'copper', 'copra-cake', 'corn', 'cotton', 'cotton-oil', 'cpi', 'cpu', 'crude', 'dfl', 'dlr'] ...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"T_qroRjPbhcS"},"source":["Για ένα τυχαίο document μπορούμε να δούμε τις κατηγορίες που ανήκει και το ίδιο το κείμενο χρησιμοποιώντας το id του:"]},{"cell_type":"code","metadata":{"id":"TtI_Oqxsb8uJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225336755,"user_tz":-120,"elapsed":14390,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"eb39a93f-f80b-4b05-9202-b28857f2baef"},"source":["def describe_doc(document_id):\n","    # Raw categories\n","    print(\"Categories\")\n","    doc_categories = reuters.categories(document_id) \n","    print(doc_categories)\n","    # Raw document\n","    print(\"Document\")\n","    print(reuters.raw(document_id));\n","\n","doc_id = 'training/9880'\n","describe_doc(doc_id)\n","doc_id = 'training/9865'\n","describe_doc(doc_id)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Categories\n","['money-fx']\n","Document\n","U.K. MONEY MARKET GETS 25 MLN STG LATE HELP\n","  The Bank of England said it provided\n","  about 25 mln stg in late help to the money market, bringing the\n","  total assistance today to 266 mln stg.\n","      This compares with the bank's revised estimate of a 350 mln\n","  stg money market shortfall.\n","  \n","\n","\n","Categories\n","['barley', 'corn', 'grain', 'wheat']\n","Document\n","FRENCH FREE MARKET CEREAL EXPORT BIDS DETAILED\n","  French operators have requested licences\n","  to export 675,500 tonnes of maize, 245,000 tonnes of barley,\n","  22,000 tonnes of soft bread wheat and 20,000 tonnes of feed\n","  wheat at today's European Community tender, traders said.\n","      Rebates requested ranged from 127.75 to 132.50 European\n","  Currency Units a tonne for maize, 136.00 to 141.00 Ecus a tonne\n","  for barley and 134.25 to 141.81 Ecus for bread wheat, while\n","  rebates requested for feed wheat were 137.65 Ecus, they said.\n","  \n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yqg9kYW7moPW"},"source":["Το Reuters χρησιμοποιείται συχνά για την μελέτη της απόδοσης αλγορίθμων Μηχανικής Μάθησης στην κατηγοριοποίηση ή ομάδοποιήση κειμένων."]},{"cell_type":"markdown","metadata":{"id":"kcNsEV60VJOd"},"source":["### Από το internet\n","\n","Σημείωση: Ο παρακάτω κώδικας δεν θα τρέξει στο περιβάλλον του Microsoft Azure. Ο λόγος είναι ότι το Azure δεν επιτρέπει την πρόσβαση σε εξωτερικά URLs για να αποφύγει τη χρήση των notebooks σε denial of service (DoS) attacks. Μπορείτε να τον τρέξετε τοπικά στον υπολογιστή σας."]},{"cell_type":"code","metadata":{"id":"cMLHmozBVJOe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225336757,"user_tz":-120,"elapsed":14383,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"991bcbf7-0bf4-442e-aca9-918cc7e6d2ee"},"source":["import urllib\n","\n","# ορίζουμε το url που περιέχει το κείμενο (εδώ το Moby Dick)\n","url = 'https://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg/2/7/0/2701/2701-0.txt'\n","\n","with urllib.request.urlopen(url) as response:\n","   raw = response.read()\n","\n","#τυπώνουμε ένα κομμάτι του κειμένου\n","text_chunk=raw[10000:11000]\n","print(text_chunk)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["b's, and perisheth in the\\r\\n  bottomless gulf of his paunch.\\xe2\\x80\\x9d \\xe2\\x80\\x94_Holland\\xe2\\x80\\x99s Plutarch\\xe2\\x80\\x99s Morals_.\\r\\n\\r\\n  \\xe2\\x80\\x9cThe Indian Sea breedeth the most and the biggest fishes that are:\\r\\n  among which the Whales and Whirlpooles called Balaene, take up as\\r\\n  much in length as four acres or arpens of land.\\xe2\\x80\\x9d \\xe2\\x80\\x94_Holland\\xe2\\x80\\x99s Pliny_.\\r\\n\\r\\n  \\xe2\\x80\\x9cScarcely had we proceeded two days on the sea, when about sunrise a\\r\\n  great many Whales and other monsters of the sea, appeared. Among the\\r\\n  former, one was of a most monstrous size.... This came towards us,\\r\\n  open-mouthed, raising the waves on all sides, and beating the sea\\r\\n  before him into a foam.\\xe2\\x80\\x9d \\xe2\\x80\\x94_Tooke\\xe2\\x80\\x99s Lucian_. \\xe2\\x80\\x9c_The True History_.\\xe2\\x80\\x9d\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n  \\xe2\\x80\\x9cHe visited this country also with a view of catching horse-whales,\\r\\n  which had bones of very great value for their teeth, of which he\\r\\n  brought some to the king.... The best whales were catched in his own\\r\\n  country, of which some were forty-eight, some fifty yards long. He\\r\\n  said that he was one'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sOIlekSrk7W4"},"source":["Το κείμενο είναι σε κωδικοποίηση Unicode UTF-8. Θα το μετατρέψουμε σε εκτυπώσιμους χαρακτήρες."]},{"cell_type":"code","metadata":{"id":"lKb1lugrj9qU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225336757,"user_tz":-120,"elapsed":14375,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"f762bc1d-7021-4fcf-ead6-52243c5a3b1d"},"source":["s = text_chunk.decode('utf-8')\n","print(s)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["s, and perisheth in the\r\n","  bottomless gulf of his paunch.” —_Holland’s Plutarch’s Morals_.\r\n","\r\n","  “The Indian Sea breedeth the most and the biggest fishes that are:\r\n","  among which the Whales and Whirlpooles called Balaene, take up as\r\n","  much in length as four acres or arpens of land.” —_Holland’s Pliny_.\r\n","\r\n","  “Scarcely had we proceeded two days on the sea, when about sunrise a\r\n","  great many Whales and other monsters of the sea, appeared. Among the\r\n","  former, one was of a most monstrous size.... This came towards us,\r\n","  open-mouthed, raising the waves on all sides, and beating the sea\r\n","  before him into a foam.” —_Tooke’s Lucian_. “_The True History_.”\r\n","\r\n","\r\n","\r\n","\r\n","  “He visited this country also with a view of catching horse-whales,\r\n","  which had bones of very great value for their teeth, of which he\r\n","  brought some to the king.... The best whales were catched in his own\r\n","  country, of which some were forty-eight, some fifty yards long. He\r\n","  said that he was one\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EKDKy_NMVJOh"},"source":["### Από τοπικό αρχείο \n","\n","Έστω ότι έχω ένα αρχείο στον υπολογιστή μου με όνομα `mydoc.txt`. Αυτό πρέπει πρώτα να το ανεβάσουμε στο περιβάλλον του notebook. Γενικά αυτή η διαδικασία διαφέρει από cloud σε cloud, οπότε ο παρακάτω κώδικας θα τρέξει μόνο σε περιβάλλον Google Colaboratory. Αντίστοιχες διαδικασίες ανεβάσματος αρχείου από τον τοπικό υπολογιστή υπάρχουν και για τα υπόλοιπα cloud που έχουμε δείξει."]},{"cell_type":"code","metadata":{"id":"drJ5uCxVnZDp","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":91},"executionInfo":{"status":"ok","timestamp":1606225345366,"user_tz":-120,"elapsed":22973,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"25b280f4-7b31-4eb5-b4e7-76bdfb79cd76"},"source":["from google.colab import files\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-3645c187-9df2-48d8-b9ab-5de4d141ca46\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-3645c187-9df2-48d8-b9ab-5de4d141ca46\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving mydoc.txt to mydoc (1).txt\n","User uploaded file \"mydoc.txt\" with length 1042 bytes\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NzYTrrzBndhX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225352163,"user_tz":-120,"elapsed":1340,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"9fb5c4a7-728f-4b7e-fc5d-56e0a87acfb9"},"source":["!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["'mydoc (1).txt'   mydoc.txt   sample_data\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Oo4gforhnyHw"},"source":["Διαβάζω το περιεχόμενο του αρχείο μέσα στο string \"document\""]},{"cell_type":"code","metadata":{"id":"uJQ97LXDVJOp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225345369,"user_tz":-120,"elapsed":22959,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"03ea98b2-562a-4418-eeaf-bd84e0eb270a"},"source":["with open('mydoc.txt', 'r') as f:\n","    document = ''\n","    for line in f:\n","        document += line\n","\n","print(document)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Commerce Secretary Malcolm Baldrige\n","said he supported efforts to persuade newly-industrialized\n","countries (NICS) to revalue currencies that are tied to the\n","dollar in order to help the United States cut its massive trade\n","deficit.\n","    \"We do need to do something with those currencies or we\n","will be substituting Japanese products for Taiwanese products,\"\n","or those of other nations with currencies tied to the dollar,\n","Baldrige told a House banking subcommittee.\n","    The U.S. dollar has declined in value against the Yen and\n","European currencies, but has changed very little against the\n","currencies of some developing countries such as South Korea and\n","Taiwan because they are linked to the value of the dollar.\n","    As a result, efforts to reduce the value of the dollar over\n","the past year and a half have done little to improve the trade\n","deficits with those countries.\n","    Baldrige told a House Banking subcommittee that the\n","Treasury Department was attempting to persuade those countries\n","to reach agreement with the United States on exchange rates.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XnlcPw_ivn_p"},"source":["## Μοντέλο διανυσματικού χώρου (Vector Space Model)\n","\n","Ως σημείο εκκίνησης λαμβάνουμε ότι διαθέτουμε μια συλλογή από κείμενα (αρχεία text) και ότι οι αλγόριθμοι μηχανικής μάθησης που χρησιμοποιούμε λαμβάνουν στην είσοδο αριθμητικές τιμές (διανύσματα). Ένα πρώτο και πολύ βασικό ερώτημα λοιπόν είναι πως μπορούμε να μετατρέψουμε τα κείμενα σε κατάλληλη διανυσματική μορφή. Τί θα αποτελούσε όμως \"κατάλληλη διανυσματική μορφή\";\n","\n","Μια απάντηση που μπορούμε να δώσουμε από την υπολογιστική σκοπιά είναι ότι αν κάθε κείμενο της συλλογής μετατραπεί σε ένα διάνυσμα, θα θέλαμε η μετατροπή αυτή να κρατήσει τη σημασιολογική πληροφορία των κειμένων έτσι ώστε κείμενα που το κειμενικό τους περιεχόμενο είναι σημασιολογικά \"κοντινό\" (μιλάνε για κοντινά θέματα) να αντιστοιχούν σε σημεία του διανυσματικού χώρου αναπαράστασης που είναι κοντά μεταξύ τους και το αντίστροφο για κείμενα με ανόμοιο περιεχόμενο.\n"]},{"cell_type":"markdown","metadata":{"id":"vOY46Yu_B0Cu"},"source":["\n","### Σάκος λέξεων (bag of words)\n","\n","Ας θεωρήσουμε χωρίς βλάβη της γενικότητας την ακόλουθη μικρή συλλογή κειμένων (documents): \n","\n","d1 = \"a big black cat\"\n","\n","d2 = \"a cat and a dog\"\n","\n","d3 = \"a lovely town\"\n","\n","Τα d1 και d2 έχουν μεταξύ τους κοινό σημασιολογικό περιεχόμενο και δεν έχουν με το d3. Κατασκευάζουμε ένα διάνυσμα του οποίου κάθε χαρακτηριστικό είναι κάθε μοναδική λέξη της συλλογής μας σε αλφαβητική σειρά δηλαδή:\n","\n","\\[ a and big black cat dog lovely town \\]\n","\n","Με βάση αυτό τα 8 χαρακτηριστικά τώρα, αναπαριστούμε κάθε document με ένα διάνυσμα όπου τα χαρακτηριστικά λαμβάνουν τιμές ίσες με τη συχνότητα εμφάνισης της κάθε λέξης (term frequency) στο συγκεκριμένο document: \n","\n","d1 = \\[ 1 0 1 1 1 0 0 0 \\]\n","\n","d2 = \\[ 2 1 0 0 1 1 0 0 \\]\n","\n","d3 = \\[ 1 0 0 0 0 0 1 1 \\]\n","\n","Αυτή είναι το βασικό μοντέλο (αναπαράστασης) διανυσματικού χώρου που χρησιμοποιεί τις συχνότητες εμφάνισης κάθε λέξης. Εξαιτίας του γεγονότος ότι αγνοούμε τη σειρά των λέξεων (το \"a big black cat\" έχει την ίδια διανυσματική αναπαράσταση με το \"cat big a black\") το ονομάζουμε σάκο λέξεων - bag of words (BOW). \n","\n","Ας τα περάσουμε στο numpy και να δοκιμάσουμε να υπολογίσουμε αποστάσεις μεταξύ διανυσμάτων:"]},{"cell_type":"code","metadata":{"id":"9CIQMyt4Gv6q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225345370,"user_tz":-120,"elapsed":22952,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"d95b4f69-b201-445d-8317-f031cf191f7a"},"source":["d1 = np.array([1,0,1,1,1,0,0,0])\n","d2 = np.array([2,1,0,0,1,1,0,0])\n","d3 = np.array([1,0,0,0,0,0,1,1])\n","\n","#Ευκλείδεια απόσταση\n","\n","d1d2 = print(\"d1 με d2\", np.linalg.norm(d1-d2))\n","d1d3 = print(\"d1 με d3\", np.linalg.norm(d1-d3))\n","d2d3 = print(\"d2 με d3\", np.linalg.norm(d2-d3))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["d1 με d2 2.23606797749979\n","d1 με d3 2.23606797749979\n","d2 με d3 2.449489742783178\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7pScjhAZJMTM"},"source":["Συνεπώς βλέπουμε ότι ακόμα δεν έχουμε πετύχει αυτό που θέσαμε ως αρχικό στόχο, τα d1 και d2 να είναι πιο κοντά μεταξύ τους απ' ότι είνα με το d3. Στην πράξη δεν χρησιμοποιούμε την ευκλείδεια απόσταση γιατί για παράδειγμα αν πάρουμε το\n","\n","d4 = \"a big black cat a big black cat\"\n","\n","που δεν έχει καμία σημασιολογική μονάδα πληροφορίας (λέξη) διαφορετική από το d1 (και άρα θα έπρεπε να έχει απόσταση 0) το οποίο έχει  διανυσματική αναπαράσταση το διπλάσιο του d1\n","\n","d4 = \\[ 2 0 2 2 2 0 0 0 \\]\n","\n","Με ευκλείδεια απόσταση θα λάβουμε:"]},{"cell_type":"code","metadata":{"id":"HlsolnvpLSBs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225345371,"user_tz":-120,"elapsed":22947,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"c98431c8-9137-4bbd-cb9c-08a9e82d3a90"},"source":["d4 = np.array([2,0,2,2,2,0,0,0])\n","d1d4 = print(\"d1 με d4\", np.linalg.norm(d1-d4))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["d1 με d4 2.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Z6Zh4ryILpPP"},"source":["### Ομοιότητα συνημιτόνόυ (cosine similarity)\n","\n","Για το λόγο αυτό, στο Vector Space Model χρησιμοποιούμε την απόσταση (ή ομοιότητα) συνημιτόνου (cosine similarity): \n","\n","$ {\\text{similarity}}=\\cos(\\theta )={\\mathbf {A} \\cdot \\mathbf {B}  \\over \\|\\mathbf {A} \\|\\|\\mathbf {B} \\|}={\\frac {\\sum \\limits _{i=1}^{n}{A_{i}B_{i}}}{{\\sqrt {\\sum \\limits _{i=1}^{n}{A_{i}^{2}}}}{\\sqrt {\\sum \\limits _{i=1}^{n}{B_{i}^{2}}}}}}$\n"]},{"cell_type":"code","metadata":{"id":"FcoNf4CeL9Wy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225345371,"user_tz":-120,"elapsed":22940,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"099aee5a-e1cb-4a50-8470-bc421193674b"},"source":["import scipy as sp\n","\n","cosd1d4 = sp.spatial.distance.cosine(d1, d4)\n","print(cosd1d4)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ap8y7fDKMW3a"},"source":["και αντίστοιχα:"]},{"cell_type":"code","metadata":{"id":"Jn5n6KSsMav0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225345372,"user_tz":-120,"elapsed":22934,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"76de4491-cd22-40ec-f8b1-23ecbdc99840"},"source":["cosd1d2 = sp.spatial.distance.cosine(d1, d2)\n","cosd1d3 = sp.spatial.distance.cosine(d1, d3)\n","cosd2d3 = sp.spatial.distance.cosine(d2, d3)\n","\n","print(\"d1 με d2\", cosd1d2)\n","print(\"d1 με d3\", cosd1d3)\n","print(\"d2 με d3\", cosd2d3)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["d1 με d2 0.43305329048615915\n","d1 με d3 0.7113248654051871\n","d2 με d3 0.5635642195280153\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IYdHyGzqN1ak"},"source":["Η ομοιότητα (απόσταση) συνημιτόνου κανονικοποιεί με βάση τις νόρμες (μήκος) των κειμένων (άρα δεν έχουμε διανύσματα διαφορετικών μηκών) και είναι 1 (0) για διανύσματα που έχουν ακριβώς την ίδια \"γωνία\" στον υπερχώρο διαστάσεων Ν (o αριθμός των μοναδικών λέξεων) του vector space model.\n","\n","<!-- http://blog.christianperone.com/wp-content/uploads/2013/09/vector_space.png -->\n","![Imgur](https://i.imgur.com/Kl6MFc8.png)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"frHOFj8VoYui"},"source":["## Μετατροπή κειμένων σε διανύσματα\n"]},{"cell_type":"markdown","metadata":{"id":"HSn9R6mUPWKT"},"source":["Στη συνέχεια παρουσιάζουμε μερικά κλασικά βήματα που χρησιμοποιούμε για τη μετατροπή των κειμένων σε διανύσματα στο VSM. Τα βήματα αυτά περιλαμβάνουν κάποιες βελτιώσεις σε σχέση με το βασικό μοντέλο.\n","\n","Επειδή αν έχουμε μια μεγάλη συλλογή κειμένων το να λάβουμε όλες τις μοναδικές λέξεις ως χαρακτηριστικά του VSM μπορεί να οδηγήσει σε πάρα πολύ μεγάλες διαστάσεις, είναι βασικό μας μέλημα να χρησιμοποιούμε διάφορες τεχνικές ώστε να περιορίζουμε όσο είναι δυνατό αυτή τη διαστατικότητα χωρίς να χάνουμε περιεχόμενο (σημασία). "]},{"cell_type":"markdown","metadata":{"id":"xrbaAeBTVJOu"},"source":["### Προεπεξεργασία κειμένου\n","\n","Τώρα που φορτώσαμε το κείμενο στην python, πρέπει να το επεξεργαστούμε. Επειδή ο υπολογιστής θεωρεί τα κεφαλαία και τα μικρά ως διαφορετικούς χαρακτήρες, το πρώτο πράγμα που πρέπει να κάνουμε είναι να τα κάνουμε **όλα πεζά**. Έπειτα θέλουμε να **χωρίσουμε τις λέξεις μια προς μια**, ώστε να φτιάξουμε μια λίστα τα στοιχεία της οποίας θα είναι οι λέξεις."]},{"cell_type":"code","metadata":{"id":"EQV7lIyYVJOu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225345373,"user_tz":-120,"elapsed":22930,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"97b035fe-1400-4e30-a3b5-0c9c21292cf3"},"source":["documents = [\"Lionel Messi is the best football player in the world! Messi plays for Barcelona Football Club. Barcelona Football Club plays in the Spanish Primera Division.\",\n","            \"Lionel Messi a football player, playing for Barcelona Football Club, a Spanish football team.\", \n","            \"Barcelona is a city in a northern spanish province called Catalonia. It is the largest city in Catalonia and the second most populated spanish city.\", \n","            \"Python is a programming language. Python is an object-oriented programming language. Unlike COBOL, Python is a interpreted programming language.\", \n","            \"COBOL is a compiled computer programming language designed for business use. This programming language is imperative, procedural and, since 2002, object-oriented. But Python is better.\"]\n","\n","document = documents[1]\n","\n","nltk.download('punkt') # χρειάζεται για το tokenizer\n","words = nltk.word_tokenize(document)\n","\n","print(words)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['Lionel', 'Messi', 'a', 'football', 'player', ',', 'playing', 'for', 'Barcelona', 'Football', 'Club', ',', 'a', 'Spanish', 'football', 'team', '.']\n"],"name":"stdout"},{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"6LhkTcBnVJOy"},"source":["Το tokenizer ουσιαστικά κάνει ό,τι και η built-in μέθοδος `.split()` των string, αλλά λίγο πιο έξυπνα. Για αρχή χωρίζει με βάση τόσο τα κενά (`' '`), όσο και τα tabs (`'\\t'`) και τα new lines (`'\\n'`). Επίσης όπως μπορούμε να δούμε και παραπάνω χωρίζει και τις παρενθέσεις από το περιεχόμενό τους.\n","\n","Το επόμενο βήμα είναι να διαγράψουμε από τη λίστα μας τα **σημεία στίξης**. Μόλις το κάνουμε αυτό, θέλουμε να διαγράψουμε και μερικές συχνά χρησιμοποιούμενες λέξεις που δεν προσφέρουν σημασιολογική αξία στο κείμενο (**stopwords**).  Τυπικά stopwotds στα αγγλικά είναι λέξεις όπως \"the\", \"a\", \"to\", \"and\", \"he\", \"she\" κοκ."]},{"cell_type":"code","metadata":{"id":"p6pypWyaVJOz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225345373,"user_tz":-120,"elapsed":22924,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"bec60a38-9f4a-46c0-dad5-1ec9f5bf9907"},"source":["nltk.download('stopwords') # κατεβάζουμε ένα αρχείο που έχει stopwords στα αγγλικά\n","from nltk.corpus import stopwords\n","import string\n","\n","'''\n","filtered_words = [word for word in words if word not in list(string.punctuation)] # το string.punctuation είναι απλά ένα\n","                                                                                  # string που περιέχει όλα τα σημεία στίξης\n","\n","filtered_words = [word for word in filtered_words if word not in stopwords.words('english')] # το stopwords.words('english')\n","                                                                                             # είναι μια λίστα που περιέχει\n","                                                                                             # stopwords στα αγγλικά\n","'''\n","filtered_words = [word for word in words if word not in stopwords.words('english') + list(string.punctuation)]\n","\n","print(filtered_words)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['Lionel', 'Messi', 'football', 'player', 'playing', 'Barcelona', 'Football', 'Club', 'Spanish', 'football', 'team']\n"],"name":"stdout"},{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"BlSuSAUzVJO3"},"source":["Πρέπει να κάνουμε καλύτερη δουλειά στην αφαίρεση των σημείων στίξης γιατί δεν αφαιρούνται οι λέξεις που περιέχουν περισσότερα από ένα τέτοια σημεία."]},{"cell_type":"code","metadata":{"id":"VcLJukuIVJO4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225345374,"user_tz":-120,"elapsed":22920,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"ed152cc2-093b-4bba-fca9-2c14c8bc9b06"},"source":["def thorough_filter(words):\n","    filtered_words = []\n","    for word in words:\n","        pun = []\n","        for letter in word:\n","            pun.append(letter in string.punctuation)\n","        if not all(pun):\n","            filtered_words.append(word)\n","    return filtered_words\n","        \n","filtered_words = thorough_filter(filtered_words)\n","print(filtered_words)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['Lionel', 'Messi', 'football', 'player', 'playing', 'Barcelona', 'Football', 'Club', 'Spanish', 'football', 'team']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WCySdKVxVJO9"},"source":["### Stemming & Lemmatization\n","\n","Για γραμματικούς λόγους, τα κείμενα χρησιμοποιούν διαφορετικές μορφές μιας λέξης, όπως π.χ. *play*, *plays*, *playing*, *played*. Αυτό έχει σαν αποτέλεσμα πως, ενώ αναφερόμαστε σε κάποιο παρόμοιο σημασιολογικό περιεχόμενο, ο υπολογιστής τις καταλαβαίνει ως διαφορετικές και προσθέτει διαστάσεις στην αναπαράσταση. Για να λύσουμε αυτό το πρόβλημα, μπορούμε να χρησιμοποιήσουμε δύο γλωσσολογικούς μετασχηματισμούς, είτε την αφαίρεση της κατάληξης (stemming), είτε τη λημματοποίηση (lemmatization). Ο στόχος, τόσο της αφαίρεσης κατάληξης όσο και της λημματοποίησης, είναι να φέρουν τις διάφορες μορφές της λέξης σε μια κοινή μορφή βάσης. Πιο συγκεκριμένα:\n","\n","Η **αφαίρεση της κατάληξης** αναφέρεται σε μια ακατέργαστη ευριστική διαδικασία που απομακρύνει τα άκρα των λέξεων με την ελπίδα να επιτύχει αυτό το στόχο σωστά τις περισσότερες φορές.\n","\n","Η **λημματοποίηση** αναφέρεται στην απομάκρυνση της κλίσης των λέξεων και στην επιστροφή της μορφής της λέξης όπως θα τη βρίσκαμε στο λεξικό, με τη χρήση λεξιλογίου και μορφολογικής ανάλυσης των λέξεων. Η μορφή αυτή είναι γνωστή ως λήμμα (*lemma*)."]},{"cell_type":"code","metadata":{"id":"bTe8-vDgVJO-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225346419,"user_tz":-120,"elapsed":23959,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"299f0bf2-7e55-42e0-d612-316d7dd35efb"},"source":["nltk.download('wordnet') # απαραίτητα download για τους stemmer/lemmatizer\n","nltk.download('rslp')\n","\n","from nltk.stem import WordNetLemmatizer\n","wordnet_lemmatizer = WordNetLemmatizer()\n","\n","from nltk.stem.porter import PorterStemmer\n","porter_stemmer = PorterStemmer()\n","\n","lem_words = [wordnet_lemmatizer.lemmatize(word) for word in filtered_words]\n","stem_words = [porter_stemmer.stem(word) for word in filtered_words]\n","\n","print('\\n{:<20} {:<20} {:<20}'.format('Original', 'Stemmed', 'Lemmatized'))\n","print('-'*60)\n","for i in range(len(filtered_words)):\n","    print('{:<20} {:<20} {:<20}'.format(filtered_words[i], stem_words[i], lem_words[i]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Original             Stemmed              Lemmatized          \n","------------------------------------------------------------\n","Lionel               lionel               Lionel              \n","Messi                messi                Messi               \n","football             footbal              football            \n","player               player               player              \n","playing              play                 playing             \n","Barcelona            barcelona            Barcelona           \n","Football             footbal              Football            \n","Club                 club                 Club                \n","Spanish              spanish              Spanish             \n","football             footbal              football            \n","team                 team                 team                \n"],"name":"stdout"},{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package rslp to /root/nltk_data...\n","[nltk_data]   Package rslp is already up-to-date!\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"3828s8RpVJPB"},"source":["**Προσοχή:** χρησιμοποιούμε είτε stemming (πιο συχνά), είτε lemmatization, αλλά όχι και τα δύο μαζί. Το πρώτο βελτιώνει την ανάκληση, το δεύτερο την ακρίβεια.\n","\n","Αφότου έχουμε ολοκληρώσει τις γλωσσολογικές προεπεξεργασίες, θα ορίσουμε μια μικρή συλλογή κειμένων ώστε να προχωρήσουμε ένα παράδειγμα ομαδοποίησης  κειμένων. \n","\n","Όπως βλέπουμε παρακάτω τα πρώτα δύο και τα τελευταία δύο κείμενα βρίσκονται  σημασιολογικά κοντά μεταξύ τους."]},{"cell_type":"code","metadata":{"id":"hjhcVYkhVJPI"},"source":["# Το νέο σύνολο κειμένων μας\n","documents = [\"Lionel Messi is the best football player in the world! Messi plays for Barcelona Football Club. Barcelona Football Club plays in the Spanish Primera Division.\",\n","            \"Lionel Messi a football player, playing for Barcelona Football Club, a Spanish football team.\", \n","            \"Barcelona is a city in a northern spanish province called Catalonia. It is the largest city in Catalonia and the second most populated spanish city.\", \n","            \"Python is a programming language. Python is an object-oriented programming language. Unlike COBOL, Python is a interpreted programming language.\", \n","            \"COBOL is a compiled computer programming language designed for business use. This programming language is imperative, procedural and, since 2002, object-oriented. But Python is better.\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BhosxSZKUZaI"},"source":["Κάνουμε τη γνωστή μας προεπεξεργασία και τυπώνουμε τη συχνότητα κάθε token σε κάθε document."]},{"cell_type":"code","metadata":{"id":"j1_d_UMzTYrk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225346423,"user_tz":-120,"elapsed":23952,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"18749db7-0c48-4c20-cc0b-d45017267c94"},"source":["import collections\n","\n","def preprocess_document(document):\n","    # όλα τα προηγούμενα βήματα που κάναμε μέχρι στιγμής\n","    words = nltk.word_tokenize(document.lower())\n","    filtered_words = [word for word in words if word not in stopwords.words('english') + list(string.punctuation)]\n","    filtered_words = thorough_filter(filtered_words)\n","    stemmed_words = [porter_stemmer.stem(wordnet_lemmatizer.lemmatize(word)) for word in filtered_words]\n","    cnt = collections.Counter(stemmed_words)\n","    return cnt\n","\n","preprocessed_documents = [preprocess_document(doc) for doc in documents]\n","\n","for doc in preprocessed_documents:\n","    print(doc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Counter({'footbal': 3, 'messi': 2, 'play': 2, 'barcelona': 2, 'club': 2, 'lionel': 1, 'best': 1, 'player': 1, 'world': 1, 'spanish': 1, 'primera': 1, 'divis': 1})\n","Counter({'footbal': 3, 'lionel': 1, 'messi': 1, 'player': 1, 'play': 1, 'barcelona': 1, 'club': 1, 'spanish': 1, 'team': 1})\n","Counter({'citi': 3, 'spanish': 2, 'catalonia': 2, 'barcelona': 1, 'northern': 1, 'provinc': 1, 'call': 1, 'largest': 1, 'second': 1, 'popul': 1})\n","Counter({'python': 3, 'program': 3, 'languag': 3, 'object-ori': 1, 'unlik': 1, 'cobol': 1, 'interpret': 1})\n","Counter({'program': 2, 'languag': 2, 'cobol': 1, 'compil': 1, 'comput': 1, 'design': 1, 'busi': 1, 'use': 1, 'imper': 1, 'procedur': 1, 'sinc': 1, '2002': 1, 'object-ori': 1, 'python': 1, 'better': 1})\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"X-JniL0wVJPN"},"source":["Μια τυπική μέθοδος μείωσης της διασταστικότητας είναι να πετάμε τους πάρα πολύ συχνούς όρους, τους πάρα πολύ σπάνιους ή τους όρους που εμφανίζονται σε πολύ λίγα documents (μιλάμε πάντα για το σύνολο της συλλογής, όχι τα μεμονωμένα documents).\n","\n","Στο μικρό αυτό dataset αποφασίζουμε να πετάξουμε τους όρους που εμφανίζονται μόνο μία φορά στο σύνολο της συλλογής"]},{"cell_type":"code","metadata":{"id":"dMHIgFDBVJPP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225346425,"user_tz":-120,"elapsed":23948,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"e7528b14-42c0-46ba-839d-0c88639eb67b"},"source":["threshold = 1\n","\n","total_counter = preprocessed_documents[0]\n","for i in range(1, len(preprocessed_documents)):\n","    total_counter += preprocessed_documents[i] # counter που περιέχει τα συνολικά αθροίσματα σε όλα τα κείμενα\n","\n","print(total_counter, '\\n')\n","\n","vocabulary = [word for word in total_counter if total_counter[word] > threshold] # κρατάμε μόνο τους όρους με συχνότητα εμφάνισης πάνω από το κατώφλι\n","\n","print(vocabulary)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Counter({'footbal': 6, 'program': 5, 'languag': 5, 'barcelona': 4, 'spanish': 4, 'python': 4, 'messi': 3, 'play': 3, 'club': 3, 'citi': 3, 'lionel': 2, 'player': 2, 'catalonia': 2, 'object-ori': 2, 'cobol': 2, 'best': 1, 'world': 1, 'primera': 1, 'divis': 1, 'team': 1, 'northern': 1, 'provinc': 1, 'call': 1, 'largest': 1, 'second': 1, 'popul': 1, 'unlik': 1, 'interpret': 1, 'compil': 1, 'comput': 1, 'design': 1, 'busi': 1, 'use': 1, 'imper': 1, 'procedur': 1, 'sinc': 1, '2002': 1, 'better': 1}) \n","\n","['lionel', 'messi', 'footbal', 'player', 'play', 'barcelona', 'club', 'spanish', 'citi', 'catalonia', 'python', 'program', 'languag', 'object-ori', 'cobol']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yFY2a06iVJPR"},"source":["Για την ευκολία μας θα δημιουργήσουμε έναν πίνακα που στις γραμμές του θα έχει τα documents και στις στήλες του τις λέξεις και θα αποθηκεύσουμε μέσα σε αυτόν τον αριθμό εμφάνισης των όρων. "]},{"cell_type":"code","metadata":{"id":"pUIfU63sVJPS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225346430,"user_tz":-120,"elapsed":23947,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"504d124f-d8a4-44ec-fd91-3ca6ce1808d2"},"source":["freq_array = np.zeros((len(preprocessed_documents), len(vocabulary)))\n","\n","for i in range(len(preprocessed_documents)):\n","    for j in range(len(vocabulary)):\n","        freq_array[i,j] += preprocessed_documents[i][vocabulary[j]] \n","\n","print(vocabulary, '\\n')\n","print(freq_array)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['lionel', 'messi', 'footbal', 'player', 'play', 'barcelona', 'club', 'spanish', 'citi', 'catalonia', 'python', 'program', 'languag', 'object-ori', 'cobol'] \n","\n","[[2. 3. 6. 2. 3. 4. 3. 4. 3. 2. 4. 5. 5. 2. 2.]\n"," [1. 1. 3. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 1. 0. 2. 3. 2. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 3. 1. 1.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 2. 2. 1. 1.]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vmawczqZVJPW"},"source":["### TF-IDF\n","\n","Η αναπαράσταση στο VSM μόνο με τις συχνότητες εμφάνισης κάθε όρου δεν είναι βέλτιστη. Στην πράξη χρησιμοποιούμε το **TF-IDF** (Term Frequency - Inverse Document Frequency).\n","\n","Όπως προσδίδει και το όνομά του, το tf-idf αποτελείται από 2 όρους. Ο πρώτος είναι το **Term Frequency (TF)**:\n","\n","$$ tf(i,d) = \\frac{f(i,d)}{\\sum_{i} f(i,d)}$$\n","\n","Όπου *i* ο όρος στο κείμενο *d*. Το tf είναι στην ουσία η συχνότητα με την οποία εμφανίζεται ο κάθε όρος στο κείμενο. Λέξεις με μεγάλη συχνότητα είναι σημαντικότερες για το κείμενο από ό,τι λέξεις με μικρή."]},{"cell_type":"code","metadata":{"id":"YXLO-r_RVJPX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225346433,"user_tz":-120,"elapsed":23943,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"c066e518-9aac-4e35-b64d-367eca846c00"},"source":["print(freq_array.sum(axis=1)), '\\n' # ο αριθμός των όρων ανά κείμενο\n","\n","\n","for i in range(len(freq_array)):\n","    freq_array[i, :] = freq_array[i, :] / freq_array.sum(axis=1)[i] # Η συχνότητα του όρου (αριθμός εμφάνισης όρου / συνολικοί όροι στο κείμενο)\n","\n","print(freq_array)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[50. 10.  8. 11.  7.]\n","[[0.04       0.06       0.12       0.04       0.06       0.08\n","  0.06       0.08       0.06       0.04       0.08       0.1\n","  0.1        0.04       0.04      ]\n"," [0.1        0.1        0.3        0.1        0.1        0.1\n","  0.1        0.1        0.         0.         0.         0.\n","  0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.125\n","  0.         0.25       0.375      0.25       0.         0.\n","  0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.27272727 0.27272727\n","  0.27272727 0.09090909 0.09090909]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.14285714 0.28571429\n","  0.28571429 0.14285714 0.14285714]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"n-ft9F1eVJPa"},"source":["Ο δεύτερος όρος στο tf-idf είναι το **Inverse Document Frequency**:\n","\n","$$ idf(i) = log \\frac{N}{df(i)}$$\n","\n","Όπου *Ν* ο αριθμός των κειμένων και *df(i)* ο αριθμός των κειμένων στους οποίους εμφανίζεται ο όρος *i*. Το idf είναι ένας δείκτης της πληροφορίας που δίνει η κάθε λέξη. Αν η λέξη εμφανίζεται σε όλα τα κείμενα τότε αυτή δε δίνει καθόλου πληροφορία και το κλάσμα θα γίνει 1, άρα ο λογάριθμος θα μας δώσει την τιμή 0. Αντίθετα σε όσο πιο λίγα κείμενα εμφανίζεται η λέξη, τόσο πιο μεγάλη τιμή θα έχει το κλάσμα. "]},{"cell_type":"code","metadata":{"id":"YmsGVtFDVJPb"},"source":["non_zero_elements_per_row = np.zeros((len(freq_array[0])))\n","\n","for i in range(len(freq_array)):\n","    for j in range(len(freq_array[0])):\n","        if freq_array[i,j]>0.0:\n","            non_zero_elements_per_row[j] += 1\n","\n","#non_zero_elements_per_row = np.count_nonzero(freq_array, axis=0)\n","\n","idf = np.log10(float(len(freq_array))/non_zero_elements_per_row) # ο αριθμητής του κλάσματος είναι ο αριθμός των κειμένων μας \n","                                                                 # (ή ο αριθμός των γραμμών στον πίνακα freq_array)\n","                                                                 # η np.count_zero μετράει πόσα μη μηδενικά στοιχεία έχει ο πίνακας \n","                                                                 # (στην περίπτωσή μας ο παρονομαστής του κλάσματος του idf)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BhOpEdJ6VJPd"},"source":["Το tf-idf τελικά υπολογίζεται ως το γινόμενο των δύο όρων:\n","\n","$$ tfidf(i) = tf(i,d) \\cdot idf(i)$$"]},{"cell_type":"code","metadata":{"id":"oakbvK76VJPe","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225346437,"user_tz":-120,"elapsed":23934,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"0d20a2dc-02ae-4c7e-c6a9-50d7ec42983c"},"source":["tf_idf = freq_array * idf # το tf-idf είναι απλά το γινόμενο του tf με το idf\n","\n","print(tf_idf)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[0.0159176  0.0238764  0.0477528  0.0159176  0.0238764  0.0177479\n","  0.0238764  0.0177479  0.0238764  0.0159176  0.0177479  0.02218487\n","  0.02218487 0.00887395 0.00887395]\n"," [0.039794   0.039794   0.119382   0.039794   0.039794   0.02218487\n","  0.039794   0.02218487 0.         0.         0.         0.\n","  0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.02773109\n","  0.         0.05546219 0.1492275  0.099485   0.         0.\n","  0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.0605042  0.0605042\n","  0.0605042  0.02016807 0.02016807]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.03169268 0.06338536\n","  0.06338536 0.03169268 0.03169268]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eKCWHEfuVJPi"},"source":["Για να δούμε ποιο κείμενο βρίσκεται πιο κοντά στο άλλο, υπολογίζουμε απλά τις αποστάσεις του ενός διανύσματος απ' το άλλο."]},{"cell_type":"code","metadata":{"id":"QyW1IV6zVJPi","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225346438,"user_tz":-120,"elapsed":23929,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"30c61f50-55b3-479f-80a8-397db179e5fb"},"source":["distances = np.zeros((len(tf_idf), len(tf_idf)))\n","\n","import scipy as sp\n","for i in range(len(tf_idf)):\n","      for j in range(len(tf_idf)):\n","            distances[i,j]= sp.spatial.distance.cosine(tf_idf[i],tf_idf[j])\n","            #distances[i,j] = sum(np.abs(tf_idf[i] - tf_idf[j])) # το ίδιο με ευκλείδια, εδώ είναι λιγότερο κακή γιατί έχουμε κανονικοποιησει ως προς το μήκος\n","print(distances)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[0.         0.19019445 0.59448787 0.55963979 0.56477791]\n"," [0.19019445 0.         0.93608371 1.         1.        ]\n"," [0.59448787 0.93608371 0.         1.         1.        ]\n"," [0.55963979 1.         1.         0.         0.04818273]\n"," [0.56477791 1.         1.         0.04818273 0.        ]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N65CJy19VJPm"},"source":["Όπως παρατηρούμε τα πρώτα 2 και τα τελευταία 2 διανύσματα του πίνακα έχουν πολύ μικρή απόσταση (της τάξης του 0.1). Αντίθετα όλα τα υπόλοιπα έχουν απόσταση μεγαλύτερη από 0.5.\n"]},{"cell_type":"markdown","metadata":{"id":"w0T-s4Zx19cL"},"source":["## Εφαρμογή: Ομαδοποίηση κειμένων"]},{"cell_type":"markdown","metadata":{"id":"oWmjWb8H159y"},"source":["\n","### Ιεραρχικό Clustering\n","\n","Για την ομαδοποίηση των αρχείων θα δούμε έναν νέο τύπο αλγορίθμου ομαδοποίησης, τον **ιεραρχικό (hierarchical)**. Σε αντίθεση με τους centroid-based αλγορίθμους που είδαμε προηγουμένως (π.χ. k-means), οι ιεραρχικοί αλγόριθμοι χρησιμοποιούν τις αποστάσεις των σημείων για να ορίσουν μια ολόκληρη ιεραρχία από ομάδες στις οποίες ανήκουν τα δεδομένα. Για να το πραγματοποιήσουμε αυτό, θα χρησιμοποιήσουμε την [μέθοδο ελαχιστοποίησης της διασποράς του Ward](https://en.wikipedia.org/wiki/Ward%27s_method). Ο αλγόριθμος αυτός ψάχνει αναδρομικά να βρει το ζεύγος των cluster που αν τα ενώσουμε θα δώσει την ελάχιστη αύξηση στη συνολική εσωτερική διασπορά των cluster. (Σημ. εσωτερική διασπορά θεωρούμε τη διασπορά όλων των σημείων από το κέντρο του cluster και ορίζεται για κάθε cluster ξεχωριστά. Συνολική εσωτερική διασπορά θεωρούμε το άθροισμα όλων των εσωτερικών διασπορών για κάθε cluster).\n","\n","Αρχικά θεωρεί ότι το κάθε σημείο είναι κι από ένα cluster. Έπειτα ψάχνει να βρει ποιο ζεύγος σημείων, αν ενωθούν σε ένα cluster, θα οδηγήσουν στην ελάχιστη αύξηση της συνολικής εσωτερικής διασποράς. Προφανώς, στην περίπτωση αυτή θα είναι τα δύο πιο κοντινά σημεία. Η διαδικασία αυτή επαναλαμβάνεται μέχρις ότου να καταλήξουμε σε 2 ομάδες. \n","\n","Αυτό μπορεί να υλοποιηθεί πολύ απλά στο [scikit-learn](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html) στο προηγούμενο παράδειγμα με τις προτάσεις:"]},{"cell_type":"code","metadata":{"id":"0gzxgxaXVJPn","colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"status":"ok","timestamp":1606227332677,"user_tz":-120,"elapsed":945,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"d8896236-db46-48a7-9e39-41fdb8ef393b"},"source":["from scipy.cluster.hierarchy import dendrogram, linkage\n","Z = linkage(tf_idf, 'ward') # εκπαιδεύει τον αλγόριθμο\n","dendrogram(Z) # σχεδιάζει ένα δενδρόγραμμα με το αποτέλεσμα του ιεραρχικού αλγορίθμου\n","print"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function print>"]},"metadata":{"tags":[]},"execution_count":77},{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2092\u001b[0m         \u001b[0mhardcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2094\u001b[0;31m         \u001b[0mParameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2095\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2096\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m_get_renderer\u001b[0;34m(figure, print_method)\u001b[0m\n\u001b[1;32m   1558\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1560\u001b[0;31m             raise RuntimeError(f\"{print_method} did not call Figure.draw, so \"\n\u001b[0m\u001b[1;32m   1561\u001b[0m                                f\"no renderer is available\")\n\u001b[1;32m   1562\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0mpil_kwargs\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0mKeyword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0;34m'pnginfo'\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mpresent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mcompletely\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincluding\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;34m'Software'\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name '_png'"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"uGx-U97PVJPq"},"source":["Παρατηρούμε ότι οι προτάσεις που βρίσκονται κοντά μεταξύ τους καταλήγουν και σε κοινά cluster. Θα προσπαθήσουμε να εφαρμόσουμε την τεχνική αυτή και σε ένα πραγματικό πρόβλημα με αληθινά κείμενα.\n"]},{"cell_type":"markdown","metadata":{"id":"uHZHhc7iaZUi"},"source":["\n","### 20 Newsgroups dataset\n","\n","Ως πραγματικό παράδειγμα θα χρησιμοποιήσουμε το [20 Newsgroups](http://qwone.com/~jason/20Newsgroups/) dataset, το οποίο υπάρχει και μέσα στο [sklearn](http://scikit-learn.org/stable/datasets/twenty_newsgroups.html). Για το clustering θα χρησιμοποιήσουμε τον ιεραρχικό αλγόριθμο που μελετήσαμε προηγουμένως."]},{"cell_type":"code","metadata":{"id":"01oYTGVYVJPr"},"source":["from sklearn.datasets import fetch_20newsgroups\n","newsgroups = fetch_20newsgroups(subset='all')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G_PUNTJkcU90"},"source":["To 20 newsgroups είναι και αυτό ένα dataset για κατηγοριοποίηση ή ομαδοποίηση κειμένων. Τυπώνουμε τις κατηγορίες των κειμένων:"]},{"cell_type":"code","metadata":{"id":"hGjtK1xabZ1d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225346791,"user_tz":-120,"elapsed":24261,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"5efa022d-c551-46b4-d406-fdc620a92e4b"},"source":["print(newsgroups.target_names)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pquHlH5tVJPw"},"source":["Θα πάρουμε 3 κατηγορίες από το dataset αυτό και θα δημιουργήσουμε ένα corpus με τα πρώτα 5 κείμενα από κάθε κατηγορία. Για ευκολία θα επιλέξουμε 3 αρκετά ξεκάθαρες μεταξύ τους κατηγορίες."]},{"cell_type":"code","metadata":{"id":"Tq6P3Xd3VJPy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225347174,"user_tz":-120,"elapsed":24632,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"7d91a6a9-02bb-455f-9df4-fe1306633a32"},"source":["import functools\n","\n","categ = ['alt.atheism', 'comp.graphics', 'rec.sport.baseball']\n","data = functools.reduce(lambda x,y: x+y, [fetch_20newsgroups(categories=[x], remove=('headers', 'footers'))['data'][:5] for x in categ])\n","print('Input shape:', len(data), '\\n')\n","print(data[0][:1000])\n","print(\"-----\")\n","print(data[13][:1000])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input shape: 15 \n","\n","In <16BA7103C3.I3150101@dbstu1.rz.tu-bs.de> I3150101@dbstu1.rz.tu-bs.de (Benedikt Rosenau) writes:\n","\n",">In article <1993Apr5.091258.11830@monu6.cc.monash.edu.au>\n",">darice@yoyo.cc.monash.edu.au (Fred Rice) writes:\n","> \n",">(Deletion)\n",">>>>Of course people say what they think to be the religion, and that this\n",">>>>is not exactly the same coming from different people within the\n",">>>>religion.  There is nothing with there existing different perspectives\n",">>>>within the religion -- perhaps one can say that they tend to converge on\n",">>>>the truth.\n",">>\n",">>>My point is that they are doing a lot of harm on the way in the meantime.\n",">>>\n",">>>And that they converge is counterfactual, religions appear to split and\n",">>>diverge. Even when there might be a 'True Religion' at the core, the layers\n",">>>above determine what happens in practise, and they are quite inhumane\n",">>>usually.\n",">>>\n","> \n",">What you post then is supposed to be an answer, but I don't see what is has\n",">got to do with what I say.\n","> \n",">I will repeat it. Religions\n","-----\n","Disclaimer -- This is for fun.\n","\n","In my computerized baseball game, I keep track of a category called\n","\"stolen hits\", defined as a play made that \"an average fielder would not\n","make with average effort.\"  Using the 1992 Defensive Averages posted\n","by Sherri Nichols (Thanks Sherri!), I've figured out some defensive stats\n","for the second basemen. Hits Stolen have been redefined as \"Plays Kurt\n","Stillwell would not have made.\"\n","\n","OK, I realize that's unfair.  Kurt's probably the victim of pitching staff,\n","fluke shots, and a monster park factor.  But let's put it this way:  If we\n","replaced every second baseman in the NL with someone with Kurt's 57.6% out\n","making ability, how many extra hits would go by?\n","\n","To try and correlate it to reality a little more, I've calculated Net\n","Hits Stolen, based on the number of outs made compared to what a league\n","average fielder would make.  By the same method I've calculated Net Double\n","Plays, and Net Extra Bases (doubles and triples let by).\n","\n","Finally, I throw all this int\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UhkPMD3lVJP2"},"source":["Σημειώστε εδώ ότι με το να πετάμε τους πολύ σπάνιους όρους ξεφορτωνόμαστε διάφορα σπάνια strings όπως emails, τυπογραφικά λάθη, \"παράξενα\" σύμβολα κλπ\n","\n","\n","### TfidfVectorizer και μείωση της διαστατικότητας του VSM\n","\n","Για την προεπεξεργασία των αρχείων θα χρησιμοποιήσουμε τη συνάρτηση [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) του sklearn. Η συγκεκριμένη συνάρτηση έχει τη δυνατότητα να υποστηρίξει και όλη την [προεπεξεργασία](http://scikit-learn.org/stable/modules/feature_extraction.html#customizing-the-vectorizer-classes) που κάναμε προηγουμένως (stopwords, stemming, lematizing, κτλ). Επίσης δέχεται και πολλές επιπλέον παραμέτρους όπως την `max_df=x` η οποία αγνοεί τους όρους που εμφανίζονται σε ποσοστό `x` των κειμένων και πάνω  (δηλ. λέξεις πολύ συχνές στο συγκεκριμένο σύνολο κειμένων), και την `min_df=y` η οποία αγνοεί τους όρους οι οποίοι εμφανίζονται σε ποσοστό μικρότερο από `y` του συνόλου των κειμένων (δηλ. πολύ σπάνιοι όροι). Για το παρακάτω παράδειγμα δεν θα εφαρμόσουμε stemming ή lemmatizing καθώς δεν βοηθάει στη συγκεκριμένη περίπτωση."]},{"cell_type":"code","metadata":{"id":"eGUujy-TVJP3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225347564,"user_tz":-120,"elapsed":25011,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"850cde0f-cf94-4941-cdc3-348c995a42ac"},"source":["import matplotlib.pyplot as plt\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","print(\"Dimensions before optimizing TfidfVectorizer parameters\")\n","vectorizer = TfidfVectorizer()\n","tf_idf_array = vectorizer.fit_transform(data).toarray() # επιστρέφει sparse matrix, γι'αυτό το κάνουμε .toarray()\n","print('TF-IDF array shape:', tf_idf_array.shape)\n","\n","print(\"Dimensions after optimizing TfidfVectorizer parameters\")\n","vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, stop_words='english')\n","tf_idf_array = vectorizer.fit_transform(data).toarray() # επιστρέφει sparse matrix, γι'αυτό το κάνουμε .toarray()\n","print('TF-IDF array shape:', tf_idf_array.shape)\n","Z = linkage(tf_idf_array, 'ward')\n","\n","labels = ['a'] * 5 + ['g'] * 5 + ['b'] * 5 # 'a' = atheism, 'g' = graphics, 'b' = baseball \n","\n","dendrogram(Z, labels=labels, color_threshold=0)\n","\n","colors = {'a':'r', 'g':'g', 'b':'b'}\n","for l in plt.gca().get_xticklabels():\n","    l.set_color(colors[l.get_text()])\n","print"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Dimensions before optimizing TfidfVectorizer parameters\n","TF-IDF array shape: (15, 1232)\n","Dimensions after optimizing TfidfVectorizer parameters\n","TF-IDF array shape: (15, 124)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<function print>"]},"metadata":{"tags":[]},"execution_count":69},{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2092\u001b[0m         \u001b[0mhardcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2094\u001b[0;31m         \u001b[0mParameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2095\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2096\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m_get_renderer\u001b[0;34m(figure, print_method)\u001b[0m\n\u001b[1;32m   1558\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1560\u001b[0;31m             raise RuntimeError(f\"{print_method} did not call Figure.draw, so \"\n\u001b[0m\u001b[1;32m   1561\u001b[0m                                f\"no renderer is available\")\n\u001b[1;32m   1562\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0mpil_kwargs\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0mKeyword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0;34m'pnginfo'\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mpresent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mcompletely\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincluding\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;34m'Software'\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name '_png'"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"hbstBcfgVJP6"},"source":["Παρατηρούμε ότι όντως τοποθετεί με αρκετά καλή ακρίβεια τα κλαδιά που περιέχουν κείμενα από την ίδια κατηγορία. Επίσης ο αλγόριθμος αυτός μπορεί να εντοπίσει και ιεραρχίες εντός της κάθε ομάδας. (Σημ. σε ένα πραγματικό unsupervised πρόβλημα τα χρώματα και τα label στον άξονα x **δεν** είναι διαθέσιμα).\n"]},{"cell_type":"markdown","metadata":{"id":"19cZxmnnhtu3"},"source":["\n","Σημειώστε επίσης την τεράστια επίδραση στις διαστάσεις των διανυσμάτων (το 1/10) που έχουν οι παράμετροι του  TfidfVectorizer. Στην πράξη προσπαθούμε να μικρύνουμε όσο γίνεται τις διαστάσεις μέχρι το σημείο που αρχίζει να πέφτει η ποιότητα (της κατηγοριοποίησης, του clustering κοκ).\n"]},{"cell_type":"markdown","metadata":{"id":"axdk56-nhvyn"},"source":["\n","### k-Means και αριθμός clusters\n","\n","Θα δοκιμάσουμε επίσης για το ίδιο πρόβλημα και τον **k-means**, σε περισσότερα κείμενα. Πρώτα φορτώνουμε τα κείμενα..."]},{"cell_type":"code","metadata":{"id":"yiUI7OoLVJP6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225349009,"user_tz":-120,"elapsed":26449,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"7a8d8843-56e1-4f71-a87c-031ed772bcef"},"source":["categ = ['alt.atheism', 'comp.graphics', 'rec.sport.baseball']\n","data = functools.reduce(lambda x,y: x+y, [fetch_20newsgroups(categories=[x], remove=('headers', 'footers'))['data'][:100] for x in categ])\n","print('Σύνολο κειμένων:', len(data))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Σύνολο κειμένων: 300\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PVXBumV-VJP9"},"source":["Στη συνέχεια εφαρμόζουμε την προεπεξεργασία και τρέχουμε τον k-means για διάφορα k για να βρούμε το βέλτιστο."]},{"cell_type":"code","metadata":{"id":"fgJO85EcVJP-"},"source":["from sklearn.cluster import KMeans\n","from sklearn.metrics import silhouette_score\n","tf_idf_array = vectorizer.fit_transform(data)\n","\n","silhouette_scores = []\n","for k in range(2, 10):\n","    km = KMeans(k)\n","    preds = km.fit_predict(tf_idf_array)\n","    silhouette_scores.append(silhouette_score(tf_idf_array, preds))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b4FUiTrfVJQA"},"source":["Σχεδιάζουμε τη γραφική του silhouette και βρίσκουμε το βέλτιστο k. Αυτό αντιπροσωπεύει τον αριθμό των κατηγοριών στις οποίες ανήκουν τα κείμενά μας."]},{"cell_type":"code","metadata":{"id":"vrnA-CPuVJQB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225350165,"user_tz":-120,"elapsed":27591,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"8e999a93-4286-490f-e6dd-481045010be2"},"source":["plt.plot(range(2, 10), silhouette_scores)\n","best_k = np.argmax(silhouette_scores) + 2 # +2 γιατί ξεκινάμε το range() από k=2 και όχι από 0 που ξεκινάει η αρίθμηση της λίστας\n","plt.scatter(best_k, silhouette_scores[best_k-2], color='r') # για τον ίδιο λόγο το καλύτερο k είναι αυτό 2 θέσεις παρακάτω από το index της λίστας\n","plt.xlim([2,9])\n","plt.annotate(\"best k\", xy=(best_k, silhouette_scores[best_k-2]), xytext=(5, silhouette_scores[best_k-2]),arrowprops=dict(arrowstyle=\"->\")) # annotation\n","print('Maximum average silhouette score for k =', best_k)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Maximum average silhouette score for k = 3\n"],"name":"stdout"},{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2092\u001b[0m         \u001b[0mhardcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2094\u001b[0;31m         \u001b[0mParameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2095\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2096\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m_get_renderer\u001b[0;34m(figure, print_method)\u001b[0m\n\u001b[1;32m   1558\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1560\u001b[0;31m             raise RuntimeError(f\"{print_method} did not call Figure.draw, so \"\n\u001b[0m\u001b[1;32m   1561\u001b[0m                                f\"no renderer is available\")\n\u001b[1;32m   1562\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0mpil_kwargs\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0mKeyword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0;34m'pnginfo'\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mpresent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mcompletely\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincluding\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;34m'Software'\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name '_png'"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"5PmC1zVwVJQG"},"source":["Με το κριτήριο silhouette βρήκαμε 3 cluster στα κείμενά μας, όσες κατηγορίες είχαμε και αρχικά.\n","Ας εκτυπώσουμε τις ετικέτες που μας δίνει ο k-means:"]},{"cell_type":"code","metadata":{"id":"00e7BytwVJQG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225350167,"user_tz":-120,"elapsed":27586,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"bca1a2e4-5938-40ce-c669-d0dd10fc925b"},"source":["km = KMeans(best_k)\n","km.fit(tf_idf_array)\n","print(km.labels_)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 0 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 1 0 2 2 1 1 2 2 2 2 1 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 2 1 0 0 0 0\n"," 0 0 0 0 1 1 0 0 0 0 2 0 1 0 1 1 2 0 0 1 2 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n"," 0 0 1 0 0 1 0 1 1 0 2 0 0 0 0 1 0 0 0 0 0 1 0 0 0 2 1 0 1 1 1 0 0 0 1 0 0\n"," 2 1 0 0]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qlwgP3UfVJQN"},"source":["Ξέρουμε ότι στο σύνολό μας, τα πρώτα 100 κείμενα ανήκουν στην 1η κατηγορία, τα επόμενα 100 στη δεύτερη, κτλ. Από τις παραπάνω προβλέψεις βλέπουμε ότι τα έχει πάει αρκετά καλά ο k-means. Σημειώστε ότι το label δεν έχει σημασία. \n","Για να δούμε για ποιο πράγμα μιλάει η κάθε κατηγορία, μπορούμε να βρούμε τους top όρους για κάθε ομάδα."]},{"cell_type":"code","metadata":{"id":"oDPxSPMmVJQO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225350168,"user_tz":-120,"elapsed":27581,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"95e992d5-a2d7-4303-ab07-3e596d351bc2"},"source":["terms = vectorizer.get_feature_names()\n","order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n","for i in range(best_k):\n","    out = \"Cluster %d:\" % i\n","    for ind in order_centroids[i, :20]:\n","        out += ' %s' % terms[ind]\n","    print(out)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cluster 0: year edu game team games better season baseball pitching cubs new clemens article good hit hitter win like alomar fans\n","Cluster 1: god edu people article think don com just believe atheism say does know religion like time keith wrong exist read\n","Cluster 2: image thanks graphics know hi files program does mail file information book looking help card use software images code color\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Z-C8XiNYVJQR"},"source":["Οι όροι βλέπουμε ότι έχουν όντως σχέση με το περιεχόμενο των κειμένων. Μπορούμε να τυπώσουμε και περισσότερα clusters και να διαπιστώσουμε ότι και αυτά έχουν σημασιολογική συνοχή."]},{"cell_type":"code","metadata":{"id":"Wu2sqzOdVJQS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606225350819,"user_tz":-120,"elapsed":28223,"user":{"displayName":"Parask Tz","photoUrl":"","userId":"08609487936413149826"}},"outputId":"4ec03a14-9022-42e7-e19b-26aeeceef530"},"source":["km = KMeans(10)\n","km.fit(tf_idf_array)\n","order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n","for i in range(10):\n","    out = \"Cluster %d:\" % i\n","    for ind in order_centroids[i, :20]:\n","        out += ' %s' % terms[ind]\n","    print(out)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cluster 0: team clemens game baseball edu pitching games win david players colorado sox better runs rest ca tonight cs pitcher days\n","Cluster 1: new mets stadium fan phillies grand year expos reds edu york rockies omar mailing sox yankees older box team white\n","Cluster 2: edu year article good like hit baseball time maybe better jewish alomar hitter com season think really players spring keith\n","Cluster 3: card driver drivers information com does ram net windows plus displays hi oeinck mirage cold copy super vesa looking ibm\n","Cluster 4: people morality objective just don moral edu value religion think atheists war mathew cc bible religious wrong evidence say claim\n","Cluster 5: graphics thanks know advance info mail codes vga copy hi thomas looking greatly svga assembly source comp color details mode\n","Cluster 6: jaeger bu islam islamic muslim rushdie gregg law uk question edu muslims buphy god article laws khomeini bcci religion book\n","Cluster 7: god edu atheism believe exist article think psuvm motto existence watch does don isc rit ultb com universe bible say\n","Cluster 8: thanks files viewer hi subject says gifs texas gl pd lansing mormon address just 24 edit millitello sam works gov\n","Cluster 9: image graphics program images software use version files information unix file help mail email color code know earth data need\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fIMe-MMjjBXn"},"source":["Σημειώστε ότι η παρουσία διάφορων όρων όπως edu, use, thanks που είτε υπάρχουν παντού είτε έχουν προφανώς μικρή σημασιολογική αξία, δείχνει ότι θα μπορούσαμε να κάνουμε ακόμα καλύτερη προεπεξεργασία και διανυσματική αναπαράσταση. "]}]}