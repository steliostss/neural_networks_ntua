# -*- coding: utf-8 -*-
"""75-B04.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EptTV1dt7bqt6FFtjSPHieVSZ0NWhphB

# Big Dataset - B04

## Section A: Basic Information

##### Upgrade hosted runtime
"""

!pip install --upgrade pip           #upgrade pip package installer
!pip install --upgrade scikit-learn  #upgrade scikit-learn package
!pip install --upgrade numpy         #upgrade numpy package
!pip install --upgrade pandas        #upgrade #upgrade pandas package
!pip install --upgrade joblib
!pip install --upgrade imbalanced-learn

"""#### Q1.

**Spambase Dataset**

Το dataset αποτελεί την ανάλυση των spam και των non-spam e-mail που έχουν συλλεχθεί. Η συλλογή των spam e-mail συγκεντρώθηκε από έναν διαχειριστή ενός mailserver και διαφόρων ατόμων που αρχειοθέτησαν τα spam mails τους.  
Τα non-spam e-mail συγκεντρώθηκαν από αρχειοθέτηση τόσο προσωπικών e-mail όσο και e-mail από εργασιακούς χώρους. Τα δεδομένα αυτά είναι χρήσιμα για την δημιουργία ενός spam filter για e-mail.

#### Q2

Όπως βλέπουμε πιο κάτω, αλλά και από την ιστοσελίδα του [UCI-Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/Spambase):

Το dataset περιέχει 4601 δείγματα και 57 χαρακτηριστικά.

Τα χαρακτηριστικά αυτά χωρίζονται ώς εξής:
1. 48 συνεχή πραγματικά τύπου real [0,100] χαρακτηριστικά τύπου: char_freq_CHAR, που αναπαριστούν το ποσοστό των χαρακτήρων που κάνουν match με **CHAR**
2. 1 χαρακτηριστικό συνεχούς τυπου real [1,...] αποδίδει το μεσό μήκος των ακολουθιών συνεχόμενων κεφαλαίων γραμμάτων.
3. 1 χαρακτηριστικό συνεχούς τυπου int [1,...] αποδίδει το μεγαλύτερο μήκος των ακολουθιών συνεχόμενων κεφαλαίων γραμμάτων.
4. 1 χαρακτηριστικό συνεχούς τύπου int [1,...] αποδίδει το άθροισμα του μήκους όλων των ακολουθιών συνεχόμενων κεφαλαίων γραμμάτων.
5. 1 χαρακτηριστικό διακριτού τύπου [0,1] αποδίδει τον τύπο του e-mail: spam / non-spam. Αυτό το χαρακτηριστικό αποτελεί το label κάθε entry του dataset.

##### Retrieve dataset
"""

import pandas as pd
import numpy as np
import ast
import io
import requests
import matplotlib.pyplot as plt
from urllib.error import HTTPError

# datafile = "spambase.data"

try:
    #data without headers for better manipulation
    spambase_data_url = "https://raw.githubusercontent.com/steliostss/neural_networks_ntua/master/nn2020-21/Assignment1/Big_Dataset/spambase.csv"
    data = pd.read_csv(spambase_data_url, header=None)

    #data with headers for better visualizing
    #data_headers = pd.read_csv(data_csv_url)

    print("Succesful file processing!")

except HTTPError:
    print("URL not working.")

"""##### Printing for validation / visualization"""

#print for better visualization
data.head(6)

"""##### Custom Functions"""

## GATHER ALL FUNCTIONS FOR SECTION-B HERE

# evaluate type of value in the given variable
def tryeval(np_samples):
    for row in range(len(np_samples)): 
        for col in range(len(np_samples[row])):
            try: 
                np_samples[row][col] = ast.literal_eval(np_samples[row][col])
            except ValueError:
                pass
    return np_samples

# define if all features have the same type
def features_datatypes(features):
    datatypes = list()
    for row in range(len(features)):
        for col in range(len(np_samples[row])):
            current_type = type(features[row][col])
            if current_type not in datatypes:
                datatypes.append(current_type)
    return datatypes

# define all class labels
def class_labels(labels):
    cLabels = [] # all the labels gathered
    for col in range(len(labels)):
        current_val = labels[col]
        if current_val not in cLabels:
            cLabels.append(current_val)
    return cLabels

# gather data features in a table
data_features = data.iloc[[0],:-1]
( _ , number_of_features ) = data_features.shape
print("Q2: Number of features = ", number_of_features)
# print(data_features.shape) # uncomment if you want to check the results

# gather data samples in a table
data_samples = data.iloc[0:,:-1]
( number_of_samples , _ ) = data_samples.shape
print("Q2: Number of samples = ", number_of_samples)
# print(data_samples.shape) # uncomment if you want to check the results

# transform the gathered data in numpy arrays
np_features = data_features.values
np_samples = data_samples.values

# convert the type of samples to the correct type
np_samples = tryeval(np_samples)
datatypes = features_datatypes(np_samples)


print("Q2: Type of features =", end=' ')
print(*datatypes, sep = " & ")

"""#### Q3

Δεν υπάρχουν επικεφαλίδες στο αρχείο, καθώς ούτε και αρίθμηση γραμμών. Η μόνη περιγραφή είναι στην ιστοσελίδα από όπου παρέχεται το dataset.

#### Q4

Οι ετικέτες των κλάσεων είναι [0, 1] και βρίσκονται στην τελευταία στήλη.
"""

# gather class labels in a table

binary_class_labels = data.iloc[:, 57] 
np_labels = binary_class_labels.values.flatten()

np_labels

# make a list with all different labels
list_of_labels = class_labels(np_labels)
print("Q4: Classification Labels =", end=' ')
print(*list_of_labels, sep = " & ")

label_names = list()
for i in range(len(list_of_labels)):
    label_names.append(str(list_of_labels[i]))
# label_names = ('0','1')
label_names

"""#### Q5

Δεν χρειάστηκε να κάνουμε κάποια μετατροπή στο dataset.

#### Q6

Μέσω εντολών shell ελέγχουμε αν το dataset μας έχει κενές τιμές. Όπως φαινεται παρακάτω, δεν υπάρχουν.
"""

# check if dataset has empty values
# and if, how many of them

!echo "For spambase.data file, empty values: "
!cat spambase.data | grep "?" | wc -l

"""#### Q7

Το dataset μας δεν είναι ισορροπημένο και αυτό φαίνεται στις συχνότητες παρακάτω. Θα χρησιμοποιήσουμε την μέθοδο oversampling για να το ισορροπήσουμε, καθώς έχουμε λίγα δείγματα και δεν θέλουμε να χάσουμε πληροφορία.
"""

print("frequencies:", np.bincount(np_labels))
freq = np.bincount(np_labels)
for i in range(len(freq)):
    print("For label:", i, "percentage is", "{:.2%}".format(freq[i]/number_of_samples))

"""#### Q8"""

from sklearn.model_selection import train_test_split

# Split our data
train, test, train_labels, test_labels = train_test_split(np_samples, 
                                                          np_labels, 
                                                          test_size=0.3)

print("Train size:", train.shape)
print("Test size:", test.shape)

"""## Section B: Baseline Classification

### Custom Functions
"""

from sklearn.linear_model import LogisticRegression 
from sklearn.preprocessing import StandardScaler 
from sklearn.metrics import confusion_matrix, classification_report 
from imblearn.over_sampling import RandomOverSampler
from imblearn.over_sampling import SMOTE
from sklearn.dummy import DummyClassifier
from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics import classification_report
from matplotlib import pyplot as plt
import time

def print_precision_recall_fscore_support(method, test_labels, pred, label_names):
    print(method, end = '\n\n')
    (none, micro, macro, weighted) = get_PRFS(method, test_labels, pred, label_names)
    print("none     :", none )
    print("micro    :", micro )
    print("macro    :", macro )
    print("weighted :", weighted, end = '\n\n')
    print(classification_report(test_labels, pred, target_names=label_names), end = '\n\n')

    ( _ , _ , microF1    , _ ) = micro
    ( _ , _ , macroF1    , _ ) = macro
    ( _ , _ , weightedF1 , _ ) = weighted

    barplotF1 = (microF1, macroF1, weightedF1)
    xaxis = ("microF1", "macroF1", "weightedF1")
    plt.figure(figsize=(10,5))
    plt.bar(xaxis, barplotF1)
    plt.show()
    print("---------------------------------------------------------------------------------------------------------------------", end = '\n')
    print("---------------------------------------------------------------------------------------------------------------------", end = '\n\n')

# get_precision_recall_fscore_support
def get_PRFS(method, test_labels, pred, label_names):
    none = precision_recall_fscore_support(test_labels, pred, average=None)
    micro = precision_recall_fscore_support(test_labels, pred, average='micro')
    macro = precision_recall_fscore_support(test_labels, pred, average='macro')
    weighted = precision_recall_fscore_support(test_labels, pred, average='weighted')
    return (none, micro, macro, weighted)

"""### Dummy Classifier"""

# We will use the below dictionaries to compare the results of each classifier
f1_macro_default={}
f1_macro_optimized={}

f1_micro_default={}
f1_micro_optimized={}

train_time_default={}
train_time_optimized={}

predict_time_default={}
predict_time_optimized={}

from sklearn.dummy import DummyClassifier
dc_uniform = DummyClassifier(strategy="uniform")
dc_constant_0 = DummyClassifier(strategy="constant", constant=0)
dc_constant_1 = DummyClassifier(strategy="constant", constant=1)
dc_most_frequent = DummyClassifier(strategy="most_frequent")
dc_stratified = DummyClassifier(strategy="stratified")

# με τη μέθοδο fit "εκπαιδεύουμε" τον ταξινομητή στο σύνολο εκπαίδευσης (τα χαρακτηριστικά και τις ετικέτες τους)
from sklearn.metrics import accuracy_score

# με τη μέθοδο predict παράγουμε προβλέψεις για τα δεδομένα ελέγχου (είσοδος τα χαρακτηριστικά μόνο)
predictions = {}
spambase_accuracy = {}

model_dc_uni = dc_uniform.fit(train, train_labels)
preds = model_dc_uni.predict(test)
predictions['dc_uniform'] = preds
spambase_accuracy['uniform (random)'] = accuracy_score(test_labels, preds)


model_dc_con0 = dc_constant_0.fit(train, train_labels)
preds = model_dc_con0.predict(test)
predictions['dc_constant_0'] = preds
spambase_accuracy['constant 0'] = accuracy_score(test_labels, preds)

model_dc_con1 = dc_constant_1.fit(train, train_labels)
preds = model_dc_con1.predict(test)
predictions['dc_constant_1'] = preds
spambase_accuracy['constant 1'] = accuracy_score(test_labels, preds)

model_dc_freq = dc_most_frequent.fit(train, train_labels)
preds = model_dc_freq.predict(test)
predictions['dc_most_frequent'] = preds
spambase_accuracy['most frequent label'] = accuracy_score(test_labels, preds)

start_time = time.time()
model_dc_strat = dc_stratified.fit(train, train_labels)
train_time = (time.time() - start_time)

train_time_default['Dummy'] = train_time
train_time_optimized['Dummy'] = train_time

start_time = time.time()
preds = model_dc_strat.predict(test)
predictions['dc_stratified'] = preds
spambase_accuracy['stratified'] = accuracy_score(test_labels, preds)
pred_time = (time.time() - start_time)

predict_time_default['Dummy'] = train_time
predict_time_optimized['Dummy'] = train_time

for i in predictions:
    print("Prediction for", i, '=', predictions[i])

print()
    
print("Classification Accuracy on the Spambase Dataset (30% test set)\n")
sorted_accuracy = [(k, spambase_accuracy[k]) for k in sorted(spambase_accuracy, key=spambase_accuracy.get, reverse=True)]

print("----------Results are sorted----------\n")

for k,v in sorted_accuracy:
    print(k,v)

from sklearn.metrics import confusion_matrix
# Compute confusion matrix

print("Confusion matrices\n")
for i in predictions:
    # print confusion matrix
    cnf_matrix = confusion_matrix(test_labels, predictions[i])
    print(i)
    print(cnf_matrix, end='\n\n')

"""Σχετικά με τα confusion matrix παραπάνω:
1. Για στρατηγική constant, δεν έχουμε καμία πρόβλεψη για την αντίθετη κλάση, γι αυτό δεν έχουμε και false positives / false negatives.
2. Αντίστοιχα στο most frequent, όπου η κλάση 0 είναι η πιο συχνή, έχουμε ίδιο αποτέλεσμα με την constant 0 στρατηγική.
3. Η uniform ναι μεν παράγει τυχαία αποτελέσματα αλλά με ομοιόμορφη κατανομή και βλέπουμε πως αποτυγχάνει στην κλάση 1, καθώς η ομοιόμορφη κατανομή ευνοεί την πολυπληθέστερη κλάση.
4. Στην stratified έχουμε μια παρόμοια με την uniform κατανομή αποτελεσμάτων.
"""

for i in predictions:
    print_precision_recall_fscore_support(i, test_labels, predictions[i], label_names)

print(train_time_default)
print(predict_time_default)

#There is no point of optimizing the dummy classifier, so we will take as optimized the default value again
report_dict = classification_report(test_labels, preds, output_dict = True)
f1_macro_default['Dummy'] = report_dict['macro avg']['f1-score']
f1_macro_optimized['Dummy'] = report_dict['macro avg']['f1-score']

f1_micro_default['Dummy'] = report_dict['accuracy']
f1_micro_optimized['Dummy'] = report_dict['accuracy']

print(f1_macro_default)
print(f1_micro_default)

"""Όπως βλέπουμε, ο Dummy classifier δεν είναι πολύ αποδοτικός. Το καλύτερό του αποτέλεσμα προέκυψε από τη στρατηγική dc_constant = 1 και αυτό γιατί το dataset μας έχει μια μικρή κλίση προς το label 1.

### Gaussian Naive Bayes Classifier
"""

from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()

# κάνουμε εκπαίδευση (fit) δηλαδή ουσιαστικά υπολογίζουμε μέση τιμή και διακύμανση για όλα τα χαρακτηριστικά και κλάσεις στο training set
start_time = time.time()
model_gnb = gnb.fit(train, train_labels)
train_time = (time.time() - start_time)

train_time_default['GaussianNB'] = train_time

start_time = time.time()
preds = model_gnb.predict(test)
train_time = (time.time() - start_time)

predict_time_default['GaussianNB'] = train_time

# η GaussianNB έχει builtin μέθοδο υπολογισμό accuracy. Αποθηκεύουμε την τιμή της στον πίνακά μας με τα αποτελέσματα από τα άλλα classifiers
spambase_accuracy['gaussian naive bayes'] = model_gnb.score(test, test_labels)

# και ξανατυπώνουμε τα sorted αποτελέσματα
print("Classification Accuracy on the Spambase Dataset (30% test set)\n")

print("---------- Results are sorted ----------\n")

sorted_accuracy = [(k, spambase_accuracy[k]) for k in sorted(spambase_accuracy, key=spambase_accuracy.get, reverse=True)]
for k, v in sorted_accuracy:
    print(k,v)

# Compute confusion matrix
pred = model_gnb.predict(test)
print("Confusion matrix\n")
cnf_matrix = confusion_matrix(test_labels, pred)
print("Gaussian Naive Bayes")
print(cnf_matrix, end='\n\n')

"""Βλέπουμε πως καταφέρνουμε να μαντέψουμε σωστά την κλάση 0, όμως αποτυγχάνουμε στην κλάση 1. Αυτό πιθανόν να οφείλεται στην ύπαρξη περισσότερων δειγμάτων από την κλάση 0."""

print_precision_recall_fscore_support("GaussianNB", test_labels, pred, label_names)

print(train_time_default)
print(predict_time_default)

report_dict = classification_report(test_labels, preds, output_dict = True)
f1_macro_default['GaussianNB'] = report_dict['macro avg']['f1-score']
f1_micro_default['GaussianNB'] = report_dict['accuracy']

print(f1_macro_default)
print(f1_micro_default)

"""Όπως βλέπουμε, έχουμε πολύ καλύτερα αποτελέσματα από τον Dummy Classifier, φτάνοντας ένα αρκετά καλό f1-score. Επιπλέον, είναι εμφανές ότι το f1-macro και f1-micro score είναι αρκετά κοντά, όπως περιμέναμε, καθώς οι κλάσεις μας είναι πάνω κάτω ισορροπημένες στην κατανομή.

### k Nearest Neighbors Classifier (kNN)
"""

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier()

start_time = time.time()
knn.fit(train, train_labels)
total_time = (time.time() - start_time)

train_time_default['kNN'] = total_time
print("Fit done in:",total_time,"seconds")

start_time = time.time()
pred = knn.predict(test)
total_time = (time.time() - start_time)

predict_time_default['kNN'] = total_time

cnf_matrix = confusion_matrix(test_labels, pred)

print(cnf_matrix)

print_precision_recall_fscore_support("KNeighborsClassifier", test_labels, pred, label_names)

print(train_time_default)
print(predict_time_default)

report_dict = classification_report(test_labels, preds, output_dict = True)
f1_macro_default['kNN'] = report_dict['macro avg']['f1-score']
f1_micro_default['kNN'] = report_dict['accuracy']

print(f1_macro_default)
print(f1_micro_default)

"""Όπως βλέπουμε ο kNN δεν μας δίνει καλύτερα αποτελέσματα από ότι ο GaussianNB Classifier στο συγκεκριμένο dataset. 

Αυτό πιθανόν να οφείλεται στο γεγονός ότι έχουμε πολλά χαρακτηριστικά, οπότε και μεγάλη διαστασιμότητα (dimensionality). Περιμένουμε σημαντική βελτίωση όταν κανονικοποιήσουμε τα δεδομένα μας.

### MLP Classifier
"""

from sklearn.neural_network import MLPClassifier

clf = MLPClassifier(solver='lbfgs', alpha=1e-5,
                    hidden_layer_sizes=(5,), random_state=1,
                    max_iter=2000)

start_time = time.time()
clf.fit(train, train_labels)
total_time = (time.time() - start_time)

train_time_default['MLPClassifier'] = total_time
print("Fit done in:",total_time,"seconds")

start_time = time.time()
preds = clf.predict(test)
total_time = (time.time() - start_time)

predict_time_default['MLPClassifier'] = total_time

# Compute confusion matrix
pred = clf.predict(test)
print("Confusion matrix\n")
cnf_matrix = confusion_matrix(test_labels, pred)
print("MLP Classifier")
print(cnf_matrix, end='\n\n')

"""Και εδώ βλέπουμε καλύτερα αποτελέσματα σε σχέση με τους προηγούμενους classifiers. Συγκεκριμένα βλέπουμε καλύτερη απόδοση στην κλάση 0, πιθανότατα γιατί ο classifier έχει μάθει καλύτερα να διακρίνει entries από αυτή την κλάση, αφού το dataset μας είναι imbalanced με κλίση προς την κλάση 0."""

print_precision_recall_fscore_support("MLPClassifier", test_labels, pred, label_names)

print(train_time_default)
print(predict_time_default)

report_dict = classification_report(test_labels, preds, output_dict = True)
f1_macro_default['MLPClassifier'] = report_dict['macro avg']['f1-score']
f1_micro_default['MLPClassifier'] = report_dict['accuracy']

print(f1_macro_default)
print(f1_micro_default)

"""Όπως βλέπουμε, ο MLP έχει πολύ καλύτερα αποτελέσματα από τους 3 προηγούμενους classifiers. Αυτό έχει να κάνει πιθανότατα γιατί βάλαμε πολύ μεγάλο όριο στο max_iter. Είναι καλύτερος από τους άλλους 3 και συγκεκριμένα από τον kNN γιατί τα δεδομένα μας δεν είναι βελτιστοποιημένα στο κομμάτι του preprocessing, πχ scaling που βοηθάει τον kNN, οπότε ο MLP που αντιδράει καλύτερα σε αυτές τις περιπτώσεις μαθαίνει καλύτερα τα βάρη ενώ ο kNN δεν έχει κάποια εκπαίδευση.

### SVM Classifier

#### Linear Kernel
"""

from sklearn.svm import SVC # "Support vector classifier"
from sklearn.svm import LinearSVC # "Support vector classifier"

model_svm_linear = LinearSVC()

start_time = time.time()
model_svm_linear.fit(train, train_labels)
total_time = (time.time() - start_time)

train_time_default['SVM_linear'] = total_time
print("Fit done in:",total_time,"seconds")

start_time = time.time()
preds = model_svm_linear.predict(test)
total_time = (time.time() - start_time)

predict_time_default['SVM_linear'] = total_time

# Compute confusion matrix
pred = model_svm_linear.predict(test)
print("Confusion matrix\n")
cnf_matrix = confusion_matrix(test_labels, pred)
print("SVM Classifier - Linear Kernel")
print(cnf_matrix, end='\n\n')

"""Στον συγκεκριμένο classifier βλέπουμε την καλύτερη απόδοση μέχρι τώρα.. 

Δοκιμάσαμε και τον SVC classifier και η εκπαίδευση πήρε περίπου 10 λεπτά, όμως έδωσε καλύτερα αποτελέσματα από τον linearSVC. Αυτό είναι γιατί τα penalty, tol και loss είναι πιο αυστηρά στον SVC σε σχέση με τον LinearSVC.
"""

print_precision_recall_fscore_support("SVM_linear", test_labels, pred, label_names)

print(train_time_default)
print(predict_time_default)

report_dict = classification_report(test_labels, preds, output_dict = True)
f1_macro_default['SVM_linear'] = report_dict['macro avg']['f1-score']
f1_micro_default['SVM_linear'] = report_dict['accuracy']

print(f1_macro_default)
print(f1_micro_default)

"""#### RBF Kernel"""

model_svm_rbf = SVC(kernel='rbf')

start_time = time.time()
model_svm_rbf.fit(train, train_labels)
total_time = (time.time() - start_time)

train_time_default['SVM_rbf'] = total_time
print("Fit done in:",total_time,"seconds")

start_time = time.time()
preds = model_svm_rbf.predict(test)
total_time = (time.time() - start_time)

predict_time_default['SVM_rbf'] = total_time

# Compute confusion matrix
pred = model_svm_rbf.predict(test)
print("Confusion matrix\n")
cnf_matrix = confusion_matrix(test_labels, pred)
print("SVM Classifier - RBF Kernel")
print(cnf_matrix, end='\n\n')

"""Εδώ βλέπουμε πως έχουμε χειρότερα αποτελέσματα από τον linear kernel. Έτσι συμπεραίνουμε με μεγαλύτερη σιγουρία πως το dataset μας πιθανότατα είναι γραμμικά διαχωρίσιμο και η μετατροπή του με rbf kernel function προκαλεί προβλήματα. """

print_precision_recall_fscore_support("SVM_rbf", test_labels, pred, label_names)

print(train_time_default)
print(predict_time_default)

report_dict = classification_report(test_labels, preds, output_dict = True)
f1_macro_default['SVM_rbf'] = report_dict['macro avg']['f1-score']
f1_micro_default['SVM_rbf'] = report_dict['accuracy']

print(f1_macro_default)
print(f1_micro_default)

"""#### Poly Kernel"""

model_svm_poly = SVC(kernel='poly')

start_time = time.time()
model_svm_poly.fit(train, train_labels)
total_time = (time.time() - start_time)

train_time_default['SVM_poly'] = total_time
print("Fit done in:",total_time,"seconds")

start_time = time.time()
preds = model_svm_poly.predict(test)
total_time = (time.time() - start_time)

predict_time_default['SVM_poly'] = total_time

# Compute confusion matrix
pred = model_svm_poly.predict(test)
print("Confusion matrix\n")
cnf_matrix = confusion_matrix(test_labels, pred)
print("SVM Classifier - Poly Kernel")
print(cnf_matrix, end='\n\n')

"""Εδώ βλέπουμε πως έχουμε μεγάλη κλίση στην πρόβλεψη της κλάσης 0. Πιθανότατα είναι γιατί τα δεδομένα μας είναι απλωμένα στο πεδίο με τέτοιο τρόπο, που η μετατροπή τους μέσω μιας polynomial kernel function τα μπλέκει και δεν επιτρέπει τον ξεκάθαρο διαχωρισμό τους."""

print_precision_recall_fscore_support("SVM_poly", test_labels, pred, label_names)

print(train_time_default)
print(predict_time_default)

report_dict = classification_report(test_labels, preds, output_dict = True)
f1_macro_default['SVM_poly'] = report_dict['macro avg']['f1-score']
f1_micro_default['SVM_poly'] = report_dict['accuracy']

print(f1_macro_default)
print(f1_micro_default)

"""Όπως βλέπουμε, την καλύτερη απόδοση την έχει η linear kernel function και μάλιστα κατά μεγάλη διαφορά. Όμως υπάρχει αντιστρόφως ανάλογη απόδοση στον χρόνο εκπαίδεσης.

## Section C: Optimizing Classifiers

### GridSearchCV & Print
"""

from sklearn.model_selection import GridSearchCV
from sklearn.neural_network import MLPClassifier
from sklearn.feature_selection import VarianceThreshold
from sklearn.preprocessing import StandardScaler 
from imblearn.over_sampling import RandomOverSampler
from sklearn.decomposition import PCA
from imblearn.pipeline import Pipeline

selector = VarianceThreshold()
scaler = StandardScaler()
ros = RandomOverSampler()
pca = PCA()

def gridsearch_init_print(classifier, param_grid, pipe, train=train, train_labels=train_labels, test=test, test_labels=test_labels):

    # We will use 5 fold validation
    estimator = GridSearchCV(pipe, param_grid=param_grid, cv=5, scoring='f1_micro', n_jobs=-1, verbose=10)

    start_time = time.time()
    estimator.fit(train, train_labels)
    total_time = (time.time() - start_time)

    train_time_optimized[classifier] = total_time
    print("Fit done in:",(time.time() - start_time)/60,"minutes")

    start_time = time.time()

    preds = estimator.predict(test)
    total_time = (time.time() - start_time)

    predict_time_optimized[classifier] = total_time

    print(classification_report(test_labels, preds))

    print(estimator.best_estimator_)
    print(estimator.best_params_)

    # Compute confusion matrix
    pred = estimator.predict(test)
    print("Confusion matrix\n")
    cnf_matrix = confusion_matrix(test_labels, pred)
    print(classifier, "Classifier", )
    print(cnf_matrix, end='\n\n')

    report_dict = classification_report(test_labels, preds, output_dict = True)
    f1_macro_optimized[classifier] = report_dict['macro avg']['f1-score']
    f1_micro_optimized[classifier] = report_dict['accuracy']


    print("------------F1 macro------------")
    print("Default:", f1_macro_default)
    print("Optimiz:", f1_macro_optimized)
    print("------------F1 micro------------")
    print("Default:", f1_micro_default)
    print("Optimiz:", f1_micro_optimized)

"""### Sample to test dataset"""

from sklearn.utils import shuffle

# define max samples
max_samples = 500

# extract data
all_features = data.iloc[0:, :-1]
all_labels = data.iloc[0:, -1]

# shuffle respectively
shuffled_features, shuffled_labels = shuffle(all_features, all_labels, random_state=341976)
sdata = shuffled_features.iloc[0:max_samples-1,:]
slabels = shuffled_labels.iloc[0:max_samples-1]

# convert to np array
snp_samples = sdata.values
snp_labels = slabels.values

# check frequencies
freq = np.bincount(snp_labels)
for i in range(len(freq)):
    print("For label:", i, "percentage is", "{:.2%}".format(freq[i]/max_samples))

# split to train, test
# Split our data
strain, stest, strain_labels, stest_labels = train_test_split(snp_samples, 
                                                          snp_labels, 
                                                          test_size=0.3)

print(strain.shape)
print(stest.shape)

"""### Balance Dataset - Oversampling"""

sampler = SMOTE()
train, train_labels = sampler.fit_sample(np_samples, np_labels)

# print length of train set to validate oversampling
print("Length of train_set is =", len(train), '\n')

"""### Variance Threshold

Ελέγχουμε τη διασπορά κάθε χαρακτηριστικού στο train dataset ούτως ώστε να καταλάβουμε ποία θα είναι η επιλογή μας για το κατώφλι διασποράς.
"""

train_Var = np.var(train, axis=0)
print(train_Var)

from sklearn.feature_selection import VarianceThreshold

# initialize the selector
selector = VarianceThreshold(0)
# fit the selector in the data
train_reduced = selector.fit_transform(train)
print(train.shape)
print(train_reduced.shape)

selector = VarianceThreshold(0.05)

train_reduced = selector.fit_transform(train)
print(train_reduced)

mask = selector.get_support()
print(mask)

print(train.shape)
print(train_reduced.shape)

selector = VarianceThreshold(0.2)

train_reduced = selector.fit_transform(train)
print(train.shape)
print(train_reduced.shape)

"""Εδώ βλέπουμε πως πρέπει να επιλέξουμε μια τιμή μικρότερη του 0.05, καθώς τα features μειώνονται δραστικά, οπότε μπορεί να χάνουμε σημαντική πληροφορία.

### Dummy Classifier
"""

dc_stratified = DummyClassifier(strategy="stratified")

start_time = time.time()
model = dc_stratified.fit(train, train_labels)
train_time = (time.time() - start_time)

train_time_default['Dummy'] = train_time
train_time_optimized['Dummy'] = train_time

start_time = time.time()
preds = dc_stratified.predict(test)
pred_time = (time.time() - start_time)

predict_time_default['Dummy'] = train_time
predict_time_optimized['Dummy'] = train_time


print (classification_report(test_labels, preds))

print(train_time_default)
print(predict_time_default)

"""Όπως βλέπουμε εδώ, δεν πετύχαμε κάποια σημαντική βελτίωση, στον Dummy Classifier, με την προεπεξεργασία δεδομένων.

### Optimized Gaussian Naive Bayes Classifier
"""

from imblearn.pipeline import Pipeline

# import the known classes for preprocessing
from sklearn.feature_selection import VarianceThreshold
from sklearn.decomposition import PCA
from sklearn.model_selection import GridSearchCV

clf = GaussianNB()

param_grid = {
    'selector__threshold': [0, 0.01, 0.02, 0.03, 0.04, 0.05] #according to the calculations we did in the beginning of this section
}

pipe = Pipeline(steps=[('selector', selector), ('gaussiannb', clf)], memory = 'tmp')
gridsearch_init_print('GaussianNB', param_grid, pipe, strain, strain_labels, stest, stest_labels)

param_grid = {
    'selector__threshold': [0.03], #according to the calculations we did in the beginning of this section
    'pca__n_components': [30, 32, 38, 40, 42, 44, 45],
}

clf = GaussianNB()
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('gaussiannb', clf)], memory = 'tmp')
gridsearch_init_print('GaussianNB', param_grid, pipe)

"""Βλέπουμε πως με sacled dataset ο classifier τα πηγαίνει καλύτερα από οτι με το κανονικό."""

param_grid = {
    'selector__threshold': [0.03], #according to the calculations we did in the beginning of this section
    'pca__n_components': [43, 45, 46, 47, 50, 60, 70]
}

clf = GaussianNB()
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('gaussiannb', clf)], memory = 'tmp')
gridsearch_init_print('GaussianNB', param_grid, pipe)

"""Βλέπουμε μια αισθητή βελτίωση στην απόδοση με 46 components στην μέθοδο pca."""

param_grid = {
    'selector__threshold': [0.03], #according to the calculations we did in the beginning of this section
    'pca__n_components': [47]
}

clf = GaussianNB()
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('ros', ros), ('gaussiannb', clf)], memory = 'tmp')
gridsearch_init_print('GaussianNB', param_grid, pipe)

"""Βλέπουμε όμως πως πέφτει με random over sampler, οπότε τον αφαιρούμε."""

print(train.shape)
print(train_reduced.shape)

"""Βλέπουμε ότι το καλύτερο αποτέλεσμα το πετύχαμε για Variance Threshold 0.02. Δεν έχουμε τόσα πολλά features συγκριτικά με τον αριθμό των δειγμάτων, οπότε σταματάμε σε αυτό το threshold.

Θα δοκιμάσουμε και με PCA:
"""

# initialize the estimators (transformers and classifier) without parameters
clf = GaussianNB()

param_grid = {
    'selector__threshold': [0.04],
    'pca__n_components': [31,32,33,34,35,36,37]
}

pipe = Pipeline(steps=[('selector', selector),('pca',pca), ('gaussiannb', clf)], memory = 'tmp')
gridsearch_init_print('GaussianNB', param_grid, pipe)

"""Εδώ βλέπουμε ότι έχουμε λιγότερες διαστάσεις αλλά απειροελάχιστη διαφορά απόδοσης σε σχέση με τον non-optimized classifier.

Στο καινούργιο pipeline βρήκαμε καλύτερο σκορ, χρησιμοποιώντας variance_threshold=0.04 και PCA.

Εδώ να σημειώσουμε πως η επιλογή μας στα components του PCA έγινε μετά από πειραματισμούς με μεγαλύτερες τιμές, που δεν απέδιδαν παραπάνω.

Μπορεί να κάναμε αρκετό pre-processing και να χρησιμοποιήσαμε gridsearchCV αλλά δεν είχε κάποιά αξιόλογή επίδραση στον Gaussian Naive Bayes, τουλάχιστον με τις παραμέτρους που δοκιμάσαμε.

### Optimized kNN Classifier

Αρχικά θα δοκιμάσουμε μόνο με Variance Threshold. Θα χρησιμοποιήσουμε όλους τους πυρήνες (n_jobs = -1) και verbose = 10 για να ελέγχουμε την πορεία της εκπαίδευσης.
"""

clf = KNeighborsClassifier(n_jobs=-1)

param_grid = {
    # 'selector__threshold': [0.05, 0.06, 0.07, 0.08, 0.09, 0.1],
    'kNN__n_neighbors': [1, 2, 3, 4, 5, 10, 15],
    'kNN__weights': ['uniform', 'distance'],
    'kNN__metric': ['euclidean', 'manhattan', 'chebyshev', 'minkowski', 'hamming'] #default minkowski
}

pipe = Pipeline(steps=[('kNN', clf)], memory = 'tmp')
gridsearch_init_print('kNN', param_grid, pipe, strain, strain_labels, stest, stest_labels)

"""Επιλέγουμε να προχωρήσουμε πρώτα με τα weights. Κρατάμε το 'distance' ως καλύτερο."""

clf = KNeighborsClassifier(n_jobs=-1)

param_grid = {
    # 'selector__threshold': [0.05, 0.06, 0.07, 0.08, 0.09, 0.1],
    'kNN__weights': ['distance'],
    'kNN__n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15],
    'kNN__metric': ['euclidean', 'manhattan', 'chebyshev', 'minkowski', 'hamming'] #default minkowski
}

pipe = Pipeline(steps=[('kNN', clf)], memory = 'tmp')
gridsearch_init_print('kNN', param_grid, pipe, strain, strain_labels, stest, stest_labels)

"""Βλέπουμε πως παρόλο που δώσαμε μεγάλο εύρος neighbors, επιλέγεται πάλι το k=5. Οπότε κρατάμε αυτό ως βέλτιστο και metric = hamming."""

clf = KNeighborsClassifier(n_jobs=-1)

param_grid = {
    # 'selector__threshold': [0.05, 0.06, 0.07, 0.08, 0.09, 0.1],
    'kNN__weights': ['distance'],
    'kNN__n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15],
    'kNN__metric': ['euclidean', 'manhattan', 'chebyshev', 'minkowski', 'hamming'] #default minkowski
}

pipe = Pipeline(steps=[('scaler', scaler), ('sampler', ros), ('kNN', clf)], memory = 'tmp')
gridsearch_init_print('kNN', param_grid, pipe, strain, strain_labels, stest, stest_labels)

clf = KNeighborsClassifier(n_jobs=-1)

param_grid = {
    # 'selector__threshold': [0.05, 0.06, 0.07, 0.08, 0.09, 0.1],
    'pca__n_components': [31,32,33,34,35,36,37],
    'kNN__weights': ['distance'],
    'kNN__n_neighbors': [5, 6, 7, 8, 9, 10, 15],
    'kNN__metric': ['euclidean', 'manhattan', 'chebyshev', 'minkowski', 'hamming'] #default minkowski
}

pipe = Pipeline(steps=[('scaler', scaler), ('pca', pca), ('sampler', ros), ('kNN', clf)], memory = 'tmp')
gridsearch_init_print('kNN', param_grid, pipe, strain, strain_labels, stest, stest_labels)

clf = KNeighborsClassifier(n_jobs=-1)

param_grid = {
    'pca__n_components': [34],
    'kNN__weights': ['distance'],
    'kNN__n_neighbors': [14, 15, 18, 20],
    'kNN__metric': ['euclidean', 'manhattan', 'chebyshev', 'minkowski', 'hamming'] #default minkowski
}

pipe = Pipeline(steps=[('scaler', scaler), ('pca', pca), ('sampler', ros), ('kNN', clf)], memory = 'tmp')
gridsearch_init_print('kNN', param_grid, pipe, strain, strain_labels, stest, stest_labels)

clf = KNeighborsClassifier(n_jobs=-1)

param_grid = {
    # 'pca__n_components': [34],
    'selector__threshold': [0, 0.1, 0.2],
    'kNN__n_neighbors': [5, 6, 7, 10, 15],
    'kNN__weights': ['distance'],
    'kNN__metric': ['hamming'] #default minkowski
}

pipe = Pipeline(steps=[('selector', selector),('scaler', scaler), ('kNN', clf)], memory = 'tmp')
gridsearch_init_print('kNN', param_grid, pipe)

"""Αν και βάλαμε όλο το dataset να κάνει fit εξ αρχής, χωρίς να δοκιμάσουμε το sampled dataset, μας έβαλε σχεδόν 100% επιτυχία (αν εξαιρέσουμε 3 False Negatives, από confusion matrix) οπότε σταματάμε την βελτιστοποίηση εδώ.

Οι βελτιστες παράμετροι φαίνονται παραπάνω.

### Optimized MLP Classifier

Δοκιμάζουμε όλες τις παραμέτρους και βλέπουμε ποιός συνδυασμός τους μας δίνει τα καλύτερα αποτελέσματα.

Στη συνέχεια θα βάλουμε scaler, ros, pca κλπ.
"""

## Parameters to optimize
param_grid = {
    'selector__threshold': [0.003],
    'mlpclassifier__solver': ['lbfgs','sgd','adam'], # default ‘adam’
    'mlpclassifier__activation': ['identity', 'logistic', 'tanh', 'relu'], # default ‘relu’
    'mlpclassifier__hidden_layer_sizes': [(5,) , (15,) , (20,) , (50,) , (100,)], # tuple default (100,).The ith element represents the number of neurons in the ith hidden layer.
    'mlpclassifier__learning_rate': ['constant','invscaling','adaptive'], # Only used when solver='sgd'.
    'mlpclassifier__max_iter': [100,150,200,250],
    'mlpclassifier__alpha': [0.0001, 0.002, 0.05] 
}

mlp = MLPClassifier()
pipe = Pipeline(steps=[('selector', selector), ('mlpclassifier', mlp)], memory = 'tmp')
gridsearch_init_print('MLPClassifier', param_grid, pipe, strain, strain_labels, stest, stest_labels)

## Parameters to optimize
param_grid = {
    'selector__threshold': [0.003],
    'mlpclassifier__solver': ['lbfgs'], # default ‘adam’
    'mlpclassifier__activation': ['tanh'], # default ‘relu’
    'mlpclassifier__hidden_layer_sizes': [(3,), (5,)], # tuple default (100,).The ith element represents the number of neurons in the ith hidden layer.
    'mlpclassifier__learning_rate': ['adaptive'], # Only used when solver='sgd'.
    'mlpclassifier__max_iter': [500, 1000],
    'mlpclassifier__alpha': [0.05, 0.1] 
}

mlp = MLPClassifier()
pipe = Pipeline(steps=[('selector', selector), ('mlpclassifier', mlp)], memory = 'tmp')
gridsearch_init_print('MLPClassifier', param_grid, pipe, strain, strain_labels, stest, stest_labels)

## Parameters to optimize
param_grid = {
    'selector__threshold': [0.003],
    'mlpclassifier__solver': ['lbfgs'], # default ‘adam’
    'mlpclassifier__activation': ['tanh'], # default ‘relu’
    'mlpclassifier__hidden_layer_sizes': [(1,), (2,), (3,)], # tuple default (100,).The ith element represents the number of neurons in the ith hidden layer.
    'mlpclassifier__learning_rate': ['adaptive'], # Only used when solver='sgd'.
    'mlpclassifier__max_iter': [500, 600],
    'mlpclassifier__alpha': [0.1, 0.2] 
}

mlp = MLPClassifier()
pipe = Pipeline(steps=[('selector', selector), ('mlpclassifier', mlp)], memory = 'tmp')
gridsearch_init_print('MLPClassifier', param_grid, pipe, strain, strain_labels, stest, stest_labels)

## Parameters to optimize
param_grid = {
    'selector__threshold': [0.003],
    'mlpclassifier__solver': ['lbfgs'], # default ‘adam’
    'mlpclassifier__activation': ['tanh'], # default ‘relu’
    'mlpclassifier__hidden_layer_sizes': [(3,)], # tuple default (100,).The ith element represents the number of neurons in the ith hidden layer.
    'mlpclassifier__learning_rate': ['adaptive'], # Only used when solver='sgd'.
    'mlpclassifier__max_iter': [400, 500],
    'mlpclassifier__alpha': [0.2, 0.3, 0.5] 
}

mlp = MLPClassifier()
pipe = Pipeline(steps=[('selector', selector), ('mlpclassifier', mlp)], memory = 'tmp')
gridsearch_init_print('MLPClassifier', param_grid, pipe, strain, strain_labels, stest, stest_labels)

## Parameters to optimize
param_grid = {
    'selector__threshold': [0.003],
    'mlpclassifier__solver': ['lbfgs'], # default ‘adam’
    'mlpclassifier__activation': ['tanh'], # default ‘relu’
    'mlpclassifier__hidden_layer_sizes': [(3,)], # tuple default (100,).The ith element represents the number of neurons in the ith hidden layer.
    'mlpclassifier__learning_rate': ['adaptive'], # Only used when solver='sgd'.
    'mlpclassifier__max_iter': [490, 500, 510],
    'mlpclassifier__alpha': [0.2, 0.25, 0.3, 0.4] 
}

mlp = MLPClassifier()
pipe = Pipeline(steps=[('selector', selector), ('mlpclassifier', mlp)], memory = 'tmp')
gridsearch_init_print('MLPClassifier', param_grid, pipe, strain, strain_labels, stest, stest_labels)

"""Βλέπουμε ότι έχουμε πετύχει πολύ καλά αποτελέσματα και τώρα θα εκπαιδεύσουμε το μεγάλο dataset."""

## Parameters to optimize
param_grid = {
    'selector__threshold': [0.003],
    'mlpclassifier__solver': ['lbfgs'], # default ‘adam’
    'mlpclassifier__activation': ['tanh'], # default ‘relu’
    'mlpclassifier__hidden_layer_sizes': [(3,)], # tuple default (100,).The ith element represents the number of neurons in the ith hidden layer.
    'mlpclassifier__learning_rate': ['adaptive'], # Only used when solver='sgd'.
    'mlpclassifier__max_iter': [500],
    'mlpclassifier__alpha': [0.25] 
}

mlp = MLPClassifier()
pipe = Pipeline(steps=[('selector', selector), ('mlpclassifier', mlp)], memory = 'tmp')
gridsearch_init_print('MLPClassifier', param_grid, pipe)

mlp = MLPClassifier()
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('mlpclassifier', mlp)], memory = 'tmp')
gridsearch_init_print('MLPClassifier', param_grid, pipe)

"""Mε standardization η απόδοση βλέπουμε πως βελτιώθηκε κατά 1%."""

param_grid = {
    'pca__n_components': [10, 20, 30, 40, 50],
    # 'selector__threshold': [0.003],
    'mlpclassifier__solver': ['lbfgs'], # default ‘adam’
    'mlpclassifier__activation': ['tanh'], # default ‘relu’
    'mlpclassifier__hidden_layer_sizes': [(3,)], # tuple default (100,).The ith element represents the number of neurons in the ith hidden layer.
    'mlpclassifier__learning_rate': ['adaptive'], # Only used when solver='sgd'.
    'mlpclassifier__max_iter': [500],
    'mlpclassifier__alpha': [0.25] 
}

mlp = MLPClassifier()
pipe = Pipeline(steps=[('scaler', scaler), ('pca',pca), ('mlpclassifier', mlp)], memory = 'tmp')
gridsearch_init_print('MLPClassifier', param_grid, pipe)

param_grid = {
    'pca__n_components': [35, 38, 45, 47, 50, 53, 56, 57],
    # 'selector__threshold': [0.003],
    'mlpclassifier__solver': ['lbfgs'], # default ‘adam’
    'mlpclassifier__activation': ['tanh'], # default ‘relu’
    'mlpclassifier__hidden_layer_sizes': [(3,)], # tuple default (100,).The ith element represents the number of neurons in the ith hidden layer.
    'mlpclassifier__learning_rate': ['adaptive'], # Only used when solver='sgd'.
    'mlpclassifier__max_iter': [500],
    'mlpclassifier__alpha': [0.25] 
}

mlp = MLPClassifier()
pipe = Pipeline(steps=[('scaler', scaler), ('pca',pca), ('mlpclassifier', mlp)], memory = 'tmp')
gridsearch_init_print('MLPClassifier', param_grid, pipe)

param_grid = {
    'pca__n_components': [53],
    # 'selector__threshold': [0.003],
    'mlpclassifier__solver': ['lbfgs'], # default ‘adam’
    'mlpclassifier__activation': ['tanh'], # default ‘relu’
    'mlpclassifier__hidden_layer_sizes': [(3,)], # tuple default (100,).The ith element represents the number of neurons in the ith hidden layer.
    'mlpclassifier__learning_rate': ['adaptive'], # Only used when solver='sgd'.
    'mlpclassifier__max_iter': [500],
    'mlpclassifier__alpha': [0.25] 
}

mlp = MLPClassifier()
pipe = Pipeline(steps=[('scaler', scaler), ('pca',pca), ('mlpclassifier', mlp)], memory = 'tmp')
gridsearch_init_print('MLPClassifier', param_grid, pipe)

"""Με την μέθοδο pca η απόδοση βελτιωθηκε ελαχιστα."""

mlp = MLPClassifier()
pipe = Pipeline(steps=[('scaler', scaler), ('pca',pca), ('mlpclassifier', mlp)], memory = 'tmp')
gridsearch_init_print('MLPClassifier', param_grid, pipe)

"""Με τον random oversample η απόδοση επίσης βελτιώθηκε, αλλά πάρα πολύ λίγο. Δεν είναι σημαντική η συνεισφορά του.

Αφου τρέξαμε πολλές φορές με διαφορετικές υπερπαραμέτρους παρακάτω παραθέτουμε τις καλύτερες παραμέτρους:

|  Parameter          | Value    |
|---------------------|----------|
| Activation          | tanh     |
| Hidden Layer Sizes  | 3        |
| Learning Rat        | Adaptive |
| Max iterations      | 500      |
| Solver              | lbfgs    |
| Alpha               | 0.25     |

### Optimized SVM Classifier

#### Linear Kernel
"""

## Parameters to optimize
param_grid = {
    'selector__threshold': [0, 0.001, 0.002, 0.003, 0.004],
    'linear_svm__loss': ["hinge", "squared_hinge"], # default ‘squared_hinge’
    'linear_svm__tol': [1e-2, 1e-8, 1e-14] # default 1e-4
}

linear_svm = LinearSVC()
pipe = Pipeline(steps=[('selector', selector), ('linear_svm', linear_svm)], memory = 'tmp')
gridsearch_init_print('SVM_linear', param_grid, pipe, strain, strain_labels, stest, stest_labels)

# Δοκιμάζουμε με μεγαλύτερο tol
param_grid = {
    'selector__threshold': [0, 0.001, 0.002, 0.003, 0.004],
    'linear_svm__loss': ["hinge", "squared_hinge"], # default ‘squared_hinge’
    'linear_svm__tol': [1e-3, 1e-10, 1e-14, 1e-16] # default 1e-4
}

linear_svm = LinearSVC()
pipe = Pipeline(steps=[('selector', selector), ('linear_svm', linear_svm)], memory = 'tmp')
gridsearch_init_print('SVM_linear', param_grid, pipe, strain, strain_labels, stest, stest_labels)

# Δοκιμάζουμε με μεγαλύτερο tol
param_grid = {
    'selector__threshold': [0, 0.001, 0.002, 0.003, 0.004],
    'linear_svm__loss': ["hinge", "squared_hinge"], # default ‘squared_hinge’
    'linear_svm__tol': [1e-14, 1e-16, 1e-20] # default 1e-4
}

linear_svm = LinearSVC()
pipe = Pipeline(steps=[('selector', selector), ('linear_svm', linear_svm)], memory = 'tmp')
gridsearch_init_print('SVM_linear', param_grid, pipe, strain, strain_labels, stest, stest_labels)

# Δοκιμάζουμε με μεγαλύτερο tol
param_grid = {
    'selector__threshold': [0, 0.001, 0.002, 0.003, 0.004],
    'linear_svm__loss': ["hinge", "squared_hinge"], # default ‘squared_hinge’
    'linear_svm__tol': [1e-14, 1e-22, 1e-23] # default 1e-4
}

linear_svm = LinearSVC()
pipe = Pipeline(steps=[('selector', selector), ('linear_svm', linear_svm)], memory = 'tmp')
gridsearch_init_print('SVM_linear', param_grid, pipe, strain, strain_labels, stest, stest_labels)

"""Δε βελτιώθηκε, αντιθέτως χειροτέρευσε, οπότε κρατάμε τις παραμέτρους από το προηγούμενο fit."""

# Δοκιμάζουμε με μεγαλύτερο διαφορετικό threshold
param_grid = {
    'linear_svm__loss': ["hinge"], # default ‘squared_hinge’
    'selector__threshold': [0, 0.001, 0.002, 0.003, 0.004],
    'linear_svm__tol': [1e-14] # default 1e-4
}

linear_svm = LinearSVC()
pipe = Pipeline(steps=[('selector', selector), ('linear_svm', linear_svm)], memory = 'tmp')
gridsearch_init_print('SVM_linear', param_grid, pipe, strain, strain_labels, stest, stest_labels)

# Δοκιμάζουμε με μεγαλύτερο διαφορετικό threshold
param_grid = {
    'linear_svm__loss': ["hinge"], # default ‘squared_hinge’
    'selector__threshold': [0.002],
    'linear_svm__tol': [1e-14] # default 1e-4
}

linear_svm = LinearSVC()
pipe = Pipeline(steps=[('selector', selector), ('linear_svm', linear_svm)], memory = 'tmp')
gridsearch_init_print('SVM_linear', param_grid, pipe, strain, strain_labels, stest, stest_labels)

"""Άρα κρατάμε το hinge για την παράμετρο loss και threshold = 0.002. Τώρα θα εκπαιδεύσουμε το μεγάλο dataset."""

linear_svm = LinearSVC()
pipe = Pipeline(steps=[('selector', selector), ('linear_svm', linear_svm)], memory = 'tmp')
gridsearch_init_print('SVM_linear', param_grid, pipe)

"""Κάνουμε standardization για να δούμε αν βοηθάει."""

linear_svm = LinearSVC()
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('linear_svm', linear_svm)], memory = 'tmp')
gridsearch_init_print('SVM_linear', param_grid, pipe)

"""Φαίνεται να έχει μεγάλη διαφορά, οπότε το κρατάμε. Προσθέτουμε & random oversampler.

Έχουμε ακριβώς τα ίδια αποτελέσματα, οπότε δεν το προσθέτουμε στις επόμενες επαναλήψεις.
"""

linear_svm = LinearSVC()
pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('ros', ros), ('linear_svm', linear_svm)], memory = 'tmp')
gridsearch_init_print('SVM_linear', param_grid, pipe)

"""Ούτε με random oversampler είδαμε καμια σημαντική διαφορά οπότε καταλήγουμε στις παρακάτω παραμέτρους: 

|  Parameter          | Value    |
|---------------------|----------|
| Selector            | 0.04     |
| Loss                | hinge    |
| Tol                 | 1e-20    |

#### RBF Kernel
"""

## Parameters to optimize
param_grid = {
    'rbf_svm__gamma': ['scale', 'auto', 0.2, 1.0, 2.0], # default scale
    'rbf_svm__tol': [1e-2, 1e-4, 1e-8, 1e-14], # default 1e-4
    'rbf_svm__C': [0.1, 0.5, 1.0, 2.0, 5.0, 10.0] # default 1.0
}

rbf_svm = SVC(kernel='rbf')

pipe = Pipeline(steps=[('rbf_svm', rbf_svm)], memory = 'tmp')
gridsearch_init_print('SVM_rbf', param_grid, pipe, strain, strain_labels, stest, stest_labels)

"""Ασχολούμαστε αρχικά με τη βελτιστοποίηση του gamma. Βλέπουμε ότι προτιμάει το auto."""

param_grid = {
    'rbf_svm__gamma': ['auto'], # default scale
    'rbf_svm__tol': [1e-0, 1e-2, 1e-4, 1e-8, 1e-14], # default 1e-4
    'rbf_svm__C': [0.1, 0.5, 1.0, 2.0, 5.0, 10.0] # default 1.0
}

rbf_svm = SVC(kernel='rbf')

pipe = Pipeline(steps=[('rbf_svm', rbf_svm)], memory = 'tmp')
gridsearch_init_print('SVM_rbf', param_grid, pipe, strain, strain_labels, stest, stest_labels)

param_grid = {
    'rbf_svm__gamma': ['auto'], # default scale
    'rbf_svm__tol': [1e-0, 1e-2, 1e-3, 1e-4, 1e-5], # default 1e-4
    'rbf_svm__C': [0.1, 0.5, 1.0, 2.0, 5.0, 10.0] # default 1.0
}

rbf_svm = SVC(kernel='rbf')

pipe = Pipeline(steps=[('rbf_svm', rbf_svm)], memory = 'tmp')
gridsearch_init_print('SVM_rbf', param_grid, pipe, strain, strain_labels, stest, stest_labels)

"""Φαίνεται ότι η καλύτερη επιλογή είναι για tol = 0.001. Δυστυχώς όμως δεν βελτιώνει ούτε στο ελάχιστο την απόδοση του συστήματος. Πιθανότατα έχει να κάνει με την κατανομή του sampled dataset. Κρατάμε προς το παρόν αυτές τις παραμέτρους μέχρι να δοκιμάσουμε το πλήρες dataset."""

param_grid = {
    'rbf_svm__gamma': ['auto'], # default scale
    'rbf_svm__tol': [1e-3], # default 1e-4
    'rbf_svm__C': [0.1, 0.5, 1.0, 2.0, 4.0, 4.5, 5.0, 5.5, 6.0, 10.0] # default 1.0
}

rbf_svm = SVC(kernel='rbf')

pipe = Pipeline(steps=[('rbf_svm', rbf_svm)], memory = 'tmp')
gridsearch_init_print('SVM_rbf', param_grid, pipe, strain, strain_labels, stest, stest_labels)

"""Πάλι δεν φαίνεται να υπάρχει καμία μεταβολή. Συνεχίζουμε με selector, scaler και random oversampler για να δουμε αν υπάρχει διαφορά. """

param_grid = {
    'selector__threshold': [0.0, 0.0001, 0.001, 0.01, 0.1],
    'rbf_svm__gamma': ['auto'], # default scale
    'rbf_svm__tol': [1e-3], # default 1e-4
    'rbf_svm__C': [5.0] # default 1.0
}

rbf_svm = SVC(kernel='rbf')

pipe = Pipeline(steps=[('selector', selector), ('rbf_svm', rbf_svm)], memory = 'tmp')
gridsearch_init_print('SVM_rbf', param_grid, pipe, strain, strain_labels, stest, stest_labels)

"""Όπως βλέπουμε δεν μας βοηθάει ο selector καθόλου. Άρα τον αφαιρούμε.

"""

param_grid = {
    'rbf_svm__gamma': ['auto'], # default scale
    'rbf_svm__tol': [1e-3], # default 1e-4
    'rbf_svm__C': [5.0] # default 1.0
}

rbf_svm = SVC(kernel='rbf')

pipe = Pipeline(steps=[('scaler', scaler), ('rbf_svm', rbf_svm)], memory = 'tmp')
gridsearch_init_print('SVM_rbf', param_grid, pipe, strain, strain_labels, stest, stest_labels)

"""Εδώ βλέπουμε μεγάλη διαφορά σε σχέση με πριν. Μειώθηκαν σημαντικά τα λάθη, οπότε κρατάμε σίγουρα τον scaler. Δοκιμάζουμε pca."""

param_grid = {
    'rbf_svm__gamma': ['auto'], # default scale
    'rbf_svm__tol': [1e-3], # default 1e-4
    'rbf_svm__C': [5.0] # default 1.0
}

rbf_svm = SVC(kernel='rbf')

pipe = Pipeline(steps=[('scaler', scaler), ('pca', pca), ('rbf_svm', rbf_svm)], memory = 'tmp')
gridsearch_init_print('SVM_rbf', param_grid, pipe, strain, strain_labels, stest, stest_labels)

"""Δεν υπήρχε κάποια σημαντική διαφορά. Αφαιρούμε την pca."""

param_grid = {
    'rbf_svm__gamma': ['auto'], # default scale
    'rbf_svm__tol': [1e-3], # default 1e-4
    'rbf_svm__C': [5.0] # default 1.0
}

rbf_svm = SVC(kernel='rbf')

pipe = Pipeline(steps=[('scaler', scaler), ('ros', ros), ('rbf_svm', rbf_svm)], memory = 'tmp')
gridsearch_init_print('SVM_rbf', param_grid, pipe, strain, strain_labels, stest, stest_labels)

"""Τώρα θα δοκιμάσουμε να εκπαιδεύσουμε το κανονικό dataset"""

param_grid = {
    'rbf_svm__gamma': ['auto'], # default scale
    'rbf_svm__tol': [1e-3], # default 1e-4
    'rbf_svm__C': [5.0] # default 1.0
}

rbf_svm = SVC(kernel='rbf')

pipe = Pipeline(steps=[('scaler', scaler), ('ros', ros), ('rbf_svm', rbf_svm)], memory = 'tmp')
gridsearch_init_print('SVM_rbf', param_grid, pipe)

"""Βλέπουμε παρόμοια συμπεριφορά στην απόδοση σε σχέση με το sampled dataset. Το ποσοστό απόδησης μας δείχνει ότι έχουμε διαλέξει αρκετά βέλτιστες παραμέτρους.

Οι καλύτερες παράμετροι που επιλέχθηκαν, παρουσιάζονται παρακάτω.

|  Parameter          | Value    |
|---------------------|----------|
| gamma               | auto     |
| tol                 | 0.001    |
| C                   | 5.0      |

#### Poly Kernel
"""

## Parameters to optimize
param_grid = {
    # 'selector__threshold': [0,0.001, 0.002, 0.003, 0.004],
    'poly_svm__gamma': ['scale', 'auto', 2.0], # default scale
    'poly_svm__tol': [1e-2, 1e-4], # default 1e-4
    'poly_svm__degree': [1, 3], # default 1
    'poly_svm__C': [0.1, 0.5, 1.0, 3.0] # default 1.0
}

poly_svm = SVC(kernel='poly')

pipe = Pipeline(steps=[('poly_svm', poly_svm)], memory = 'tmp')
gridsearch_init_print('SVM_poly', param_grid, pipe, strain, strain_labels, stest, stest_labels)

"""Εδώ παρατηρούμε πως ο χρόνος εκπαίδευσης αυξάνεται σημαντικά και μάλιστα έχουμε μόνο το sampled dataset!

Φυσικά όμως η ακρίβεια ανεβαίνει πάρα πολύ.

Λόγω του μεγάλου χρόνο εκπαίδευσης, θα κάνουμε λιγότερες δοκιμές και θα κρατήσουμε το degree = 1, όπως έβγαλε ήδη.
"""

## Parameters to optimize
param_grid = {
    # 'selector__threshold': [0,0.001, 0.002, 0.003, 0.004],
    'poly_svm__degree': [1], # default 1
    'poly_svm__gamma': [1.0, 2.0, 3.0], # default scale
    'poly_svm__tol': [1e-2, 1e-3], # default 1e-4
    'poly_svm__C': [0.01, 0.1, 0.2] # default 1.0
}

poly_svm = SVC(kernel='poly')

pipe = Pipeline(steps=[('poly_svm', poly_svm)], memory = 'tmp')
gridsearch_init_print('SVM_poly', param_grid, pipe, strain, strain_labels, stest, stest_labels)

"""Βλέπουμε βελτίωση σε σχέση με πριν. Κρατάμε gamma = 3.0."""

## Parameters to optimize
param_grid = {
    # 'selector__threshold': [0,0.001, 0.002, 0.003, 0.004],
    'poly_svm__degree': [1], # default 1
    'poly_svm__gamma': [3.0], # default scale
    'poly_svm__tol': [1e-2, 1e-3, 1e-4, 1e-8], # default 1e-4
    'poly_svm__C': [0.01, 0.1, 0.2, 0.5] # default 1.0
}

poly_svm = SVC(kernel='poly')

pipe = Pipeline(steps=[('poly_svm', poly_svm)], memory = 'tmp')
gridsearch_init_print('SVM_poly', param_grid, pipe, strain, strain_labels, stest, stest_labels)

"""Δεν υπήρξε καμία διαφορά, οπότε κρατάμε μια παράμετρο (tol = 0.01) και δοκιμάζουμε το C ξανά."""

## Parameters to optimize
param_grid = {
    # 'selector__threshold': [0,0.001, 0.002, 0.003, 0.004],
    'poly_svm__degree': [1], # default 1
    'poly_svm__gamma': [2.0], # default scale
    'poly_svm__tol': [1e-2], # default 1e-4
    'poly_svm__C': [0.001, 0.01, 0.1, 0.2, 0.5] # default 1.0
}

poly_svm = SVC(kernel='poly')

pipe = Pipeline(steps=[('poly_svm', poly_svm)], memory = 'tmp')
gridsearch_init_print('SVM_poly', param_grid, pipe, strain, strain_labels, stest, stest_labels)

"""Δεν υπήρξε μεγάλη διαφορά, οπότε δοκιμάζουμε σε περιοχές πιο κοντά στο "βελτιστο" C=0.1"""

## Parameters to optimize
param_grid = {
    # 'selector__threshold': [0,0.001, 0.002, 0.003, 0.004],
    'poly_svm__degree': [1], # default 1
    'poly_svm__gamma': [2.0], # default scale
    'poly_svm__tol': [1e-2], # default 1e-4
    'poly_svm__C': [0.05, 0.1, 0.15] # default 1.0
}

poly_svm = SVC(kernel='poly')

pipe = Pipeline(steps=[('poly_svm', poly_svm)], memory = 'tmp')
gridsearch_init_print('SVM_poly', param_grid, pipe, strain, strain_labels, stest, stest_labels)

"""Ούτε τώρα υπήρξε καμία διαφορά. Θα προσθέσουμε scaler, sampler και pca με τη σειρά, για να δουμε αν θα υπάρξει κάποια διαφορά."""

param_grid = {
    'poly_svm__degree': [1], # default 1
    'poly_svm__gamma': [2.0], # default scale
    'poly_svm__tol': [1e-2], # default 1e-4
    'poly_svm__C': [0.1] # default 1.0
}

poly_svm = SVC(kernel='poly')

pipe = Pipeline(steps=[('scaler', scaler), ('poly_svm', poly_svm)], memory = 'tmp')
gridsearch_init_print('SVM_poly', param_grid, pipe, strain, strain_labels, stest, stest_labels)

"""Βλέπουμε πως ο scaler είχε απόδοση πάνω στο sampled dataset. Τον κρατάμε και δοκιμάζουμε με sampler."""

param_grid = {
    'poly_svm__degree': [1], # default 1
    'poly_svm__gamma': [2.0], # default scale
    'poly_svm__tol': [1e-2], # default 1e-4
    'poly_svm__C': [0.1] # default 1.0
}

poly_svm = SVC(kernel='poly')

pipe = Pipeline(steps=[('scaler', scaler), ('samlper', sampler), ('poly_svm', poly_svm)], memory = 'tmp')
gridsearch_init_print('SVM_poly', param_grid, pipe, strain, strain_labels, stest, stest_labels)

"""Δεν υπήρχε μεγάλη διαφορά σε σχέση με μόνο τον scaler.

Τώρα θα εκπαιδεύσουμε το πλήρες dataset.
"""

param_grid = {
    'poly_svm__degree': [1], # default 1
    'poly_svm__gamma': [2.0], # default scale
    'poly_svm__tol': [1e-2], # default 1e-4
    'poly_svm__C': [0.1] # default 1.0
}

poly_svm = SVC(kernel='poly')

pipe = Pipeline(steps=[('scaler', scaler), ('sampler', ros), ('poly_svm', poly_svm)], memory = 'tmp')
gridsearch_init_print('SVM_poly', param_grid, pipe)

"""Βλέπουμε παρόμοια συμπεριφορά στην απόδοση σε σχέση με το sampled dataset. Ίσως ελάχιστα πεσμένη. Το ποσοστό απόδησης μας δείχνει ότι έχουμε διαλέξει αρκετά βέλτιστες παραμέτρους.

Οι καλύτερες παράμετροι που επιλέχθηκαν, παρουσιάζονται παρακάτω.

|  Parameter          | Value    |
|---------------------|----------|
| degree              | 1        |
| gamma               | 2.0      |
| tol                 | 0.01     |
| C                   | 0.1      |

### Final Results & Comparisons
"""

import matplotlib.pyplot as plt

f1_scores = [f1_micro_default, f1_micro_optimized]
print("F1 micro scores:")
pd.DataFrame(f1_scores, index=['default', 'optimized'])

N = 7
f1_default = list(f1_micro_default.values())

ind = np.arange(N)  # the x locations for the groups
width = 0.35       # the width of the bars

fig, ax = plt.subplots()
rects1 = ax.bar(ind, f1_default, width, color='g')

f1_optimized = list(f1_micro_optimized.values())

rects2 = ax.bar(ind + width, f1_optimized, width, color='b')

# add some text for labels, title and axes ticks
ax.set_ylabel('f1_micro score')
ax.set_title('F1 micro score default vs optimized')
ax.set_xticks(ind + width / 2)
ax.set_xticklabels(list(f1_micro_default.keys()))

ax.legend((rects1[0], rects2[0]), ('default', 'optimized'))

# Turn on the grid
#ax.minorticks_on()
#ax.grid(which='major', linestyle='-', linewidth='0.5', color='red')
# Customize the minor grid
#ax.grid(which='minor', linestyle=':', linewidth='0.5', color='black')

def autolabel(rects):
    """
    Attach a text label above each bar displaying its height
    """
    for rect in rects:
        height = rect.get_height()
        ax.text(rect.get_x() + rect.get_width()/2., 1.01*height,
                "{:.2f}".format(height),
                ha='center', va='bottom')

autolabel(rects1)
autolabel(rects2)

plt.show()

"""##### Comments

Σε κάθε ταξινομητή βλέπουμε μια καλού επιπέδου βελτίωση σε σχέση με το baseline classification. Φυσικά, οι ταξινομητές που είχαν ήδη ένα καλό επίπεδο ακρίβειας, βελτιώνονται λιγότερα, όπως είναι λογικό.

- ο GaussianNB βελτιώθηκε ελάχιστα σε σχέση με πριν.
- ο MLP παρέμεινε σταθερός
- ο kNN βελτιώθηκε κατά λίγο
- ο SVM με linear kernel είχε καλή επίδοση πριν, και βελτιώθηκε λίγο
- ο SVM με rbf kernel είχε μέτρια επίδοση και βελτιώθκε πολύ
- ο SVM με polynomial kernel είχε μέτρια προς κακή επίδοση και είχε την μεγαλύτερη βελτίωση από όλους.

Καλύτερη απόδοση από όλους είχε ο MLP και ο SVM με RBF kernel.

Στους πιο πολλούς ταξινομητές ο scaler φαίνεται να είχε σημαντική συνεισφορά στην βελτίωση της ακρίβειας. Αυτό πιθανότατα συμβαίνει γιατί τα δεδομένα μας είναι πολύ συμπυκνωμένα σε μια περιοχή και κάνοντας τους κανονικοποίηση, βοηθάει την εκπαίδευση του classifier.

Εν αντιθέση, ο random oversampler στους πιο πολλούς δεν είχε καθόλου καλό αποτέλεσμα. Μάλιστα, σε κάποιους η απόδοση έπεσε. Πιθανόν γιατί γίνεται overfitting κάνοντας oversampling.

Η μέθοδος pca βελτίωσε την απόδοση κατά περιπτώσεις.. Σχεδόν οι μισοί ταξινομητές επωφελήθηκαν από τη χρηση της.

Όσον αφορά τον selector (VarianceThreshold) παρόλο που βάλαμε χαμηλές τιμες ως όριο, δεν είχε την απαραίτητη απόδοση. Περιμέναμε δηλαδή οι τιμές που έχουν μικρή διασπορά να μπερδεύουν τον classifier. Πιθανότατα αυτός ήταν ο λόγος που είχε τόσο μεγάλη επίδραση ο scaler. Επειδή είχαμε λίγα features και ήταν όλα κρίσιμη πληροφορία, μόλις τα ξεχωρίζαμε με κανονικοποίηση, είχε μεγάλη διαφορά.

Κοιτώντας έρευνες πάνω στο ίδιο dataset:

- [Adaptive Approach for Spam Detection ](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.412.2911&rep=rep1&type=pdf)
- [Spam Detection Using Feature Selection and Parameters Optimization](https://sci-hub.se/https://ieeexplore.ieee.org/abstract/document/5447486)

μπορούμε να πούμε πως πετυχαίνουμε παρόμοια ποσοστά.
"""