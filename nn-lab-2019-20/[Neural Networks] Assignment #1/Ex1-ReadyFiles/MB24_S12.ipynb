{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ΜΒ24-S12.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "oqcJEQwRnDdO",
        "cMIDOr19nKo6",
        "Sl0vfsrYc-4m",
        "45120CfmgzJb",
        "oQaikIfGcvw1",
        "cr8f1_Axc4fI",
        "xebU-h0ldN58",
        "X_sKL3VPdjK2",
        "YRdxqG4kd3DC",
        "-Ym4ULdPd6o-",
        "PhcQ_caxeGDx",
        "uFh5NnUGQ9SO",
        "WbTMUToWm1d3",
        "2UHYkaYtMuDC",
        "dMrUL--3G_F0",
        "GFDUwXAoOmpD",
        "kyJbkdYzeImt",
        "KW93Qn_MdKfa",
        "PYNgFvG6cxCJ",
        "kYuRVpvYWjHB",
        "TnH4aeVDWqj4",
        "d1GK08jOdZH_",
        "dm_DxswmdfZc",
        "dHITnSyXS2Yo"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEMtmB2UOx3_",
        "colab_type": "text"
      },
      "source": [
        "# Neural Networks & Intelligent Computer Systems | 1st Assignment\n",
        "Team ΜΒ-24 | Small Dataset S12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqcJEQwRnDdO",
        "colab_type": "text"
      },
      "source": [
        "## Section A: Our Team"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwUJsjVJPqLp",
        "colab_type": "text"
      },
      "source": [
        "<table align=\"left\">\n",
        "    <tr align=\"left\"><th>Surname</th><th>Name</th><th>Student ID</th></tr>\n",
        "    <tr><td>Korkovili</td><td>Ioanna</td><td>03115078</td></tr>\n",
        "    <tr><td>Xanthi</td><td>Eleni</td><td>03115054</td></tr>\n",
        "    <tr><td>Tsagkarakis</td><td>Stylianos</td><td>03115180</td></tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMIDOr19nKo6",
        "colab_type": "text"
      },
      "source": [
        "## Section B: Introduction to the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oxX8zE04NHEV"
      },
      "source": [
        "**LSVT Voice Rehabilitation Data Set**\n",
        "\n",
        "This dataset is composed of a range of biomedical speech signal processing algorithms from 14 people who have been diagnosed with Parkinson's disease undergoing LSVT (a program assisting voice rehabilitation). \n",
        "\n",
        "The original study used 309 algorithms to characterize 126 speech signals from 14 people, a robust feature selection mechanism to determine the most parsimonious feature subset, and Support Vector Machines (SVM) and Random Forests (RF) to predict the binary response (acceptable vs unacceptable phonation during rehabilitation). Both cross-validation (10-fold cross validation with 100 repetitions for statistical confidence) and leave one subject out methods were used for the validation of the findings. In both cases we denostrated a near 90% accurate replication of the clinicians' assessment.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl0vfsrYc-4m",
        "colab_type": "text"
      },
      "source": [
        "### Upgrade hosted runtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1rh_BRrITBs",
        "colab_type": "code",
        "outputId": "a6d26490-5f2f-4dab-e7a6-b28ee9d5a46c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!pip install --upgrade pip           #upgrade pip package installer\n",
        "!pip install --upgrade scikit-learn  #upgrade scikit-learn package\n",
        "!pip install --upgrade numpy         #upgrade numpy package\n",
        "!pip install --upgrade pandas        #upgrade #upgrade pandas package\n",
        "!pip install --upgrade joblib\n",
        "!pip install --upgrade imbalanced-learn"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (19.3.1)\n",
            "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.3.3)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.14.1)\n",
            "Requirement already up-to-date: numpy in /usr/local/lib/python3.6/dist-packages (1.17.4)\n",
            "Requirement already up-to-date: pandas in /usr/local/lib/python3.6/dist-packages (0.25.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
            "Requirement already up-to-date: joblib in /usr/local/lib/python3.6/dist-packages (0.14.1)\n",
            "Requirement already up-to-date: imbalanced-learn in /usr/local/lib/python3.6/dist-packages (0.6.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.22 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.22)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.3.3)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.14.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45120CfmgzJb",
        "colab_type": "text"
      },
      "source": [
        "### Retrieve dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFxCg9zSR5v0",
        "colab_type": "code",
        "outputId": "e78535a0-3bf0-45d5-aeca-8cb7e033d1d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import io\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "from urllib.error import HTTPError\n",
        "\n",
        "# responsefile = \"lsvt_binary_response.csv\"\n",
        "# datafile = \"lsvt_data.csv\"\n",
        "# demographicsfile = \"lsvt_demographics.csv\"\n",
        "\n",
        "try:\n",
        "    #data without headers for better manipulation\n",
        "    binary_csv_url = \"https://raw.githubusercontent.com/steliostss/neural_networks_ntua/master/ex1/lsvt_binary_response.csv?token=AH57CIKFAWBUCP4KSDDKT4C576IO6\"\n",
        "    binary_response = pd.read_csv(binary_csv_url, header=None)\n",
        "\n",
        "    # data_csv_url = \"https://raw.githubusercontent.com/steliostss/neural_networks_ntua/master/ex1/lsvt_data_2.csv?token=AH57CINQWC5N4TIH7QQGZXC5753RE\"\n",
        "    data_csv_url = \"https://raw.githubusercontent.com/steliostss/neural_networks_ntua/master/ex1/lsvt_data.csv?token=AH57CIN4KNS65U7AGYDJX5K576HEE\"\n",
        "    data = pd.read_csv(data_csv_url, header=None)\n",
        "\n",
        "    demographics_csv_url = \"https://raw.githubusercontent.com/steliostss/neural_networks_ntua/master/ex1/lsvt_demographics.csv?token=AH57CIJAK62CQJZTPBS22JK57475Q\"\n",
        "    demographics = pd.read_csv(demographics_csv_url, header=None)\n",
        "\n",
        "    #data with headers for better visualizing\n",
        "    demographics_headers = pd.read_csv(demographics_csv_url)\n",
        "    data_headers = pd.read_csv(data_csv_url)\n",
        "    binary_response_headers = pd.read_csv(binary_csv_url)\n",
        "\n",
        "    print(\"Succesful file processing!\")\n",
        "\n",
        "except HTTPError:\n",
        "    print(\"URL not working.\")\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Succesful file processing!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQaikIfGcvw1",
        "colab_type": "text"
      },
      "source": [
        "### Printing for validation / visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9P8e258R-DQ",
        "colab_type": "code",
        "outputId": "53bf0eed-4358-43ad-9fb4-1dd9780da09f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "#print for better visualization\n",
        "data_headers.head(3)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Jitter-&gt;F0_abs_dif</th>\n",
              "      <th>Jitter-&gt;F0_dif_percent</th>\n",
              "      <th>Jitter-&gt;F0_PQ5_classical_Schoentgen</th>\n",
              "      <th>Jitter-&gt;F0_PQ5_classical_Baken</th>\n",
              "      <th>Jitter-&gt;F0_PQ5_generalised_Schoentgen</th>\n",
              "      <th>Jitter-&gt;F0_abs0th_perturb</th>\n",
              "      <th>Jitter-&gt;F0_CV</th>\n",
              "      <th>Jitter-&gt;F0_TKEO_mean</th>\n",
              "      <th>Jitter-&gt;F0_TKEO_std</th>\n",
              "      <th>Jitter-&gt;F0_TKEO_prc5</th>\n",
              "      <th>Jitter-&gt;F0_TKEO_prc25</th>\n",
              "      <th>Jitter-&gt;F0_TKEO_prc75</th>\n",
              "      <th>Jitter-&gt;F0_TKEO_prc95</th>\n",
              "      <th>Jitter-&gt;F0_FM</th>\n",
              "      <th>Jitter-&gt;F0range_5_95_perc</th>\n",
              "      <th>Jitter-&gt;pitch_abs</th>\n",
              "      <th>Jitter-&gt;pitch_percent</th>\n",
              "      <th>Jitter-&gt;pitch_PQ5_classical_Schoentgen</th>\n",
              "      <th>Jitter-&gt;pitch_PQ5_classical_Baken</th>\n",
              "      <th>Jitter-&gt;pitch_PQ5_generalised_Schoentgen</th>\n",
              "      <th>Jitter-&gt;pitch_abs0th_perturb</th>\n",
              "      <th>Jitter-&gt;pitch_CV</th>\n",
              "      <th>Jitter-&gt;pitch_TKEO_mean</th>\n",
              "      <th>Jitter-&gt;pitch_TKEO_std</th>\n",
              "      <th>Jitter-&gt;pitch_TKEO_prc5</th>\n",
              "      <th>Jitter-&gt;pitch_TKEO_prc25</th>\n",
              "      <th>Jitter-&gt;pitch_TKEO_prc75</th>\n",
              "      <th>Jitter-&gt;pitch_TKEO_prc95</th>\n",
              "      <th>Jitter-&gt;pitch_FM</th>\n",
              "      <th>Jitter-&gt;pitch_range_5_95_perc</th>\n",
              "      <th>Shimmer-&gt;Ampl_abs_dif</th>\n",
              "      <th>Shimmer-&gt;Ampl_dif_percent</th>\n",
              "      <th>Shimmer-&gt;Ampl_PQ3_classical_Schoentgen</th>\n",
              "      <th>Shimmer-&gt;Ampl_PQ3_classical_Baken</th>\n",
              "      <th>Shimmer-&gt;Ampl_PQ3_generalised_Schoentgen</th>\n",
              "      <th>Shimmer-&gt;Ampl_PQ5_classical_Schoentgen</th>\n",
              "      <th>Shimmer-&gt;Ampl_PQ5_classical_Baken</th>\n",
              "      <th>Shimmer-&gt;Ampl_PQ5_generalised_Schoentgen</th>\n",
              "      <th>Shimmer-&gt;Ampl_PQ11_classical_Schoentgen</th>\n",
              "      <th>Shimmer-&gt;Ampl_PQ11_classical_Baken</th>\n",
              "      <th>...</th>\n",
              "      <th>entropy_shannon4_1_coef</th>\n",
              "      <th>entropy_shannon4_2_coef</th>\n",
              "      <th>entropy_shannon4_3_coef</th>\n",
              "      <th>entropy_shannon4_4_coef</th>\n",
              "      <th>entropy_shannon4_5_coef</th>\n",
              "      <th>entropy_shannon4_6_coef</th>\n",
              "      <th>entropy_shannon4_7_coef</th>\n",
              "      <th>entropy_shannon4_8_coef</th>\n",
              "      <th>entropy_shannon4_9_coef</th>\n",
              "      <th>entropy_shannon4_10_coef</th>\n",
              "      <th>entropy_log4_1_coef</th>\n",
              "      <th>entropy_log4_2_coef</th>\n",
              "      <th>entropy_log4_3_coef</th>\n",
              "      <th>entropy_log4_4_coef</th>\n",
              "      <th>entropy_log4_5_coef</th>\n",
              "      <th>entropy_log4_6_coef</th>\n",
              "      <th>entropy_log4_7_coef</th>\n",
              "      <th>entropy_log4_8_coef</th>\n",
              "      <th>entropy_log4_9_coef</th>\n",
              "      <th>entropy_log4_10_coef</th>\n",
              "      <th>det_TKEO_mean4_1_coef</th>\n",
              "      <th>det_TKEO_mean4_2_coef</th>\n",
              "      <th>det_TKEO_mean4_3_coef</th>\n",
              "      <th>det_TKEO_mean4_4_coef</th>\n",
              "      <th>det_TKEO_mean4_5_coef</th>\n",
              "      <th>det_TKEO_mean4_6_coef</th>\n",
              "      <th>det_TKEO_mean4_7_coef</th>\n",
              "      <th>det_TKEO_mean4_8_coef</th>\n",
              "      <th>det_TKEO_mean4_9_coef</th>\n",
              "      <th>det_TKEO_mean4_10_coef</th>\n",
              "      <th>det_TKEO_std4_1_coef</th>\n",
              "      <th>det_TKEO_std4_2_coef</th>\n",
              "      <th>det_TKEO_std4_3_coef</th>\n",
              "      <th>det_TKEO_std4_4_coef</th>\n",
              "      <th>det_TKEO_std4_5_coef</th>\n",
              "      <th>det_TKEO_std4_6_coef</th>\n",
              "      <th>det_TKEO_std4_7_coef</th>\n",
              "      <th>det_TKEO_std4_8_coef</th>\n",
              "      <th>det_TKEO_std4_9_coef</th>\n",
              "      <th>det_TKEO_std4_10_coef</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.088112</td>\n",
              "      <td>0.041697</td>\n",
              "      <td>0.000480</td>\n",
              "      <td>-3.723304e-06</td>\n",
              "      <td>0.000422</td>\n",
              "      <td>2.458381</td>\n",
              "      <td>6.332164e-07</td>\n",
              "      <td>47.021079</td>\n",
              "      <td>1366.430390</td>\n",
              "      <td>-7.103323</td>\n",
              "      <td>-2.687924</td>\n",
              "      <td>-0.035674</td>\n",
              "      <td>2.849068</td>\n",
              "      <td>0.042287</td>\n",
              "      <td>9.116401</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.041920</td>\n",
              "      <td>0.000482</td>\n",
              "      <td>4.354061e-06</td>\n",
              "      <td>0.000440</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>6.856367e-07</td>\n",
              "      <td>2.536591e-08</td>\n",
              "      <td>7.412680e-07</td>\n",
              "      <td>-3.524844e-09</td>\n",
              "      <td>-1.382237e-09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.367104e-09</td>\n",
              "      <td>0.042287</td>\n",
              "      <td>0.000204</td>\n",
              "      <td>0.069838</td>\n",
              "      <td>11.566415</td>\n",
              "      <td>0.077160</td>\n",
              "      <td>-0.000064</td>\n",
              "      <td>0.081880</td>\n",
              "      <td>0.092070</td>\n",
              "      <td>-0.000057</td>\n",
              "      <td>0.081880</td>\n",
              "      <td>0.100744</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>...</td>\n",
              "      <td>-233661.1245</td>\n",
              "      <td>-277726.2665</td>\n",
              "      <td>-327634.1744</td>\n",
              "      <td>-390417.4249</td>\n",
              "      <td>-481323.9141</td>\n",
              "      <td>-633245.6446</td>\n",
              "      <td>-9.018569e+05</td>\n",
              "      <td>-1.433921e+06</td>\n",
              "      <td>-2528415.988</td>\n",
              "      <td>-4819157.284</td>\n",
              "      <td>4076.864063</td>\n",
              "      <td>2422.969509</td>\n",
              "      <td>1429.320757</td>\n",
              "      <td>851.745520</td>\n",
              "      <td>525.181116</td>\n",
              "      <td>345.610973</td>\n",
              "      <td>246.183529</td>\n",
              "      <td>195.776526</td>\n",
              "      <td>172.652511</td>\n",
              "      <td>164.557388</td>\n",
              "      <td>0.112549</td>\n",
              "      <td>0.443874</td>\n",
              "      <td>1.728619</td>\n",
              "      <td>6.539524</td>\n",
              "      <td>23.606344</td>\n",
              "      <td>79.049121</td>\n",
              "      <td>242.544297</td>\n",
              "      <td>661.679929</td>\n",
              "      <td>1618.318338</td>\n",
              "      <td>3643.234312</td>\n",
              "      <td>2.527583</td>\n",
              "      <td>7.088978</td>\n",
              "      <td>19.753255</td>\n",
              "      <td>54.335046</td>\n",
              "      <td>145.528630</td>\n",
              "      <td>375.097397</td>\n",
              "      <td>921.296579</td>\n",
              "      <td>2137.079844</td>\n",
              "      <td>4697.131077</td>\n",
              "      <td>9931.208257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.161798</td>\n",
              "      <td>0.057364</td>\n",
              "      <td>0.000677</td>\n",
              "      <td>5.466365e-06</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>2.592066</td>\n",
              "      <td>7.228518e-07</td>\n",
              "      <td>93.557936</td>\n",
              "      <td>2582.922776</td>\n",
              "      <td>-23.284761</td>\n",
              "      <td>-7.533801</td>\n",
              "      <td>-0.347630</td>\n",
              "      <td>7.457385</td>\n",
              "      <td>0.042783</td>\n",
              "      <td>11.568865</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.057055</td>\n",
              "      <td>0.000673</td>\n",
              "      <td>-5.419147e-06</td>\n",
              "      <td>0.000205</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>7.013483e-07</td>\n",
              "      <td>1.408057e-08</td>\n",
              "      <td>3.872420e-07</td>\n",
              "      <td>-3.561551e-09</td>\n",
              "      <td>-1.164851e-09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.195081e-09</td>\n",
              "      <td>0.042783</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.047107</td>\n",
              "      <td>7.202769</td>\n",
              "      <td>0.047907</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>0.055919</td>\n",
              "      <td>0.052175</td>\n",
              "      <td>0.000542</td>\n",
              "      <td>0.055919</td>\n",
              "      <td>0.072145</td>\n",
              "      <td>0.000223</td>\n",
              "      <td>...</td>\n",
              "      <td>-266292.2262</td>\n",
              "      <td>-315357.3478</td>\n",
              "      <td>-371033.9862</td>\n",
              "      <td>-441256.8092</td>\n",
              "      <td>-543227.8848</td>\n",
              "      <td>-713976.6286</td>\n",
              "      <td>-1.015830e+06</td>\n",
              "      <td>-1.613896e+06</td>\n",
              "      <td>-2843879.522</td>\n",
              "      <td>-5416842.350</td>\n",
              "      <td>4182.699168</td>\n",
              "      <td>2476.698050</td>\n",
              "      <td>1456.995087</td>\n",
              "      <td>866.391724</td>\n",
              "      <td>533.314567</td>\n",
              "      <td>350.486711</td>\n",
              "      <td>249.368427</td>\n",
              "      <td>198.116666</td>\n",
              "      <td>174.570294</td>\n",
              "      <td>166.263182</td>\n",
              "      <td>0.126734</td>\n",
              "      <td>0.499301</td>\n",
              "      <td>1.941236</td>\n",
              "      <td>7.344723</td>\n",
              "      <td>26.518497</td>\n",
              "      <td>88.784513</td>\n",
              "      <td>272.216266</td>\n",
              "      <td>742.338942</td>\n",
              "      <td>1814.494579</td>\n",
              "      <td>4082.136146</td>\n",
              "      <td>2.841881</td>\n",
              "      <td>7.977363</td>\n",
              "      <td>22.203504</td>\n",
              "      <td>60.993338</td>\n",
              "      <td>163.560972</td>\n",
              "      <td>421.010306</td>\n",
              "      <td>1036.092589</td>\n",
              "      <td>2404.072562</td>\n",
              "      <td>5284.082128</td>\n",
              "      <td>11165.095660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.554508</td>\n",
              "      <td>0.642913</td>\n",
              "      <td>0.007576</td>\n",
              "      <td>-7.443871e-07</td>\n",
              "      <td>0.006488</td>\n",
              "      <td>12.691326</td>\n",
              "      <td>6.946246e-04</td>\n",
              "      <td>52.988422</td>\n",
              "      <td>466.682635</td>\n",
              "      <td>-45.308680</td>\n",
              "      <td>-5.175259</td>\n",
              "      <td>-0.359585</td>\n",
              "      <td>4.549093</td>\n",
              "      <td>0.471729</td>\n",
              "      <td>39.079991</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.563163</td>\n",
              "      <td>0.006659</td>\n",
              "      <td>7.576645e-07</td>\n",
              "      <td>0.004372</td>\n",
              "      <td>0.001604</td>\n",
              "      <td>2.103274e-04</td>\n",
              "      <td>6.191656e-07</td>\n",
              "      <td>4.898115e-06</td>\n",
              "      <td>-8.230807e-07</td>\n",
              "      <td>-9.233181e-08</td>\n",
              "      <td>6.432232e-09</td>\n",
              "      <td>1.350863e-07</td>\n",
              "      <td>0.471729</td>\n",
              "      <td>0.005443</td>\n",
              "      <td>0.190733</td>\n",
              "      <td>34.449823</td>\n",
              "      <td>0.229084</td>\n",
              "      <td>-0.001374</td>\n",
              "      <td>0.259091</td>\n",
              "      <td>0.276145</td>\n",
              "      <td>0.001280</td>\n",
              "      <td>0.259091</td>\n",
              "      <td>0.315005</td>\n",
              "      <td>0.001812</td>\n",
              "      <td>...</td>\n",
              "      <td>-146466.6898</td>\n",
              "      <td>-176648.5331</td>\n",
              "      <td>-210656.5286</td>\n",
              "      <td>-253144.2859</td>\n",
              "      <td>-314304.4696</td>\n",
              "      <td>-416010.0510</td>\n",
              "      <td>-5.956926e+05</td>\n",
              "      <td>-9.520312e+05</td>\n",
              "      <td>-1686351.172</td>\n",
              "      <td>-3224775.436</td>\n",
              "      <td>3699.830964</td>\n",
              "      <td>2231.698375</td>\n",
              "      <td>1330.932885</td>\n",
              "      <td>799.805232</td>\n",
              "      <td>496.476954</td>\n",
              "      <td>328.515054</td>\n",
              "      <td>235.080823</td>\n",
              "      <td>187.675057</td>\n",
              "      <td>166.054276</td>\n",
              "      <td>158.705559</td>\n",
              "      <td>0.080899</td>\n",
              "      <td>0.318113</td>\n",
              "      <td>1.228114</td>\n",
              "      <td>4.615947</td>\n",
              "      <td>16.650282</td>\n",
              "      <td>55.476114</td>\n",
              "      <td>169.270664</td>\n",
              "      <td>461.248613</td>\n",
              "      <td>1125.194320</td>\n",
              "      <td>2523.348299</td>\n",
              "      <td>1.806103</td>\n",
              "      <td>5.078616</td>\n",
              "      <td>14.135923</td>\n",
              "      <td>38.641654</td>\n",
              "      <td>103.466808</td>\n",
              "      <td>264.654626</td>\n",
              "      <td>649.657090</td>\n",
              "      <td>1507.384591</td>\n",
              "      <td>3315.804236</td>\n",
              "      <td>6974.600636</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 310 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Jitter->F0_abs_dif  ...  det_TKEO_std4_10_coef\n",
              "0            0.088112  ...            9931.208257\n",
              "1            0.161798  ...           11165.095660\n",
              "2            0.554508  ...            6974.600636\n",
              "\n",
              "[3 rows x 310 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fhcg2Jv0jZHT",
        "colab_type": "code",
        "outputId": "ae2a2d15-e819-4237-8843-47030a3a7664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "#print for better visualization\n",
        "demographics_headers.head(3)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Subject_index</th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender, 0-&gt;Male, 1-&gt;Female</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>68</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>68</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>68</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Subject_index  Age  Gender, 0->Male, 1->Female\n",
              "0              1   68                           1\n",
              "1              1   68                           1\n",
              "2              1   68                           1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F28WDEwQjd98",
        "colab_type": "code",
        "outputId": "b56ebea2-9b61-4290-e223-61113c8d8bd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "#print for better visualization\n",
        "binary_response_headers.head(3)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   1\n",
              "0  2\n",
              "1  2\n",
              "2  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr8f1_Axc4fI",
        "colab_type": "text"
      },
      "source": [
        "### Custom functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqedVc1YuZ_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## GATHER ALL FUNCTIONS FOR SECTION-B HERE\n",
        "\n",
        "# evaluate type of value in the given variable\n",
        "def tryeval(np_samples):\n",
        "    for row in range(len(np_samples)): \n",
        "        for col in range(len(np_samples[row])):\n",
        "            try: \n",
        "                np_samples[row][col] = ast.literal_eval(np_samples[row][col])\n",
        "            except ValueError:\n",
        "                pass\n",
        "    return np_samples\n",
        "\n",
        "def tryeval1D(np_samples):\n",
        "    for row in range(len(np_samples)): \n",
        "        try: \n",
        "            np_samples[row] = ast.literal_eval(np_samples[row])\n",
        "        except ValueError:\n",
        "            pass\n",
        "    return np_samples\n",
        "\n",
        "# define if all features have the same type\n",
        "def features_datatypes(features):\n",
        "    datatypes = list()\n",
        "    for row in range(len(features)):\n",
        "        for col in range(len(features[row])):\n",
        "            current_type = type(features[row][col])\n",
        "            if current_type not in datatypes:\n",
        "                datatypes.append(current_type)\n",
        "\n",
        "    return datatypes\n",
        "# define all class labels\n",
        "def class_labels(labels):\n",
        "    cLabels = list()\n",
        "    for col in range(len(labels)):\n",
        "        current_val = labels[col]\n",
        "        if current_val not in cLabels:\n",
        "            cLabels.append(current_val)\n",
        "    return cLabels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xebU-h0ldN58",
        "colab_type": "text"
      },
      "source": [
        "### Manage datafile, get desired data\n",
        "\n",
        "Get #features, #samples, type of features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK69s1JQXlRp",
        "colab_type": "code",
        "outputId": "92d85697-6359-4119-de23-a65a0f3d27b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# gather data features in a table\n",
        "data_features = data.iloc[[0],0:]\n",
        "( _ , number_of_features ) = data_features.shape\n",
        "print(\"Q2: Number of features = \", number_of_features)\n",
        "# print(data_features.shape) # uncomment if you want to check the results\n",
        "\n",
        "# gather data samples in a table\n",
        "data_samples = data.iloc[1:,0:]\n",
        "( number_of_samples , _ ) = data_samples.shape\n",
        "print(\"Q2: Number of samples = \", number_of_samples)\n",
        "# print(data_samples.shape) # uncomment if you want to check the results\n",
        "\n",
        "# transform the gathered data in numpy arrays\n",
        "np_features = data_features.values\n",
        "np_samples = data_samples.values\n",
        "\n",
        "# # convert the type of samples to the correct type\n",
        "np_samples = tryeval(np_samples)\n",
        "datatypes = features_datatypes(np_samples)\n",
        "\n",
        "print(\"Q2: Type of features =\", end=' ')\n",
        "print(*datatypes, sep=' & ')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q2: Number of features =  310\n",
            "Q2: Number of samples =  126\n",
            "Q2: Type of features = <class 'float'> & <class 'int'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJ5SyhuoCnYE",
        "colab_type": "text"
      },
      "source": [
        "- Q3: There are headers in the first line\n",
        "\n",
        "- Q3: There is no line numbering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T01BLPCTqzlU",
        "colab_type": "code",
        "outputId": "2ba9ec02-0004-407c-9b24-6e533e75957b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# gather class labels in a table\n",
        "binary_class_labels = binary_response.iloc[0:,:] \n",
        "np_labels_temp = binary_class_labels.values.flatten()\n",
        "\n",
        "np_labels = list()\n",
        "for item in np_labels_temp:\n",
        "    np_labels.append(item)\n",
        "\n",
        "np_labels = np.array(np_labels)\n",
        "\n",
        "np_labels = tryeval1D(np_labels)\n",
        "\n",
        "np_labels"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1,\n",
              "       2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2,\n",
              "       2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2,\n",
              "       1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1,\n",
              "       2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2,\n",
              "       2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_sKL3VPdjK2",
        "colab_type": "text"
      },
      "source": [
        "### Classification Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "choIDcboiKGE",
        "colab_type": "code",
        "outputId": "2bd26da3-2a1d-4d25-d37d-af44c249f3e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# make a list with all different labels\n",
        "list_of_labels = class_labels(np_labels)\n",
        "print(\"Q4: Classification Labels =\", end=' ')\n",
        "print(*list_of_labels, sep = \" & \")\n",
        "\n",
        "label_names = list()\n",
        "for i in range(len(list_of_labels)):\n",
        "    label_names.append(str(list_of_labels[i]))\n",
        "# label_names = ('1','2')\n",
        "label_names"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q4: Classification Labels = 1 & 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1', '2']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aMVqYiNCv8k",
        "colab_type": "text"
      },
      "source": [
        "### Modifications on the datafile\n",
        "- Q5: There were some modifications on the data. \n",
        "    - We replaced **\" , \"** with **\" . \"**\n",
        "    - We removed the headers on the binary response file.\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRdxqG4kd3DC",
        "colab_type": "text"
      },
      "source": [
        "### Check Empty dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms5TCwkoS_AU",
        "colab_type": "code",
        "outputId": "d1c46c91-2202-4f63-af7c-8a0cf5f32cd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# check if dataset has empty values\n",
        "# and if, how many of them\n",
        "!ls\n",
        "!echo \"For binary_response file, empty values: \"\n",
        "!cat lsvt_binary_response.csv | grep \"?\" | wc -l\n",
        "!echo \"For data file, empty values: \"\n",
        "!cat lsvt_data.csv | grep \"?\" | wc -l\n",
        "!echo \"For demographics file, empty values: \"\n",
        "!cat lsvt_demographics.csv | grep \"?\" | wc -l"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n",
            "For binary_response file, empty values: \n",
            "cat: lsvt_binary_response.csv: No such file or directory\n",
            "0\n",
            "For data file, empty values: \n",
            "cat: lsvt_data.csv: No such file or directory\n",
            "0\n",
            "For demographics file, empty values: \n",
            "cat: lsvt_demographics.csv: No such file or directory\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ym4ULdPd6o-",
        "colab_type": "text"
      },
      "source": [
        "### Label frequencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRqXg0dzI5Va",
        "colab_type": "code",
        "outputId": "def0056d-2dff-4aa2-ee4e-6e28da44c52a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "print(\"frequencies:\", np.bincount(np_labels))\n",
        "freq = np.bincount(np_labels)\n",
        "for i in range(len(freq)):\n",
        "    if i == 0: continue\n",
        "    print(\"For label:\", i, \"percentage is\", \"{:.2%}\".format(freq[i]/number_of_samples))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frequencies: [ 0 42 84]\n",
            "For label: 1 percentage is 33.33%\n",
            "For label: 2 percentage is 66.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FY5CeA09SZBc",
        "colab_type": "text"
      },
      "source": [
        "Το παραπάνω dataset όπως φαίνεται από τις συχνότητες δεν είναι ισορροπημένο.\n",
        "Καθώς το δείγμα είναι μικρό επιλέγουμε να κανουμε oversampling για να μη χάσουμε κρίσιμη πληροφορία. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhcQ_caxeGDx",
        "colab_type": "text"
      },
      "source": [
        "### Split to test and train set\n",
        "\n",
        "After spliting, we oversample the train set to be balanced"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMx9wyt8SzfP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.metrics import confusion_matrix, classification_report \n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.over_sampling import SMOTE "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qndH6YbP8wy",
        "colab_type": "code",
        "outputId": "90cd54bd-9075-41f7-e952-6aa1e72aa166",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split our data\n",
        "train, test, train_labels, test_labels = train_test_split(np_samples, \n",
        "                                                          np_labels, \n",
        "                                                          test_size=0.2)\n",
        "\n",
        "# sampler = SMOTE()\n",
        "# train, train_labels = sampler.fit_sample(np_samples, np_labels)\n",
        "\n",
        "train_set_length = len(train)\n",
        "# print length of train set to validate oversampling\n",
        "print(\"#samples in train set =\", train_set_length, '\\n')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#samples in train set = 100 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAmCcm6dVUTo",
        "colab_type": "text"
      },
      "source": [
        "**Q8**: Our samples are **ordered tuples** since each number corresponds to a specific attribute."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFh5NnUGQ9SO",
        "colab_type": "text"
      },
      "source": [
        "## Section C: Baseline Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbTMUToWm1d3",
        "colab_type": "text"
      },
      "source": [
        "### Custom functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vfYRlvnHQ7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import classification_report\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def print_precision_recall_fscore_support(method, test_labels, pred, label_names):\n",
        "    print(method, end = '\\n\\n')\n",
        "    (none, micro, macro, weighted) = get_PRFS(method, test_labels, pred, label_names)\n",
        "    # εκτυπώνουμε 4 πίνακες, precision, recall, F1 και support. Support είναι ο συνολικός αριθμός προβλέψεων σε κάθε κλάση\n",
        "    # το πρώτο στοιχείο του κάθε πίνακα είναι η κλάση 1 και το δεύτερο η κλάσση 2\n",
        "    print(\"none     :\", none )\n",
        "    # εκτυπώνουμε τa precision, recall και F1 λαμβάνοντας υπόψη συνολικά (αθροίζοντας εκτός κλάσεων) τα δείγματα (average = micro).\n",
        "    print(\"micro    :\", micro )\n",
        "    # εκτυπώνουμε το μέσο όρο των precision, recall και F1 θεωρόντας ότι οι κλάσεις έχουν το ίδιο βάρος (average = macro)\n",
        "    print(\"macro    :\", macro )\n",
        "    # εκτυπώνουμε τa precision, recall και F1 λαμβάνοντας. Με average = weighted κάθε κλάση μετρά στο μέσο όρο ανάλογα με το support της.\n",
        "    print(\"weighted :\", weighted, end = '\\n\\n')\n",
        "    # η classification_report τυπώνει πιο ωραία οπτικά σε string τα αποτελέσματα\n",
        "    # πρώτα για κάθε κλάση και μετά με μέσους όρους\n",
        "    print(classification_report(test_labels, pred, target_names=label_names), end = '\\n\\n')\n",
        "\n",
        "    ( _ , _ , microF1    , _ ) = micro\n",
        "    ( _ , _ , macroF1    , _ ) = macro\n",
        "    ( _ , _ , weightedF1 , _ ) = weighted\n",
        "\n",
        "    barplotF1 = (microF1, macroF1, weightedF1)\n",
        "    xaxis = (\"microF1\", \"macroF1\", \"weightedF1\")\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.bar(xaxis, barplotF1)\n",
        "    plt.show()\n",
        "    print(\"---------------------------------------------------------------------------------------------------------------------\", end = '\\n')\n",
        "    print(\"---------------------------------------------------------------------------------------------------------------------\", end = '\\n\\n')\n",
        "\n",
        "# get_precision_recall_fscore_support\n",
        "def get_PRFS(method, test_labels, pred, label_names):\n",
        "    none = precision_recall_fscore_support(test_labels, pred, average=None)\n",
        "    micro = precision_recall_fscore_support(test_labels, pred, average='micro')\n",
        "    macro = precision_recall_fscore_support(test_labels, pred, average='macro')\n",
        "    weighted = precision_recall_fscore_support(test_labels, pred, average='weighted')\n",
        "    return (none, micro, macro, weighted)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UHYkaYtMuDC",
        "colab_type": "text"
      },
      "source": [
        "### Dummy Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnWtPk3JQqFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dc_uniform = DummyClassifier(strategy=\"uniform\")\n",
        "dc_constant_1 = DummyClassifier(strategy=\"constant\", constant=1)\n",
        "dc_constant_2 = DummyClassifier(strategy=\"constant\", constant=2)\n",
        "dc_most_frequent = DummyClassifier(strategy=\"most_frequent\")\n",
        "dc_stratified = DummyClassifier(strategy=\"stratified\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFpM-0ZMYr4q",
        "colab_type": "code",
        "outputId": "e5b624d9-4cd3-4e42-a04b-643a5b28322f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# με τη μέθοδο fit \"εκπαιδεύουμε\" τον ταξινομητή στο σύνολο εκπαίδευσης (τα χαρακτηριστικά και τις ετικέτες τους)\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# με τη μέθοδο predict παράγουμε προβλέψεις για τα δεδομένα ελέγχου (είσοδος τα χαρακτηριστικά μόνο)\n",
        "predictions = {}\n",
        "lsvt_accuracy = {}\n",
        "\n",
        "model = dc_uniform.fit(train, train_labels)\n",
        "preds = dc_uniform.predict(test)\n",
        "predictions['dc_uniform'] = preds\n",
        "lsvt_accuracy['uniform (random)'] = accuracy_score(test_labels, preds)\n",
        "\n",
        "\n",
        "model = dc_constant_1.fit(train, train_labels)\n",
        "preds = dc_constant_1.predict(test)\n",
        "predictions['dc_constant_1'] = preds\n",
        "lsvt_accuracy['constant 1'] = accuracy_score(test_labels, preds)\n",
        "\n",
        "model = dc_constant_2.fit(train, train_labels)\n",
        "preds = dc_constant_2.predict(test)\n",
        "predictions['dc_constant_2'] = preds\n",
        "lsvt_accuracy['constant 2'] = accuracy_score(test_labels, preds)\n",
        "\n",
        "model = dc_most_frequent.fit(train, train_labels)\n",
        "preds = dc_most_frequent.predict(test)\n",
        "predictions['dc_most_frequent'] = preds\n",
        "lsvt_accuracy['most frequent label'] = accuracy_score(test_labels, preds)\n",
        "\n",
        "model = dc_stratified.fit(train, train_labels)\n",
        "preds = dc_stratified.predict(test)\n",
        "predictions['dc_stratified'] = preds\n",
        "lsvt_accuracy['stratified'] = accuracy_score(test_labels, preds)\n",
        "\n",
        "for i in predictions:\n",
        "    print(\"Prediction for\", i, '=', predictions[i])\n",
        "\n",
        "print()\n",
        "    \n",
        "print(\"Classification Accuracy on the LSVT Voice Rehabilitation Dataset (20% test set)\\n\")\n",
        "sorted_accuracy = [(k, lsvt_accuracy[k]) for k in sorted(lsvt_accuracy, key=lsvt_accuracy.get, reverse=True)]\n",
        "\n",
        "print(\"----------Results are sorted----------\")\n",
        "print(\"** Strategy (score, accuracy_score) **\\n\")\n",
        "for k,v in sorted_accuracy:\n",
        "    print(k,v)\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction for dc_uniform = [1 1 2 2 1 1 2 2 1 2 2 1 2 2 2 1 1 2 1 2 2 1 2 1 1 1]\n",
            "Prediction for dc_constant_1 = [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Prediction for dc_constant_2 = [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Prediction for dc_most_frequent = [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Prediction for dc_stratified = [2 1 1 2 2 2 1 1 2 1 2 2 2 1 1 1 2 2 2 1 2 2 2 2 1 2]\n",
            "\n",
            "Classification Accuracy on the LSVT Voice Rehabilitation Dataset (20% test set)\n",
            "\n",
            "----------Results are sorted----------\n",
            "** Strategy (score, accuracy_score) **\n",
            "\n",
            "constant 2 0.6538461538461539\n",
            "most frequent label 0.6538461538461539\n",
            "stratified 0.5\n",
            "uniform (random) 0.46153846153846156\n",
            "constant 1 0.34615384615384615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuLFQ5lCZSsv",
        "colab_type": "code",
        "outputId": "a45072aa-01ac-4b82-cf77-904b86245100",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "# Compute confusion matrix\n",
        "\n",
        "print(\"Confusion matrices\\n\")\n",
        "for i in predictions:\n",
        "    # τυπώνουμε το confusion matrix\n",
        "    cnf_matrix = confusion_matrix(test_labels, predictions[i])\n",
        "    print(i)\n",
        "    print(cnf_matrix, end='\\n\\n')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrices\n",
            "\n",
            "dc_uniform\n",
            "[[4 5]\n",
            " [9 8]]\n",
            "\n",
            "dc_constant_1\n",
            "[[ 9  0]\n",
            " [17  0]]\n",
            "\n",
            "dc_constant_2\n",
            "[[ 0  9]\n",
            " [ 0 17]]\n",
            "\n",
            "dc_most_frequent\n",
            "[[ 0  9]\n",
            " [ 0 17]]\n",
            "\n",
            "dc_stratified\n",
            "[[ 3  6]\n",
            " [ 7 10]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhmZs3Z_pPGZ",
        "colab_type": "code",
        "outputId": "134b61ab-c01e-4123-e771-6160462f50cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "for i in predictions:\n",
        "    print_precision_recall_fscore_support(i, test_labels, predictions[i], label_names)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dc_uniform\n",
            "\n",
            "none     : (array([0.30769231, 0.61538462]), array([0.44444444, 0.47058824]), array([0.36363636, 0.53333333]), array([ 9, 17]))\n",
            "micro    : (0.46153846153846156, 0.46153846153846156, 0.46153846153846156, None)\n",
            "macro    : (0.46153846153846156, 0.45751633986928103, 0.4484848484848485, None)\n",
            "weighted : (0.5088757396449703, 0.46153846153846156, 0.4745920745920746, None)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.31      0.44      0.36         9\n",
            "           2       0.62      0.47      0.53        17\n",
            "\n",
            "    accuracy                           0.46        26\n",
            "   macro avg       0.46      0.46      0.45        26\n",
            "weighted avg       0.51      0.46      0.47        26\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAEvCAYAAABhSUTPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------------------------------------------------------------------\n",
            "---------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "dc_constant_1\n",
            "\n",
            "none     : (array([0.34615385, 0.        ]), array([1., 0.]), array([0.51428571, 0.        ]), array([ 9, 17]))\n",
            "micro    : (0.34615384615384615, 0.34615384615384615, 0.34615384615384615, None)\n",
            "macro    : (0.17307692307692307, 0.5, 0.2571428571428571, None)\n",
            "weighted : (0.11982248520710059, 0.34615384615384615, 0.178021978021978, None)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.35      1.00      0.51         9\n",
            "           2       0.00      0.00      0.00        17\n",
            "\n",
            "    accuracy                           0.35        26\n",
            "   macro avg       0.17      0.50      0.26        26\n",
            "weighted avg       0.12      0.35      0.18        26\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAAEvCAYAAAB2a9QGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAWmElEQVR4nO3df5Bd5X3f8fenUkQmpqbYbDMpkpAc\nCzfy2AV3kTt2wWMbg1wyiEzxWLhpYYZWxmMlnjDJWGlcyMjjFkMbz3Qsj6GJxk7GWDb2kGxrpRrK\nrxDbGC0/DJYSlUUQkOqpFURJXDuA4Ns/7sG5ul2xF+0+7N3l/ZrZ4ZznPM+53wvPLp97znPvTVUh\nSZKkufV35rsASZKkxciQJUmS1IAhS5IkqQFDliRJUgOGLEmSpAYMWZIkSQ0sne8CBp1yyim1atWq\n+S5DkiRpRvfee+9fVtXYdMdGLmStWrWKycnJ+S5DkiRpRkn+4ljHvF0oSZLUgCFLkiSpAUOWJElS\nA4YsSZKkBoYKWUnWJ9mXZCrJlmmOX5HkoSQPJPnTJGu79lVJfty1P5Dk83P9BCRJkkbRjO8uTLIE\n2Aa8DzgA7E4yUVV7+7rdWFWf7/pfCPwOsL479khVnTG3ZUuSJI22Ya5krQOmqmp/VT0L7AA29Heo\nqr/q230NUHNXoiRJ0sIzTMg6FXiib/9A13aUJB9N8ghwLfCrfYdWJ7k/yZ1Jzp5VtZIkSQvEnC18\nr6ptVfXzwMeBT3TN3wdWVtWZwJXAjUleOzg2yaYkk0kmDx06NFclSZIkzZthQtZBYEXf/vKu7Vh2\nABcBVNUzVfVkt30v8Ahw+uCAqrqhqsaranxsbNpPppckSVpQhglZu4E1SVYnWQZsBCb6OyRZ07d7\nAfBw1z7WLZwnyRuANcD+uShckiRplM347sKqOpJkM7ALWAJsr6o9SbYCk1U1AWxOci7wHPAUcGk3\n/Bxga5LngBeAK6rqcIsn8nKt2vKN+S5BC9xj11ww3yVIkkbYUF8QXVU7gZ0DbVf1bX/sGOO+Dnx9\nNgVKkiQtRH7iuyRJUgOGLEmSpAYMWZIkSQ0YsiRJkhowZEmSJDVgyJIkSWrAkCVJktSAIUuSJKkB\nQ5YkSVIDhixJkqQGDFmSJEkNGLIkSZIaMGRJkiQ1YMiSJElqwJAlSZLUgCFLkiSpAUOWJElSA4Ys\nSZKkBgxZkiRJDRiyJEmSGjBkSZIkNWDIkiRJasCQJUmS1IAhS5IkqQFDliRJUgOGLEmSpAYMWZIk\nSQ0YsiRJkhowZEmSJDUwVMhKsj7JviRTSbZMc/yKJA8leSDJnyZZ23fsN7tx+5KcP5fFS5IkjaoZ\nQ1aSJcA24P3AWuCS/hDVubGq3lJVZwDXAr/TjV0LbATeDKwHPtedT5IkaVEb5krWOmCqqvZX1bPA\nDmBDf4eq+qu+3dcA1W1vAHZU1TNV9Sgw1Z1PkiRpUVs6RJ9TgSf69g8Abx/slOSjwJXAMuA9fWPv\nHhh76jRjNwGbAFauXDlM3ZIkSSNtzha+V9W2qvp54OPAJ17m2BuqaryqxsfGxuaqJEmSpHkzTMg6\nCKzo21/etR3LDuCi4xwrSZK0KAwTsnYDa5KsTrKM3kL2if4OSdb07V4APNxtTwAbk5yQZDWwBrhn\n9mVLkiSNthnXZFXVkSSbgV3AEmB7Ve1JshWYrKoJYHOSc4HngKeAS7uxe5J8FdgLHAE+WlXPN3ou\nkiRJI2OYhe9U1U5g50DbVX3bH3uJsZ8CPnW8BUqSJC1EfuK7JElSA4YsSZKkBgxZkiRJDRiyJEmS\nGjBkSZIkNWDIkiRJasCQJUmS1IAhS5IkqQFDliRJUgOGLEmSpAYMWZIkSQ0YsiRJkhowZEmSJDVg\nyJIkSWrAkCVJktSAIUuSJKkBQ5YkSVIDhixJkqQGDFmSJEkNGLIkSZIaMGRJkiQ1YMiSJElqwJAl\nSZLUgCFLkiSpAUOWJElSA4YsSZKkBgxZkiRJDSyd7wIkzY1VW74x3yVogXvsmgvmuwRpURnqSlaS\n9Un2JZlKsmWa41cm2ZvkwSS3Jjmt79jzSR7ofibmsnhJkqRRNeOVrCRLgG3A+4ADwO4kE1W1t6/b\n/cB4Vf0oyUeAa4EPdsd+XFVnzHHdkiRJI22YK1nrgKmq2l9VzwI7gA39Harq9qr6Ubd7N7B8bsuU\nJElaWIYJWacCT/TtH+jajuVy4I/79n86yWSSu5NcdBw1SpIkLThzuvA9yS8D48C7+ppPq6qDSd4A\n3Jbkoap6ZGDcJmATwMqVK+eyJEmSpHkxzJWsg8CKvv3lXdtRkpwL/BZwYVU982J7VR3s/rkfuAM4\nc3BsVd1QVeNVNT42NvaynoAkSdIoGiZk7QbWJFmdZBmwETjqXYJJzgSupxewftDXfnKSE7rtU4B3\nAv0L5iVJkhalGW8XVtWRJJuBXcASYHtV7UmyFZisqgngOuBE4KYkAI9X1YXALwDXJ3mBXqC7ZuBd\niZIkSYvSUGuyqmonsHOg7aq+7XOPMe5bwFtmU6AkSdJC5NfqSJIkNWDIkiRJasCQJUmS1IAhS5Ik\nqQFDliRJUgOGLEmSpAYMWZIkSQ0YsiRJkhowZEmSJDVgyJIkSWrAkCVJktSAIUuSJKkBQ5YkSVID\nhixJkqQGDFmSJEkNGLIkSZIaMGRJkiQ1YMiSJElqwJAlSZLUgCFLkiSpAUOWJElSA4YsSZKkBgxZ\nkiRJDRiyJEmSGjBkSZIkNWDIkiRJasCQJUmS1IAhS5IkqYGhQlaS9Un2JZlKsmWa41cm2ZvkwSS3\nJjmt79ilSR7ufi6dy+IlSZJG1YwhK8kSYBvwfmAtcEmStQPd7gfGq+qtwNeAa7uxrwOuBt4OrAOu\nTnLy3JUvSZI0moa5krUOmKqq/VX1LLAD2NDfoapur6ofdbt3A8u77fOBW6rqcFU9BdwCrJ+b0iVJ\nkkbXMCHrVOCJvv0DXduxXA788XGOlSRJWhSWzuXJkvwyMA6862WO2wRsAli5cuVcliRJkjQvhrmS\ndRBY0be/vGs7SpJzgd8CLqyqZ17O2Kq6oarGq2p8bGxs2NolSZJG1jAhazewJsnqJMuAjcBEf4ck\nZwLX0wtYP+g7tAs4L8nJ3YL387o2SZKkRW3G24VVdSTJZnrhaAmwvar2JNkKTFbVBHAdcCJwUxKA\nx6vqwqo6nOST9IIawNaqOtzkmUiSJI2QodZkVdVOYOdA21V92+e+xNjtwPbjLVCSJGkh8hPfJUmS\nGjBkSZIkNWDIkiRJasCQJUmS1IAhS5IkqQFDliRJUgOGLEmSpAYMWZIkSQ0YsiRJkhowZEmSJDVg\nyJIkSWrAkCVJktTAUF8QLUnSK23Vlm/Mdwla4B675oJ5fXyvZEmSJDVgyJIkSWrAkCVJktSAIUuS\nJKkBQ5YkSVIDhixJkqQGDFmSJEkNGLIkSZIaMGRJkiQ1YMiSJElqwJAlSZLUgCFLkiSpAUOWJElS\nA4YsSZKkBgxZkiRJDRiyJEmSGhgqZCVZn2RfkqkkW6Y5fk6S+5IcSXLxwLHnkzzQ/UzMVeGSJEmj\nbOlMHZIsAbYB7wMOALuTTFTV3r5ujwOXAb8+zSl+XFVnzEGtkiRJC8aMIQtYB0xV1X6AJDuADcBP\nQlZVPdYde6FBjZIkSQvOMLcLTwWe6Ns/0LUN66eTTCa5O8lFL6s6SZKkBWqYK1mzdVpVHUzyBuC2\nJA9V1SP9HZJsAjYBrFy58hUoSZIkqa1hrmQdBFb07S/v2oZSVQe7f+4H7gDOnKbPDVU1XlXjY2Nj\nw55akiRpZA0TsnYDa5KsTrIM2AgM9S7BJCcnOaHbPgV4J31ruSRJkharGUNWVR0BNgO7gD8DvlpV\ne5JsTXIhQJKzkhwAPgBcn2RPN/wXgMkk3wVuB64ZeFeiJEnSojTUmqyq2gnsHGi7qm97N73biIPj\nvgW8ZZY1SpIkLTh+4rskSVIDhixJkqQGDFmSJEkNGLIkSZIaMGRJkiQ1YMiSJElqwJAlSZLUgCFL\nkiSpAUOWJElSA4YsSZKkBgxZkiRJDRiyJEmSGjBkSZIkNWDIkiRJasCQJUmS1IAhS5IkqQFDliRJ\nUgOGLEmSpAYMWZIkSQ0YsiRJkhowZEmSJDVgyJIkSWrAkCVJktSAIUuSJKkBQ5YkSVIDhixJkqQG\nDFmSJEkNGLIkSZIaGCpkJVmfZF+SqSRbpjl+TpL7khxJcvHAsUuTPNz9XDpXhUuSJI2yGUNWkiXA\nNuD9wFrgkiRrB7o9DlwG3Dgw9nXA1cDbgXXA1UlOnn3ZkiRJo22YK1nrgKmq2l9VzwI7gA39Harq\nsap6EHhhYOz5wC1VdbiqngJuAdbPQd2SJEkjbZiQdSrwRN/+ga5tGLMZK0mStGCNxML3JJuSTCaZ\nPHTo0HyXI0mSNGvDhKyDwIq+/eVd2zCGGltVN1TVeFWNj42NDXlqSZKk0TVMyNoNrEmyOskyYCMw\nMeT5dwHnJTm5W/B+XtcmSZK0qM0YsqrqCLCZXjj6M+CrVbUnydYkFwIkOSvJAeADwPVJ9nRjDwOf\npBfUdgNbuzZJkqRFbekwnapqJ7BzoO2qvu3d9G4FTjd2O7B9FjVKkiQtOCOx8F2SJGmxMWRJkiQ1\nYMiSJElqwJAlSZLUgCFLkiSpAUOWJElSA4YsSZKkBgxZkiRJDRiyJEmSGjBkSZIkNWDIkiRJasCQ\nJUmS1IAhS5IkqQFDliRJUgOGLEmSpAYMWZIkSQ0YsiRJkhowZEmSJDVgyJIkSWrAkCVJktSAIUuS\nJKkBQ5YkSVIDhixJkqQGDFmSJEkNGLIkSZIaMGRJkiQ1YMiSJElqwJAlSZLUgCFLkiSpgaFCVpL1\nSfYlmUqyZZrjJyT5Snf8O0lWde2rkvw4yQPdz+fntnxJkqTRtHSmDkmWANuA9wEHgN1JJqpqb1+3\ny4GnquqNSTYCnwY+2B17pKrOmOO6JUmSRtowV7LWAVNVtb+qngV2ABsG+mwAvthtfw14b5LMXZmS\nJEkLyzAh61Tgib79A13btH2q6gjwNPD67tjqJPcnuTPJ2dM9QJJNSSaTTB46dOhlPQFJkqRR1Hrh\n+/eBlVV1JnAlcGOS1w52qqobqmq8qsbHxsYalyRJktTeMCHrILCib3951zZtnyRLgZOAJ6vqmap6\nEqCq7gUeAU6fbdGSJEmjbpiQtRtYk2R1kmXARmBioM8EcGm3fTFwW1VVkrFu4TxJ3gCsAfbPTemS\nJEmja8Z3F1bVkSSbgV3AEmB7Ve1JshWYrKoJ4PeAP0gyBRymF8QAzgG2JnkOeAG4oqoOt3gikiRJ\no2TGkAVQVTuBnQNtV/Vt/w3wgWnGfR34+ixrlCRJWnD8xHdJkqQGDFmSJEkNGLIkSZIaMGRJkiQ1\nYMiSJElqwJAlSZLUgCFLkiSpAUOWJElSA4YsSZKkBgxZkiRJDRiyJEmSGjBkSZIkNWDIkiRJasCQ\nJUmS1IAhS5IkqQFDliRJUgOGLEmSpAYMWZIkSQ0YsiRJkhowZEmSJDVgyJIkSWrAkCVJktSAIUuS\nJKkBQ5YkSVIDhixJkqQGDFmSJEkNGLIkSZIaMGRJkiQ1MFTISrI+yb4kU0m2THP8hCRf6Y5/J8mq\nvmO/2bXvS3L+3JUuSZI0umYMWUmWANuA9wNrgUuSrB3odjnwVFW9EfgM8Olu7FpgI/BmYD3wue58\nkiRJi9owV7LWAVNVtb+qngV2ABsG+mwAvthtfw14b5J07Tuq6pmqehSY6s4nSZK0qA0Tsk4Fnujb\nP9C1Tdunqo4ATwOvH3KsJEnSorN0vgsASLIJ2NTt/jDJvvmsRwCcAvzlfBcxyvLp+a5AL5NzegbO\n6QXJef0SXqE5fdqxDgwTsg4CK/r2l3dt0/U5kGQpcBLw5JBjqaobgBuGqEWvkCSTVTU+33VIc8U5\nrcXIeT3ahrlduBtYk2R1kmX0FrJPDPSZAC7tti8Gbquq6to3du8+XA2sAe6Zm9IlSZJG14xXsqrq\nSJLNwC5gCbC9qvYk2QpMVtUE8HvAHySZAg7TC2J0/b4K7AWOAB+tqucbPRdJkqSRkd4FJ+loSTZ1\nt3GlRcE5rcXIeT3aDFmSJEkN+LU6kiRJDRiyXmWSXDjdVyMd57keS/JQkge6n3d07f89yf9J8t/m\n4nGkV1qSLyR5tG9u/2rX/qkkTyT54XzXqMUjye9O800qg32+kOTiadpXJfnQcTzmT86X5I7uq+9e\nnO8vtm9P8oMk33u551fPSHxOll453RsVBt8dOq3uU/tTVS+8RLd3V9XgZ7RcB/wM8OHjq1JqL8mS\nGd6I8xtV9bWBtv8KfBZ4uF1lerWpqn89i+GrgA8BN86yjH9RVZMDbV+gN99/f5bnftXyStYi0r2i\n+fPuFcr/TPKlJOcm+WaSh5OsS3JZks92/X82yc1Jvtv9vKM7x74kvw98D1iR5JLuitX3kpk/2q2q\nbgX+uvHT1SI35Hxel+TbSe5P8q0kb+rGLknyH7s5+2CSX+naH0vy6ST3AR9IckaSu7s+Nyc5+aVq\nqqq7q+r7r8DT1wKU5Df6rnp+Jslt3fZ7uvl7Xjdf70tyU5ITu+N3JBnvti/v5vs9Sf7Li3+vO+d0\n83x/31Wta4CzuytQv9bN/euS7O7m9Ye78ybJZ7u/7/8D+PszPZ+q+hN6nxig42TIWnzeCPwn4B92\nPx8C/inw68C/Hej7n4E7q+ofAW8D9nTta4DPVdWbgefofeH3e4AzgLOSXNR3jtu7X+7vNHo+enWb\naT7/OXB2VZ0JXAX8+27cJnqv8M+oqrcCX+o755NV9baq2kHvFfrHuz4PAVf39buu7/bJW1o9QS0q\ndwFnd9vjwIlJfqprexD4BHBuVb0NmASu7B+c5B8A/w74J8A76c35fj9Hb/7/Ir1wBbAFuKuqzqiq\nzwCXA09X1VnAWcC/Se9zKn8JeBOwFvhXwDsGzv2lvvn++ln8O1AfbxcuPo9W1UMASfYAt1ZVJXmI\n3v90+r2H3i8b3W2Tp7tX8n9RVXd3fc4C7qiqQ905vwScA/xhd3y624XSXJlpPp8EfDHJGqCAn+rG\nnQt8vvsuVaqq/9X4V7rznQT8vaq6s2v/InBTX7/pbhdKL+Ve4B8neS3wDHAfvbB1Nr1lGmuBb/ZW\nYrAM+PbA+HX0XvgeBkhyE3B63/E/7JZv7E3ys8eo4TzgrX1Xuk6i98L5HODL3d/6//XiVbY+090u\n1CwZshafZ/q2X+jbf4Hh/3v/3zmtSDp+M83nTwK3V9UvJVkF3DHEOZ3faqKqnkvyKHAZ8C16V6/e\nTe+K7KPALVV1ySweov/3IcfoE+BXqmrXUY3JP5vF4+o4ebvw1e1W4CPwkzUsJ03T5x7gXUlOSbIE\nuAS4c5p+0nw4ib/9PtTL+tpvAT6c3nepkuR1gwOr6mngqSQv3t75lzi3NXt30bud/Sfd9hXA/cDd\nwDuTvBEgyWuSnD4wdje9v7cnd3P3nw/xeH8N/N2+/V3AR7rblCQ5Pclruno+2P2t/zl64U+NGbJe\n3T4GvLu79XIvvUvZR+kW+W4Bbge+C9xbVX/0UidNche92y7vTXIgyflzXrnUcy3wH5Lcz9FXan8X\neBx4MMl36a3lms6l9NZePUhvzeHWl3qwJNcmOQD8TDe3f3u2T0CLzl301k59u6r+N/A39NZMHaL3\nQuDL3Xz7NgNrrqrqIL11hfcA3wQeA56e4fEeBJ5P781Lv0Zv7u8F7kvvoxeup/e7cTO9d8XupbcW\ncfBW5f8nyZe7fm/q5vvlMz57HcVPfJckaUQkObGqfthdybqZ3vcF3zzfden4eCVLkqTR8dtJHqD3\nETqP8rdvMtIC5JUsSZKkBrySJUmS1IAhS5IkqQFDliRJUgOGLEmSpAYMWZIkSQ0YsiRJkhr4f9Ra\nsUgN9lCxAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------------------------------------------------------------------\n",
            "---------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "dc_constant_2\n",
            "\n",
            "none     : (array([0.        , 0.65384615]), array([0., 1.]), array([0.        , 0.79069767]), array([ 9, 17]))\n",
            "micro    : (0.6538461538461539, 0.6538461538461539, 0.6538461538461539, None)\n",
            "macro    : (0.3269230769230769, 0.5, 0.39534883720930236, None)\n",
            "weighted : (0.42751479289940825, 0.6538461538461539, 0.5169946332737031, None)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         9\n",
            "           2       0.65      1.00      0.79        17\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.33      0.50      0.40        26\n",
            "weighted avg       0.43      0.65      0.52        26\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAEvCAYAAABhSUTPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAATDUlEQVR4nO3dfaxkd33f8c8367hSgLppvUmpH7JW\nWFNtC3XI2q2gkECc1C6VnQjS2vQBS06WRHWCQouytKkbOWrLQxOkClfFoQhSAeZBMt2UbVeU2OAS\nDLs2xmbtOKxsJ163KhvjuKFVMA7f/jHHML659h32N7t3dvf1kq4058xvzvld+ez1+55z7kx1dwAA\nODrfsdkTAAA4kYkpAIABYgoAYICYAgAYIKYAAAaIKQCAAadt1o7PPPPM3rZt22btHgBgYbfffvsf\ndPfW9Z7btJjatm1bDhw4sFm7BwBYWFX93tM95zIfAMAAMQUAMEBMAQAMEFMAAAPEFADAADEFADBA\nTAEADBBTAAADxBQAwAAxBQAwQEwBAAzYtM/mOx627f7YZk+BE9yDb37lZk8BgBXnzBQAwAAxBQAw\nQEwBAAwQUwAAA8QUAMAAMQUAMEBMAQAMEFMAAAPEFADAADEFADBATAEADBBTAAADxBQAwAAxBQAw\nQEwBAAwQUwAAAxaKqaq6pKruq6pDVbX7acb83aq6p6oOVtX7lztNAIDVdNpGA6pqS5Lrk/xoksNJ\n9lfVnu6+Z27M9iRvSvKS7n60qr7nWE0YAGCVLHJm6qIkh7r7/u5+PMmNSS5fM+ank1zf3Y8mSXd/\nebnTBABYTYvE1FlJHppbPjytm3d+kvOr6tNVdVtVXbKsCQIArLINL/N9G9vZnuSHk5yd5FNV9YLu\n/sP5QVW1K8muJDn33HOXtGsAgM2zyJmph5OcM7d89rRu3uEke7r76939QJLfzSyunqK7b+jund29\nc+vWrUc7ZwCAlbFITO1Psr2qzquq05NckWTPmjEfzeysVKrqzMwu+92/xHkCAKykDWOqu59Ick2S\nfUnuTfKh7j5YVddV1WXTsH1JHqmqe5LcnOSN3f3IsZo0AMCqWOieqe7em2TvmnXXzj3uJG+YvgAA\nThneAR0AYICYAgAYIKYAAAaIKQCAAWIKAGCAmAIAGCCmAAAGiCkAgAFiCgBggJgCABggpgAABogp\nAIABYgoAYICYAgAYIKYAAAaIKQCAAWIKAGCAmAIAGCCmAAAGiCkAgAFiCgBggJgCABggpgAABogp\nAIABYgoAYICYAgAYIKYAAAaIKQCAAadt9gQAOLVt2/2xzZ4CJ7gH3/zKTd2/M1MAAAPEFADAgIVi\nqqouqar7qupQVe1e5/mrqupIVd05ff3U8qcKALB6Nrxnqqq2JLk+yY8mOZxkf1Xt6e571gz9YHdf\ncwzmCACwshY5M3VRkkPdfX93P57kxiSXH9tpAQCcGBaJqbOSPDS3fHhat9arququqvpIVZ2zlNkB\nAKy4Zd2A/ptJtnX3C5N8PMl71xtUVbuq6kBVHThy5MiSdg0AsHkWiamHk8yfaTp7WvdN3f1Id39t\nWnxXkh9cb0PdfUN37+zunVu3bj2a+QIArJRFYmp/ku1VdV5VnZ7kiiR75gdU1XPnFi9Lcu/ypggA\nsLo2/Gu+7n6iqq5Jsi/JliTv7u6DVXVdkgPdvSfJz1fVZUmeSPKVJFcdwzkDAKyMhT5Oprv3Jtm7\nZt21c4/flORNy50aAMDq8w7oAAADxBQAwAAxBQAwQEwBAAwQUwAAA8QUAMAAMQUAMEBMAQAMEFMA\nAAPEFADAADEFADBATAEADBBTAAADxBQAwAAxBQAwQEwBAAwQUwAAA8QUAMAAMQUAMEBMAQAMEFMA\nAAPEFADAADEFADBATAEADBBTAAADxBQAwAAxBQAwQEwBAAwQUwAAA8QUAMAAMQUAMGChmKqqS6rq\nvqo6VFW7n2Hcq6qqq2rn8qYIALC6NoypqtqS5PoklybZkeTKqtqxzrjnJHl9ks8ue5IAAKtqkTNT\nFyU51N33d/fjSW5Mcvk6434lyVuS/PES5wcAsNIWiamzkjw0t3x4WvdNVfWiJOd098eeaUNVtauq\nDlTVgSNHjnzbkwUAWDXDN6BX1Xck+bUk/2Sjsd19Q3fv7O6dW7duHd01AMCmO22BMQ8nOWdu+exp\n3ZOek+SvJrmlqpLkLybZU1WXdfeBZU0UmNm2+xlPAMOGHnzzKzd7CnBSWeTM1P4k26vqvKo6PckV\nSfY8+WR3P9bdZ3b3tu7eluS2JEIKADglbBhT3f1EkmuS7Etyb5IPdffBqrquqi471hMEAFhli1zm\nS3fvTbJ3zbprn2bsD49PCwDgxOAd0AEABogpAIABYgoAYICYAgAYIKYAAAaIKQCAAWIKAGCAmAIA\nGCCmAAAGiCkAgAFiCgBggJgCABggpgAABogpAIABYgoAYICYAgAYIKYAAAaIKQCAAWIKAGCAmAIA\nGCCmAAAGiCkAgAFiCgBggJgCABggpgAABogpAIABYgoAYICYAgAYIKYAAAaIKQCAAQvFVFVdUlX3\nVdWhqtq9zvM/U1V3V9WdVfU/qmrH8qcKALB6NoypqtqS5PoklybZkeTKdWLp/d39gu6+IMlbk/za\n0mcKALCCFjkzdVGSQ919f3c/nuTGJJfPD+ju/zO3+KwkvbwpAgCsrtMWGHNWkofmlg8n+etrB1XV\nP07yhiSnJ3nFUmYHALDilnYDendf393fn+QXk/zSemOqaldVHaiqA0eOHFnWrgEANs0iMfVwknPm\nls+e1j2dG5P8+HpPdPcN3b2zu3du3bp18VkCAKyoRWJqf5LtVXVeVZ2e5Ioke+YHVNX2ucVXJvnS\n8qYIALC6NrxnqrufqKprkuxLsiXJu7v7YFVdl+RAd+9Jck1VXZzk60keTfLaYzlpAIBVscgN6Onu\nvUn2rll37dzj1y95XgAAJwTvgA4AMEBMAQAMEFMAAAPEFADAADEFADBATAEADBBTAAADxBQAwAAx\nBQAwQEwBAAwQUwAAA8QUAMAAMQUAMEBMAQAMEFMAAAPEFADAADEFADBATAEADBBTAAADxBQAwAAx\nBQAwQEwBAAwQUwAAA8QUAMAAMQUAMEBMAQAMEFMAAAPEFADAADEFADBATAEADBBTAAADFoqpqrqk\nqu6rqkNVtXud599QVfdU1V1V9Ymq+r7lTxUAYPVsGFNVtSXJ9UkuTbIjyZVVtWPNsM8n2dndL0zy\nkSRvXfZEAQBW0SJnpi5Kcqi77+/ux5PcmOTy+QHdfXN3/79p8bYkZy93mgAAq2mRmDoryUNzy4en\ndU/n6iT/dWRSAAAnitOWubGq+gdJdib5oad5fleSXUly7rnnLnPXAACbYpEzUw8nOWdu+exp3VNU\n1cVJ/nmSy7r7a+ttqLtv6O6d3b1z69atRzNfAICVskhM7U+yvarOq6rTk1yRZM/8gKr6gSTvzCyk\nvrz8aQIArKYNY6q7n0hyTZJ9Se5N8qHuPlhV11XVZdOwtyV5dpIPV9WdVbXnaTYHAHBSWeieqe7e\nm2TvmnXXzj2+eMnzAgA4IXgHdACAAWIKAGCAmAIAGCCmAAAGiCkAgAFiCgBggJgCABggpgAABogp\nAIABYgoAYICYAgAYIKYAAAaIKQCAAWIKAGCAmAIAGCCmAAAGiCkAgAFiCgBggJgCABggpgAABogp\nAIABYgoAYICYAgAYIKYAAAaIKQCAAWIKAGCAmAIAGCCmAAAGiCkAgAFiCgBgwEIxVVWXVNV9VXWo\nqnav8/zLquqOqnqiql69/GkCAKymDWOqqrYkuT7JpUl2JLmyqnasGfb7Sa5K8v5lTxAAYJWdtsCY\ni5Ic6u77k6SqbkxyeZJ7nhzQ3Q9Oz33jGMwRAGBlLXKZ76wkD80tH57WAQCc8o7rDehVtauqDlTV\ngSNHjhzPXQMAHBOLxNTDSc6ZWz57Wvdt6+4buntnd+/cunXr0WwCAGClLBJT+5Nsr6rzqur0JFck\n2XNspwUAcGLYMKa6+4kk1yTZl+TeJB/q7oNVdV1VXZYkVXVhVR1O8pNJ3llVB4/lpAEAVsUif82X\n7t6bZO+addfOPd6f2eU/AIBTindABwAYIKYAAAaIKQCAAWIKAGCAmAIAGCCmAAAGiCkAgAFiCgBg\ngJgCABggpgAABogpAIABYgoAYICYAgAYIKYAAAaIKQCAAWIKAGCAmAIAGCCmAAAGiCkAgAFiCgBg\ngJgCABggpgAABogpAIABYgoAYICYAgAYIKYAAAaIKQCAAWIKAGCAmAIAGCCmAAAGiCkAgAELxVRV\nXVJV91XVoaravc7zf6aqPjg9/9mq2rbsiQIArKINY6qqtiS5PsmlSXYkubKqdqwZdnWSR7v7eUne\nnuQty54oAMAqWuTM1EVJDnX3/d39eJIbk1y+ZszlSd47Pf5Ikh+pqlreNAEAVtMiMXVWkofmlg9P\n69Yd091PJHksyV9YxgQBAFbZacdzZ1W1K8muafGrVXXf8dw/6zozyR9s9iRWVblgfSJyTG/AcX3C\ncUxv4Dgd09/3dE8sElMPJzlnbvnsad16Yw5X1WlJzkjyyNoNdfcNSW5YYJ8cJ1V1oLt3bvY8YFkc\n05xsHNOrb5HLfPuTbK+q86rq9CRXJNmzZsyeJK+dHr86yW91dy9vmgAAq2nDM1Pd/URVXZNkX5It\nSd7d3Qer6rokB7p7T5L/mOQ/VdWhJF/JLLgAAE565QTSqa2qdk2XX+Gk4JjmZOOYXn1iCgBggI+T\nAQAYIKZOUlV12Xof/XOU23qwqu6uqjunrxdP6/9bVf1hVf2XZewHjqeqek9VPTB3XP/8tP5fVdVD\nVfXVzZ4jJ4+qetc6nx6ydsx7qurV66zfVlWvOYp9fnN7VXXL9LFwTx7vT65/d1V9uaq++O1un285\nru8zxfEz/WHA2r+6XNf0bvXV3d94hmEv7+6173PytiTfleR1RzdLOLaqakt3/8kzDHljd39kzbrf\nTPKOJF86djPjVNPdPzXw8m1JXpPk/YPT+PvdfWDNuvdkdrz/xuC2T2nOTJ2Apt9Sfmf6reN3q+p9\nVXVxVX26qr5UVRdV1VVV9Y5p/PdW1U1V9YXp68XTNu6rqt9I8sUk51TVldMZqC9WbfwWaN39iSR/\ndIy/XU5iCx7LF1XVZ6rq81X121X1/Om1W6rq307H611V9XPT+ger6i1VdUeSn6yqC6rqtmnMTVX1\n3c80p+6+rbv/13H49jkBVdUb585ivr2qfmt6/Irp+P2x6Xi9o6o+XFXPnp6/pap2To+vno73z1XV\nrz/5s3rysuk4v3/uLNWbk7x0OqP0C9Ox/7aq2j8d16+btltV9Y7pZ/t/T/I9G30/3f2pzP4KnwFi\n6sT1vCS/muQvT1+vSfI3k/zTJP9szdh/l+ST3f3XkrwoycFp/fYk/767/0qSr2f2AdWvSHJBkgur\n6sfntnHz9A/5s8fo++HUtdGx/DtJXtrdP5Dk2iT/enrdrsx+Y7+gu1+Y5H1z23yku1/U3Tdm9hv3\nL05j7k7yL+fGvW3usscLjtU3yEnl1iQvnR7vTPLsqvrOad1dSX4pycXd/aIkB5K8Yf7FVfWXkvyL\nJH8jyUsyO+bnPTez4//vZBZRSbI7ya3dfUF3vz3J1Uke6+4Lk1yY5Ker6rwkP5Hk+Ul2JPlHSV68\nZtvvmzvefeTbErnMd+J6oLvvTpKqOpjkE93dVXV3Zv+DmfeKzP5hZbrk8dj02/nvdfdt05gLk9zS\n3Uembb4vycuSfHR6fr3LfLAMGx3LZyR5b1VtT9JJvnN63cVJ/sP0eaDp7vnfrj84be+MJH+uuz85\nrX9vkg/PjVvvMh88k9uT/GBV/dkkX0tyR2ZR9dLMbq3YkeTTs7sncnqSz6x5/UWZ/XL7lSSpqg8n\nOX/u+Y9Ot1zcU1Xf+zRz+LEkL5w7c3VGZr8cvyzJB6af8//zybNmc9a7zMcSiKkT19fmHn9jbvkb\nWfy/6/9d6ozg6Gx0LP9Kkpu7+yeqaluSWxbYpmObY6K7v15VDyS5KslvZ3Y26uWZnWF9IMnHu/vK\ngV3M/3uopxlTSX6uu/c9ZWXV3x7YLwNc5js1fCLJzybfvM/kjHXGfC7JD1XVmVW1JcmVST65zjg4\n3s7Itz4P9Kq59R9P8rqafR5oqurPr31hdz+W5NGqevKyzD+M45pxt2Z2GfpT0+OfSfL5JLcleUlV\nPS9JqupZVXX+mtfuz+xn7XdPx+6rFtjfHyV5ztzyviQ/O11eTFWdX1XPmubz96af88/NLPI4DsTU\nqeH1SV4+XTa5PbPT0E8x3XC7O8nNSb6Q5Pbu/s/PtNGqujWzSyY/UlWHq+pvLX3mkLw1yb+pqs/n\nqWdd35Xk95PcVVVfyOxeq/W8NrN7o+7K7H7A655pZ1X11qo6nOS7puP6l0e/AU46t2Z2b9Nnuvt/\nJ/njzO5pOpJZ8H9gOt4+kzX3RHX3w5nd9/e5JJ9O8mCSxzbY311J/qRmf0D0C5kd+/ckuaNmb2nw\nzsz+bdyU2V+h3pPZvYJrLzH+KVX1gWnc86fj/eoNv3v+FO+ADgDHUVU9u7u/Op2Zuimzz7y9abPn\nxdFzZgoAjq9frqo7M3tbmgfyrT/04QTlzBQAwABnpgAABogpAIABYgoAYICYAgAYIKYAAAaIKQCA\nAf8fTlZBBG+GTswAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------------------------------------------------------------------\n",
            "---------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "dc_most_frequent\n",
            "\n",
            "none     : (array([0.        , 0.65384615]), array([0., 1.]), array([0.        , 0.79069767]), array([ 9, 17]))\n",
            "micro    : (0.6538461538461539, 0.6538461538461539, 0.6538461538461539, None)\n",
            "macro    : (0.3269230769230769, 0.5, 0.39534883720930236, None)\n",
            "weighted : (0.42751479289940825, 0.6538461538461539, 0.5169946332737031, None)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         9\n",
            "           2       0.65      1.00      0.79        17\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.33      0.50      0.40        26\n",
            "weighted avg       0.43      0.65      0.52        26\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAEvCAYAAABhSUTPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAf8fTlZBBG+GTswAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------------------------------------------------------------------\n",
            "---------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "dc_stratified\n",
            "\n",
            "none     : (array([0.3  , 0.625]), array([0.33333333, 0.58823529]), array([0.31578947, 0.60606061]), array([ 9, 17]))\n",
            "micro    : (0.5, 0.5, 0.5, None)\n",
            "macro    : (0.4625, 0.4607843137254902, 0.4609250398724083, None)\n",
            "weighted : (0.5125, 0.5, 0.5055821371610846, None)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.30      0.33      0.32         9\n",
            "           2       0.62      0.59      0.61        17\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.46      0.46      0.46        26\n",
            "weighted avg       0.51      0.50      0.51        26\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAEvCAYAAABhSUTPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------------------------------------------------------------------\n",
            "---------------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moeExYNt9QmW",
        "colab_type": "text"
      },
      "source": [
        "##### Comments on the diagrams\n",
        "- Among the Dummy Classifiers, it is visible that the best strategy is 'constant 2' since class 2 is the most frequent one. That is why it matches with the 'dc_most_frequent' Moreover, if we run the classification multiple times, we notice that 'stratified' strategy results in better accuracy more often than the 'uniform' strategy. This is because our dataset is not balanced and 'stratified' is more effiecient than the random strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMrUL--3G_F0",
        "colab_type": "text"
      },
      "source": [
        "### k Nearest Neighbors Classifier (kNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fequNH8Y--ul",
        "colab_type": "code",
        "outputId": "437e2fc0-7157-49bb-f92d-6a1b7c8e2033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=2)\n",
        "\n",
        "knn.fit(train, train_labels)\n",
        "\n",
        "pred = knn.predict(test)\n",
        "\n",
        "cnf_matrix = confusion_matrix(test_labels, pred)\n",
        "\n",
        "print(\"kNN Confusion matrix:\\n\\n\", cnf_matrix, '\\n')\n",
        "\n",
        "print_precision_recall_fscore_support(\"KNeighborsClassifier\", test_labels, pred, label_names)\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kNN Confusion matrix:\n",
            "\n",
            " [[ 7  2]\n",
            " [ 7 10]] \n",
            "\n",
            "KNeighborsClassifier\n",
            "\n",
            "none     : (array([0.5       , 0.83333333]), array([0.77777778, 0.58823529]), array([0.60869565, 0.68965517]), array([ 9, 17]))\n",
            "micro    : (0.6538461538461539, 0.6538461538461539, 0.6538461538461539, None)\n",
            "macro    : (0.6666666666666667, 0.6830065359477124, 0.6491754122938531, None)\n",
            "weighted : (0.717948717948718, 0.6538461538461539, 0.6616307230999886, None)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.50      0.78      0.61         9\n",
            "           2       0.83      0.59      0.69        17\n",
            "\n",
            "    accuracy                           0.65        26\n",
            "   macro avg       0.67      0.68      0.65        26\n",
            "weighted avg       0.72      0.65      0.66        26\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAEvCAYAAABhSUTPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------------------------------------------------------------------\n",
            "---------------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsSSRw_P_m1I",
        "colab_type": "text"
      },
      "source": [
        "#### Comments on the diagrams\n",
        "- We see that kNN did manage to guess the whole class '1' and around half of the class '2', that's why it reaches a weighted average of 75%, better than the Dummy's results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFDUwXAoOmpD",
        "colab_type": "text"
      },
      "source": [
        "## Section D: Optimizing Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyJbkdYzeImt",
        "colab_type": "text"
      },
      "source": [
        "### Split to Training/Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F-PScZbY7ia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split our data\n",
        "train, test, train_labels, test_labels = train_test_split(np_samples, \n",
        "                                                          np_labels, \n",
        "                                                          test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW93Qn_MdKfa",
        "colab_type": "text"
      },
      "source": [
        "### Balance Dataset - Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHyJ-O2vdJG8",
        "colab_type": "code",
        "outputId": "72d4a9dc-691c-4917-fe96-3d6e3f227be9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "sampler = SMOTE()\n",
        "train, train_labels = sampler.fit_sample(np_samples, np_labels)\n",
        "\n",
        "train_set_length = len(train)\n",
        "# print length of train set to validate oversampling\n",
        "print(\"#samples in train set =\", train_set_length, '\\n')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#samples in train set = 168 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYNgFvG6cxCJ",
        "colab_type": "text"
      },
      "source": [
        "### Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYuRVpvYWjHB",
        "colab_type": "text"
      },
      "source": [
        "#### Selection - Variance Threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5PpUxhbcKng",
        "colab_type": "code",
        "outputId": "77a8d703-eb46-44d5-f862-403030e41010",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "selector = VarianceThreshold(threshold=0.5)\n",
        "# όπως κάναμε και με τους ταξινομητές τον κάνουμε fit στα δεδομένα εκπαίδευσης\n",
        "train_reduced = selector.fit_transform(train)\n",
        "mask = selector.get_support()\n",
        "test_reduced = test[:,mask]\n",
        "\n",
        "selector = None\n",
        "selector = VarianceThreshold(threshold=15000)\n",
        "# όπως κάναμε και με τους ταξινομητές τον κάνουμε fit στα δεδομένα εκπαίδευσης\n",
        "train_reduced_20k = selector.fit_transform(train)\n",
        "mask = selector.get_support()\n",
        "test_reduced_20k = test[:,mask]\n",
        "\n",
        "print(\"0.5\", train_reduced.shape)\n",
        "print(\"0.5\", test_reduced.shape)\n",
        "print(\"20000\", train_reduced_20k.shape)\n",
        "print(\"20000\", test_reduced_20k.shape)\n",
        "print(train_labels.shape)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5 (168, 180)\n",
            "0.5 (26, 180)\n",
            "20000 (168, 93)\n",
            "20000 (26, 93)\n",
            "(168,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnH4aeVDWqj4",
        "colab_type": "text"
      },
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCPB0JzwXBSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "# όριζουμε ένα αντικείμενο scaler και το κάνουμε fit στο train set\n",
        "scaler = preprocessing.StandardScaler().fit(train)\n",
        "# standardization των features του training set\n",
        "train_scaled = scaler.transform(train)\n",
        "# εφαρμόζουμε τον scaler στα δεδομένα test\n",
        "test_scaled = scaler.transform(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1GK08jOdZH_",
        "colab_type": "text"
      },
      "source": [
        "### Hyperparameter Optimization\n",
        "Custom GridsearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVdqIZ3cqIWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_tuples(arr):\n",
        "    results = list()\n",
        "    for i in range(0, len(arr), 2):\n",
        "        results.append((arr[i], arr[i+1]))\n",
        "    return results\n",
        "\n",
        "def _gridsearch(test_set, test_set_labels, train_set, train_set_labels, KMAX, label_names):\n",
        "    # test every value for k\n",
        "    # append the result to a list\n",
        "    # sort the list\n",
        "    # return the list and keep the best\n",
        "    gridsearch_results = list()\n",
        "\n",
        "    for i in range(1, KMAX):\n",
        "        method = \"KNeighborsClassifier\"\n",
        "        knn = KNeighborsClassifier(n_neighbors=i)\n",
        "        knn.fit(train_set, train_set_labels)\n",
        "        pred = knn.predict(test_set)\n",
        "        accuracy = accuracy_score(test_set_labels, pred)\n",
        "\n",
        "        gridsearch_results.extend( (accuracy, i) )\n",
        "\n",
        "    return gridsearch_results\n",
        "\n",
        "def get_next_fold(_splitted_train, _train_labels, iter):\n",
        "    counter = 0\n",
        "    total_size = 0\n",
        "    first_time = True\n",
        "    for ( _data , _labels ) in zip(_splitted_train, _train_labels):\n",
        "        if ( counter == iter ): # if current fold is test fold\n",
        "            __test = _data\n",
        "            __test_labels = _labels\n",
        "        elif ( first_time ): # initialize train and train_labels\n",
        "            __train = _data\n",
        "            __train_labels = _labels\n",
        "            first_time = False\n",
        "        else: # everything else is the train fold\n",
        "            __train = np.concatenate((__train, _data), axis=0)\n",
        "            __train_labels = np.concatenate((__train_labels, _labels), axis=0)\n",
        "        counter += 1\n",
        "    return( __test, __test_labels, __train, __train_labels )\n",
        "\n",
        "\n",
        "def _Kfold_cv(_train, _train_labels, _label_names, _folds=10):\n",
        "    # split the train set and labels in 10 parts \n",
        "    split_train = np.array_split(_train, _folds)\n",
        "    split_labels = np.array_split(_train_labels, _folds)\n",
        "\n",
        "    # for i in range(_folds):\n",
        "    #     print (len(split_train[i]), \",\", len(split_labels[i]))\n",
        "    knn_results = list()\n",
        "    # print(KMAX)\n",
        "\n",
        "    for iter in range(_folds):\n",
        "        KMAX = len(split_train[iter]) # because there is no reason to search for more neighbors if they do no exist\n",
        "\n",
        "        # do every possible fold out of 10\n",
        "        (test_set, test_set_labels, train_set, train_set_labels) = get_next_fold(split_train, split_labels, iter)\n",
        "    \n",
        "        # and test every k for kNN and save results\n",
        "        fold_results = _gridsearch(test_set, test_set_labels, train_set, train_set_labels, KMAX, _label_names)\n",
        "        knn_results.extend((fold_results))\n",
        "\n",
        "    return knn_results\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm_DxswmdfZc",
        "colab_type": "text"
      },
      "source": [
        "### Final Classification - Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqcxpomBY9S8",
        "colab_type": "code",
        "outputId": "b405cfb4-18f1-4a1f-ed3d-ad8a82d970c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "\n",
        "# print(test_labels)\n",
        "# print(len(train), len(train_labels), len(label_names))\n",
        "\n",
        "# classic dataset\n",
        "results = _Kfold_cv(train, train_labels, label_names)\n",
        "results = make_tuples(results)\n",
        "results = sorted(results, key=lambda x:x[0], reverse=True)\n",
        "\n",
        "#reduced with variance threshold = 0.5 \n",
        "results_reduced = _Kfold_cv(train_reduced, train_labels, label_names)\n",
        "results_reduced = make_tuples(results_reduced)\n",
        "results_reduced = sorted(results_reduced, key=lambda x:x[0], reverse=True)\n",
        "\n",
        "#reduced with variance threshold = 20000 \n",
        "results_reduced_20k = _Kfold_cv(train_reduced_20k, train_labels, label_names)\n",
        "results_reduced_20k = make_tuples(results_reduced_20k)\n",
        "results_reduced_20k = sorted(results_reduced_20k, key=lambda x:x[0], reverse=True)\n",
        "\n",
        "best_k = results[0][1]\n",
        "best_k_reduced = results_reduced[0][1]\n",
        "best_k_reduced_20k = results_reduced_20k[0][1]\n",
        "print(\"Initial trainset, bestK = \", best_k)\n",
        "print(\"Variance = 0.5 trainset, bestK = \", best_k_reduced)\n",
        "print(\"Variance = 20000  trainset, bestK = \", best_k_reduced_20k)\n",
        "\n",
        "#reduced with variance threshold = 20000 \n",
        "results_scaled = _Kfold_cv(train_scaled, train_labels, label_names)\n",
        "results_scaled = make_tuples(results_scaled)\n",
        "results_scaled = sorted(results_scaled, key=lambda x:x[0], reverse=True)\n",
        "\n",
        "best_k_scaled = results_scaled[0][1]\n",
        "print(\"Scaling trainset, bestK = \", best_k_scaled)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial trainset, bestK =  2\n",
            "Variance = 0.5 trainset, bestK =  2\n",
            "Variance = 20000  trainset, bestK =  2\n",
            "Scaling trainset, bestK =  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRb4ZatPw--l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def knn_fit_predict_print(_classifier, _train, _train_labels, _test, _test_labels, _label_names):\n",
        "    _classifier.fit(_train, _train_labels)\n",
        "    pred = _classifier.predict(_test)\n",
        "    accuracy = accuracy_score(_test_labels, pred)\n",
        "    print(accuracy) \n",
        "    # print_precision_recall_fscore_support(\"kNearestNeighbors\", _test_labels, pred, _label_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHITnSyXS2Yo",
        "colab_type": "text"
      },
      "source": [
        "### Print results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsFKW_3sbMwI",
        "colab_type": "code",
        "outputId": "2a4ce1ad-04c5-4af2-a913-03999cfdf0bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "knn = None\n",
        "print(\"Initial Variance\")\n",
        "knn = KNeighborsClassifier(n_neighbors = best_k)\n",
        "print(\"accuracy = \", end=\" \")\n",
        "knn_fit_predict_print(knn, train, train_labels, test, test_labels, label_names)\n",
        "\n",
        "print(\"\\nVariance Threshold = 0.5\")\n",
        "knn = None\n",
        "knn = KNeighborsClassifier(n_neighbors = best_k_reduced)\n",
        "print(\"accuracy = \", end=\" \")\n",
        "knn_fit_predict_print(knn, train_reduced, train_labels, test_reduced, test_labels, label_names)\n",
        "\n",
        "print(\"\\nVariance Threshold = 20000\")\n",
        "knn = None\n",
        "knn = KNeighborsClassifier(n_neighbors = best_k_reduced_20k)\n",
        "print(\"accuracy = \", end=\" \")\n",
        "knn_fit_predict_print(knn, train_reduced_20k, train_labels, test_reduced_20k, test_labels, label_names)\n",
        "\n",
        "print(\"\\nScaled Trainset\")\n",
        "knn = None\n",
        "knn = KNeighborsClassifier(n_neighbors = best_k_scaled)\n",
        "print(\"accuracy = \", end=\" \")\n",
        "knn_fit_predict_print(knn, train_scaled, train_labels, test_scaled, test_labels, label_names)\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Variance\n",
            "accuracy =  0.6538461538461539\n",
            "\n",
            "Variance Threshold = 0.5\n",
            "accuracy =  0.6538461538461539\n",
            "\n",
            "Variance Threshold = 20000\n",
            "accuracy =  0.6538461538461539\n",
            "\n",
            "Scaled Trainset\n",
            "accuracy =  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-cTcuEQLo-m",
        "colab_type": "text"
      },
      "source": [
        "#### Comments on Pre-Processing results\n",
        "\n",
        "- Variance Threshold\n",
        "    - We see that there is no effect on the results of the kNN algorithm if we use pre-processing selection with VarianceThreshold Selector.\n",
        "    - You can see in the above cell that we tried with different values in the range (0.1 , 20000) and the results didn't change. \n",
        "    - Our data even though it had a small ratio of $\\frac{samples}{features}$, Variance Threshold didn't achieve anything. We conclude from this, that there were specific features that helped the estimator reach a conclusion fast, without needing the other features. \n",
        "- Standardization\n",
        "    - It seems that scaling the data is crucial for the classification since we have 100% accuracy on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZsOH-ub-xpU",
        "colab_type": "text"
      },
      "source": [
        "### Conclusion\n",
        "\n",
        "Since **we achieved 100% accuracy** on the test set, there is no need to perform any more transformations on the train and test set."
      ]
    }
  ]
}