# -*- coding: utf-8 -*-
"""MB24-B04.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RRNEDtM0wT50p6Yy7EqzYstkgNmsFVEU

# Neural Networks & Intelligent Computer Systems | 1st Assignment
Team ΜΒ-24 | Big Dataset B04

# Section A: Our Team

<table align="left">
    <tr align="left"><th>Surname</th><th>Name</th><th>Student ID</th></tr>
    <tr><td>Korkovili</td><td>Ioanna</td><td>03115078</td></tr>
    <tr><td>Xanthi</td><td>Eleni</td><td>03115054</td></tr>
    <tr><td>Tsagkarakis</td><td>Stylianos</td><td>03115180</td></tr>
</table>

# Section B: Introduction to the dataset

**Spambase Data Set**

The dataset describes the analysis of spam and non-spam emails collected. The collection of spam e-mails came from a postmaster and individuals who had filed spam. The collection of non-spam e-mails came from filed work and personal e-mails. This data is useful when constructing a personalized spam filter.

The dataset includes 4601 samples and 57 features indicating whether a particular word or character was frequently occuring in the e-mail. 3 of these features measure the length of sequences of consecutive capital letters. The last column denotes whether the e-mail was considered spam (1) or not (0), the labels of our dataset.

### Upgrade hosted runtime
"""

!pip install --upgrade pip           #upgrade pip package installer
!pip install --upgrade scikit-learn  #upgrade scikit-learn package
!pip install --upgrade numpy         #upgrade numpy package
!pip install --upgrade pandas        #upgrade #upgrade pandas package
!pip install --upgrade joblib
!pip install --upgrade imbalanced-learn

"""### Retrieve dataset"""

import pandas as pd
import numpy as np
import ast
import io
import requests
import matplotlib.pyplot as plt
from urllib.error import HTTPError

# datafile = "spambase.data"

try:
    #data without headers for better manipulation
    spambase_data_url = "https://raw.githubusercontent.com/steliostss/neural_networks_ntua/master/ex1/spambase.data?token=AH57CIML4NIAJZOJQUFI4UC576BI6&fbclid=IwAR11mbVCzpQQNxrDLhIvej6j7hfB43R4hoczCCOQ97eme5kfIaBlUMY73wY"
    data = pd.read_csv(spambase_data_url, header=None)

    #data with headers for better visualizing
    #data_headers = pd.read_csv(data_csv_url)

    print("Succesful file processing!")

except HTTPError:
    print("URL not working.")

"""### Printing for validation / visualization"""

#print for better visualization
data.head(6)

"""### Custom functions"""

## GATHER ALL FUNCTIONS FOR SECTION-B HERE

# evaluate type of value in the given variable
def tryeval(np_samples):
    for row in range(len(np_samples)): 
        for col in range(len(np_samples[row])):
            try: 
                np_samples[row][col] = ast.literal_eval(np_samples[row][col])
            except ValueError:
                pass
    return np_samples

# define if all features have the same type
def features_datatypes(features):
    datatypes = list()
    for row in range(len(features)):
        for col in range(len(np_samples[row])):
            current_type = type(features[row][col])
            if current_type not in datatypes:
                datatypes.append(current_type)
    return datatypes

# define all class labels
def class_labels(labels):
    cLabels = [] # all the labels gathered
    for col in range(len(labels)):
        current_val = labels[col]
        if current_val not in cLabels:
            cLabels.append(current_val)
    return cLabels

"""### Manage datafile, get desired data

Get #features, #samples, type of features
"""

# gather data features in a table
data_features = data.iloc[[0],:-1]
( _ , number_of_features ) = data_features.shape
print("Q2: Number of features = ", number_of_features)
# print(data_features.shape) # uncomment if you want to check the results

# gather data samples in a table
data_samples = data.iloc[0:,:-1]
( number_of_samples , _ ) = data_samples.shape
print("Q2: Number of samples = ", number_of_samples)
# print(data_samples.shape) # uncomment if you want to check the results

# transform the gathered data in numpy arrays
np_features = data_features.values
np_samples = data_samples.values

# convert the type of samples to the correct type
np_samples = tryeval(np_samples)
datatypes = features_datatypes(np_samples)


print("Q2: Type of features =", end=' ')
print(*datatypes, sep = " & ")

"""- Q3: There are no headers in the first line

- Q3: There is no line numbering
"""

# gather class labels in a table

binary_class_labels = data.iloc[:, 57] 
np_labels = binary_class_labels.values.flatten()

np_labels

"""### Classification Labels"""

# make a list with all different labels
list_of_labels = class_labels(np_labels)
print("Q4: Classification Labels =", end=' ')
print(*list_of_labels, sep = " & ")

label_names = list()
for i in range(len(list_of_labels)):
    label_names.append(str(list_of_labels[i]))
# label_names = ('0','1')
label_names

"""- Q5: There was no modification on the data.

### Check Empty dataset
"""

# check if dataset has empty values
# and if, how many of them

!echo "For spambase.data file, empty values: "
!cat spambase.data | grep "?" | wc -l

"""### Label frequencies"""

print("frequencies:", np.bincount(np_labels))
freq = np.bincount(np_labels)
for i in range(len(freq)):
    print("For label:", i, "percentage is", "{:.2%}".format(freq[i]/number_of_samples))

"""Our dataset is not balanced which is visible in the frequences above.
We will use the oversampling process in order to ensure we do not miss any information.

### Split to test and train set
"""

from sklearn.linear_model import LogisticRegression 
from sklearn.preprocessing import StandardScaler 
from sklearn.metrics import confusion_matrix, classification_report 
from imblearn.over_sampling import RandomOverSampler
from imblearn.over_sampling import SMOTE

from sklearn.model_selection import train_test_split

# Split our data
train, test, train_labels, test_labels = train_test_split(np_samples, 
                                                          np_labels, 
                                                          test_size=0.3)

"""# Section C: Baseline Classification

### Custom Functions
"""

from sklearn.dummy import DummyClassifier
from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics import classification_report
from matplotlib import pyplot as plt
import time

def print_precision_recall_fscore_support(method, test_labels, pred, label_names):
    print(method, end = '\n\n')
    (none, micro, macro, weighted) = get_PRFS(method, test_labels, pred, label_names)
    print("none     :", none )
    print("micro    :", micro )
    print("macro    :", macro )
    print("weighted :", weighted, end = '\n\n')
    print(classification_report(test_labels, pred, target_names=label_names), end = '\n\n')

    ( _ , _ , microF1    , _ ) = micro
    ( _ , _ , macroF1    , _ ) = macro
    ( _ , _ , weightedF1 , _ ) = weighted

    barplotF1 = (microF1, macroF1, weightedF1)
    xaxis = ("microF1", "macroF1", "weightedF1")
    plt.figure(figsize=(10,5))
    plt.bar(xaxis, barplotF1)
    plt.show()
    print("---------------------------------------------------------------------------------------------------------------------", end = '\n')
    print("---------------------------------------------------------------------------------------------------------------------", end = '\n\n')

# get_precision_recall_fscore_support
def get_PRFS(method, test_labels, pred, label_names):
    none = precision_recall_fscore_support(test_labels, pred, average=None)
    micro = precision_recall_fscore_support(test_labels, pred, average='micro')
    macro = precision_recall_fscore_support(test_labels, pred, average='macro')
    weighted = precision_recall_fscore_support(test_labels, pred, average='weighted')
    return (none, micro, macro, weighted)

# We will use the below dictionaries to compare the results of each classifier
f1_macro_default={}
f1_macro_optimized={}

f1_micro_default={}
f1_micro_optimized={}

train_time_default={}
train_time_optimized={}

predict_time_default={}
predict_time_optimized={}

"""### Dummy Classifier"""

from sklearn.dummy import DummyClassifier
dc_uniform = DummyClassifier(strategy="uniform")
dc_constant_0 = DummyClassifier(strategy="constant", constant=0)
dc_constant_1 = DummyClassifier(strategy="constant", constant=1)
dc_most_frequent = DummyClassifier(strategy="most_frequent")
dc_stratified = DummyClassifier(strategy="stratified")

# με τη μέθοδο fit "εκπαιδεύουμε" τον ταξινομητή στο σύνολο εκπαίδευσης (τα χαρακτηριστικά και τις ετικέτες τους)
from sklearn.metrics import accuracy_score

# με τη μέθοδο predict παράγουμε προβλέψεις για τα δεδομένα ελέγχου (είσοδος τα χαρακτηριστικά μόνο)
predictions = {}
spambase_accuracy = {}

model = dc_uniform.fit(train, train_labels)
preds = dc_uniform.predict(test)
predictions['dc_uniform'] = preds
spambase_accuracy['uniform (random)'] = accuracy_score(test_labels, preds)


model = dc_constant_0.fit(train, train_labels)
preds = dc_constant_0.predict(test)
predictions['dc_constant_0'] = preds
spambase_accuracy['constant 0'] = accuracy_score(test_labels, preds)

model = dc_constant_1.fit(train, train_labels)
preds = dc_constant_1.predict(test)
predictions['dc_constant_1'] = preds
spambase_accuracy['constant 1'] = accuracy_score(test_labels, preds)

model = dc_most_frequent.fit(train, train_labels)
preds = dc_most_frequent.predict(test)
predictions['dc_most_frequent'] = preds
spambase_accuracy['most frequent label'] = accuracy_score(test_labels, preds)

start_time = time.time()
model = dc_stratified.fit(train, train_labels)
train_time = (time.time() - start_time)

train_time_default['Dummy'] = train_time
train_time_optimized['Dummy'] = train_time

start_time = time.time()
preds = dc_stratified.predict(test)
predictions['dc_stratified'] = preds
spambase_accuracy['stratified'] = accuracy_score(test_labels, preds)
pred_time = (time.time() - start_time)

predict_time_default['Dummy'] = train_time
predict_time_optimized['Dummy'] = train_time

for i in predictions:
    print("Prediction for", i, '=', predictions[i])

print()
    
print("Classification Accuracy on the Spambase Dataset (30% test set)\n")
sorted_accuracy = [(k, spambase_accuracy[k]) for k in sorted(spambase_accuracy, key=spambase_accuracy.get, reverse=True)]

print("----------Results are sorted----------\n")

for k,v in sorted_accuracy:
    print(k,v)

from sklearn.metrics import confusion_matrix
# Compute confusion matrix

print("Confusion matrices\n")
for i in predictions:
    # print confusion matrix
    cnf_matrix = confusion_matrix(test_labels, predictions[i])
    print(i)
    print(cnf_matrix, end='\n\n')

for i in predictions:
    print_precision_recall_fscore_support(i, test_labels, predictions[i], label_names)

print(train_time_default)
print(predict_time_default)

#There is no point of optimizing the dummy classifier, so we will take as optimized the default value again
report_dict = classification_report(test_labels, preds, output_dict = True)
f1_macro_default['Dummy'] = report_dict['macro avg']['f1-score']
f1_macro_optimized['Dummy'] = report_dict['macro avg']['f1-score']

f1_micro_default['Dummy'] = report_dict['accuracy']
f1_micro_optimized['Dummy'] = report_dict['accuracy']

print(f1_macro_default)
print(f1_micro_default)

"""### Gaussian Naive Bayes Classifier"""

from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()

# κάνουμε εκπαίδευση (fit) δηλαδή ουσιαστικά υπολογίζουμε μέση τιμή και διακύμανση για όλα τα χαρακτηριστικά και κλάσεις στο training set
start_time = time.time()
model = gnb.fit(train, train_labels)
train_time = (time.time() - start_time)

train_time_default['GaussianNB'] = train_time

start_time = time.time()
preds = gnb.predict(test)
train_time = (time.time() - start_time)

predict_time_default['GaussianNB'] = train_time

# η GaussianNB έχει builtin μέθοδο υπολογισμό accuracy. Αποθηκεύουμε την τιμή της στον πίνακά μας με τα αποτελέσματα από τα άλλα classifiers
spambase_accuracy['gaussian naive bayes'] = gnb.score(test, test_labels)

# και ξανατυπώνουμε τα sorted αποτελέσματα
print("Classification Accuracy on the Spambase Dataset (30% test set)\n")

sorted_accuracy = [(k, spambase_accuracy[k]) for k in sorted(spambase_accuracy, key=spambase_accuracy.get, reverse=True)]
for k, v in sorted_accuracy:
    print(k,v)

# Compute confusion matrix
pred = gnb.predict(test)
print("Confusion matrix\n")
cnf_matrix = confusion_matrix(test_labels, pred)
print("Gaussian Naive Bayes")
print(cnf_matrix, end='\n\n')

print_precision_recall_fscore_support("GaussianNB", test_labels, pred, label_names)

print(train_time_default)
print(predict_time_default)

report_dict = classification_report(test_labels, preds, output_dict = True)
f1_macro_default['GaussianNB'] = report_dict['macro avg']['f1-score']
f1_micro_default['GaussianNB'] = report_dict['accuracy']

print(f1_macro_default)
print(f1_micro_default)

"""Here we can see that we have much greater results than the Dummy Classifier, reaching a quite good f1-score.
Moreover, as expected, it is visible that the f1-macro and f1-micro scores are quite similar, beacause our classes are more or less equally distributed.

Let's see if we can achieve better results with the kNN Classifier.

### k Nearest Neighbors Classifier (kNN)
"""

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier()

start_time = time.time()
knn.fit(train, train_labels)
total_time = (time.time() - start_time)

train_time_default['kNN'] = total_time
print("Fit done in:",total_time,"seconds")

start_time = time.time()
pred = knn.predict(test)
total_time = (time.time() - start_time)

predict_time_default['kNN'] = total_time

cnf_matrix = confusion_matrix(test_labels, pred)

print(cnf_matrix)

print_precision_recall_fscore_support("KNeighborsClassifier", test_labels, pred, label_names)

print(train_time_default)
print(predict_time_default)

report_dict = classification_report(test_labels, preds, output_dict = True)
f1_macro_default['kNN'] = report_dict['macro avg']['f1-score']
f1_micro_default['kNN'] = report_dict['accuracy']

print(f1_macro_default)
print(f1_micro_default)

"""kNN does not give us better results than the Gaussian NB in this dataset.

### Multi-Layer Perceptron (MLP) Classifier
"""

from sklearn.neural_network import MLPClassifier

clf = MLPClassifier(solver='lbfgs', alpha=1e-5,
                    hidden_layer_sizes=(5,), random_state=1)

start_time = time.time()
clf.fit(train, train_labels)
total_time = (time.time() - start_time)

train_time_default['MLPClassifier'] = total_time
print("Fit done in:",total_time,"seconds")

start_time = time.time()
preds = clf.predict(test)
total_time = (time.time() - start_time)

predict_time_default['MLPClassifier'] = total_time

# Compute confusion matrix
pred = clf.predict(test)
print("Confusion matrix\n")
cnf_matrix = confusion_matrix(test_labels, pred)
print("MLP Classifier")
print(cnf_matrix, end='\n\n')

print_precision_recall_fscore_support("MLPClassifier", test_labels, pred, label_names)

print(train_time_default)
print(predict_time_default)

report_dict = classification_report(test_labels, preds, output_dict = True)
f1_macro_default['MLPClassifier'] = report_dict['macro avg']['f1-score']
f1_micro_default['MLPClassifier'] = report_dict['accuracy']

print(f1_macro_default)
print(f1_micro_default)

"""The MLP Classifier produces even worse score than the others. This is because no data preprocessing has been conducted and the hyperparameters are not optimized (MLP has a great amount of hyperparameters).

# Section D: Optimizing Classifiers

### Balance Dataset - Oversampling
"""

sampler = SMOTE()
train, train_labels = sampler.fit_sample(np_samples, np_labels)

# print length of train set to validate oversampling
print("Length of train_set is =", len(train), '\n')

"""**Q8**: Our samples are **ordered tuples** since each number corresponds to a specific attribute.

### Variance Threshold

We check the variance of each feature in our train dataset in order to understand what values to try as threshold.

#### Pre-Processing
"""

train_Var = np.var(train, axis=0)
print(train_Var)

from sklearn.feature_selection import VarianceThreshold

# initialize the selector
selector = VarianceThreshold(0)
# fit the selector in the data
train_reduced = selector.fit_transform(train)
print(train.shape)
print(train_reduced.shape)

selector = VarianceThreshold(0.05)

train_reduced = selector.fit_transform(train)
print(train_reduced)

mask = selector.get_support()
print(mask)

print(train.shape)
print(train_reduced.shape)

selector = VarianceThreshold(0.2)

train_reduced = selector.fit_transform(train)
print(train.shape)
print(train_reduced.shape)

"""It's clear that we should definetly choose a value below 0.05 because the features are reduced a lot and we will probably have a significant loss of information.

### Dummy Classifier
"""

dc_stratified = DummyClassifier(strategy="stratified")

start_time = time.time()
model = dc_stratified.fit(train, train_labels)
train_time = (time.time() - start_time)

train_time_default['Dummy'] = train_time
train_time_optimized['Dummy'] = train_time

start_time = time.time()
preds = dc_stratified.predict(test)
pred_time = (time.time() - start_time)

predict_time_default['Dummy'] = train_time
predict_time_optimized['Dummy'] = train_time


print (classification_report(test_labels, preds))

print(train_time_default)
print(predict_time_default)

"""We can see, that with the DummyClassifier, we can't achieve good results. So, we will move on and try the Naive Bayes Classifier.

### Optimized Gaussian Naive Bayes Classifier

#### Data Processing
"""

from imblearn.pipeline import Pipeline

# import the known classes for preprocessing
from sklearn.feature_selection import VarianceThreshold
from sklearn.decomposition import PCA
from sklearn.model_selection import GridSearchCV

# initialize the estimators (transformers and classifier) without parameters
selector = VarianceThreshold()
clf = GaussianNB()

vthreshold = [0, 0.01, 0.02, 0.03, 0.04, 0.05] #according to the calculations we did in the beginning of this section

pipe = Pipeline(steps=[('selector', selector), ('gaussiannb', clf)], memory = 'tmp')

# We will use 5 fold validation
estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold), cv=5, scoring='f1_micro', n_jobs=-1)

start_time = time.time()
estimator.fit(train, train_labels)
total_time = (time.time() - start_time)/60
print("Fit done in:",total_time,"minutes")

preds = estimator.predict(test)
print (classification_report(test_labels, preds))

print (estimator.best_estimator_)
print (estimator.best_params_)
print()
print(train.shape)
print(train_reduced.shape)

"""We see that we get the best results for the Variance Threshold 0.04. We do not have many features compared to the number of samples, so we will stop here.

We will try to optimize it with PCA, too.
"""

# initialize the estimators (transformers and classifier) without parameters
selector =VarianceThreshold()
pca = PCA()
clf = GaussianNB()

vthreshold = [0.04]
n_components = [31,32,33,34,35,36,37]

pipe = Pipeline(steps=[('selector', selector),('pca',pca), ('gaussiannb', clf)], memory = 'tmp')

# We will use 5 fold validation
estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, pca__n_components=n_components), cv=5, scoring='f1_micro', n_jobs=-1)

start_time = time.time()
estimator.fit(train, train_labels)
total_time = (time.time() - start_time)/60

train_time_optimized['GaussianNB'] = total_time
print("Fit done in:",total_time,"seconds")

start_time = time.time()
preds = estimator.predict(test)
total_time = (time.time() - start_time)

predict_time_optimized['GaussianNB'] = total_time

print (classification_report(test_labels, preds))

print (estimator.best_estimator_)
print (estimator.best_params_)

"""We have less dimensions here and we get higher results when we try to optimize with PCA. Therefore, **our best score here is by using as Variance Threshold 0.04 and PCA**.

It is also important to note that the PCA values used here, were chosen after experiments in greater values. For example, we tried to keep 50 dimensions but the best results using PCA was around 32 dimensions.
"""

report_dict = classification_report(test_labels, preds, output_dict = True)
f1_macro_optimized['GaussianNB'] = report_dict['macro avg']['f1-score']
f1_micro_optimized['GaussianNB'] = report_dict['accuracy']

print(f1_macro_default)
print(f1_macro_optimized)
print(f1_micro_default)
print(f1_micro_optimized)

print(train_time_default)
print(predict_time_default)
print(train_time_optimized)
print(predict_time_optimized)

"""### Optimized kNN Classifier

We will first try only with the Variance Threshold.
We will use n_jobs=-1 so that all the cores of our machine will be used and verbose=10, for checking how the training is progressing.
"""

from imblearn.pipeline import Pipeline

# φέρνουμε τις γνωστές μας κλάσεις για preprocessing
from sklearn.feature_selection import VarianceThreshold
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# αρχικοποιούμε τους εκτιμητές (μετασχηματιστές και ταξινομητή) χωρείς παραμέτρους
selector = VarianceThreshold()
# scaler = StandardScaler()
# pca = PCA()
clf = KNeighborsClassifier(n_jobs=-1) # η παράμετρος n_jobs = 1 χρησιμοποιεί όλους τους πυρήνες του υπολογιστή

vthreshold = [0.05, 0.06, 0.07, 0.08, 0.09, 0.1]
k = [1, 2, 3, 5, 10, 15]

weights_options = ['uniform', 'distance']
metric_options = ['euclidean', 'manhattan', 'chebyshev', 'minkowski', 'hamming'] #default minkowski

pipe = Pipeline(steps=[('selector', selector), ('kNN', clf)], memory = 'tmp')

# We will use 5 fold validation
estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, kNN__n_neighbors=k, kNN__weights=weights_options, kNN__metric=metric_options), cv=5, scoring='f1_micro', n_jobs=-1, verbose=10)

start_time = time.time()
estimator.fit(train, train_labels)
total_time = (time.time() - start_time)
print("Fit done in:",total_time/60,"minutes")
preds = estimator.predict(test)
print (classification_report(test_labels, preds))

print(estimator.best_estimator_)
print(estimator.best_params_)

# We check if PCA would improve our score

selector =VarianceThreshold()
pca = PCA()
clf = KNeighborsClassifier(n_jobs=-1)

vthreshold = [0.05]
n_components = [30, 32, 38, 40, 42, 44, 45]
k = [1,2,3,4,5]

weights_options = ['distance']
metric_options = ['manhattan'] #default minkowski

pipe = Pipeline(steps=[('selector', selector),('pca',pca), ('kNN', clf)], memory = 'tmp')

# We will use 5 fold validation
estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, kNN__n_neighbors=k, pca__n_components=n_components, kNN__weights=weights_options, kNN__metric=metric_options), cv=5, scoring='f1_micro', n_jobs=-1, verbose=10)

start_time = time.time()
estimator.fit(train, train_labels)
total_time = time.time() - start_time
print("Fit done in:",total_time/60,"minutes")
preds = estimator.predict(test)
print (classification_report(test_labels, preds))

print (estimator.best_estimator_)
print (estimator.best_params_)

# We try also with the StandardScaler

selector = VarianceThreshold()
scaler = StandardScaler()
#pca = PCA()
clf = KNeighborsClassifier(n_jobs=-1) # η παράμετρος n_jobs = 1 χρησιμοποιεί όλους τους πυρήνες του υπολογιστή

vthreshold = [0.05, 0.06, 0.07, 0.08, 0.09, 0.1]
k = [1, 2, 3, 5, 10, 15]

weights_options = ['uniform', 'distance']
metric_options = ['euclidean', 'manhattan', 'chebyshev', 'minkowski', 'hamming'] #default minkowski

pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('kNN', clf)], memory = 'tmp')

# We will use 5 fold validation
estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, kNN__n_neighbors=k, kNN__weights=weights_options, kNN__metric=metric_options), cv=5, scoring='f1_micro', n_jobs=-1)

start_time = time.time()
estimator.fit(train, train_labels)
total_time = time.time() - start_time

train_time_optimized['kNN'] = total_time

print("Fit done in:",(time.time() - start_time)/60,"minutes")

start_time = time.time()
preds = estimator.predict(test)
total_time = (time.time() - start_time)

predict_time_optimized['kNN'] = total_time

print (classification_report(test_labels, preds))

print (estimator.best_estimator_)
print (estimator.best_params_)

report_dict = classification_report(test_labels, preds, output_dict = True)
f1_macro_optimized['kNN'] = report_dict['macro avg']['f1-score']
f1_micro_optimized['kNN'] = report_dict['accuracy']

print(f1_macro_default)
print(f1_macro_optimized)
print(f1_micro_default)
print(f1_micro_optimized)

print(train_time_default)
print(predict_time_default)
print(train_time_optimized)
print(predict_time_optimized)

"""### Optimized MLP Classifier

At first we will not use the Variance Threshold.
"""

## Parameters to optimize
parameter_space = {
    #'hidden_layer_sizes': [(5,) , (15,) , (20,) , (50,) , (100,)], # tuple default (100,).The ith element represents the number of neurons in the ith hidden layer.
    'activation': ['identity', 'logistic', 'tanh', 'relu'], # default ‘relu’
    'solver': ['lbfgs','sgd','adam'], # default ‘adam’
    #'learning_rate': ['constant','invscaling','adaptive'] # Only used when solver='sgd'.
    #'max_iter': [100,150,200,250],
    #'alpha': [0.0001, 0.002, 0.05] 
}

"""We will first try to see whch solver with which activation gives us the best result."""

from sklearn.model_selection import GridSearchCV
from sklearn.neural_network import MLPClassifier

mlp = MLPClassifier()
clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=5, scoring='f1_micro', verbose=10)

start_time = time.time()
clf.fit(train, train_labels)
print("Fit done in:",(time.time() - start_time)/60,"minutes")
preds = clf.predict(test)
print (classification_report(test_labels, preds))

print (clf.best_params_)

"""Since that didn 't take much time, we will check again if we can get any better results by using the Variance Threshold."""

selector =VarianceThreshold()
clf = MLPClassifier()

param_grid = {
    'selector__threshold': [0,0.001, 0.002, 0.003, 0.004],
    'mlpclassifier__activation': ['tanh'],
    'mlpclassifier__solver': ['adam']
}

pipe = Pipeline(steps=[('selector', selector), ('mlpclassifier', clf)], memory = 'tmp')

# We will use 5 fold validation
estimator = GridSearchCV(pipe, param_grid=param_grid, cv=5, scoring='f1_micro', n_jobs=-1, verbose=10)

start_time = time.time()
estimator.fit(train, train_labels)
total_time = (time.time() - start_time)

train_time_optimized['MLPClassifier'] = total_time
print("Fit done in:",(time.time() - start_time)/60,"minutes")

start_time = time.time()
preds = estimator.predict(test)
total_time = (time.time() - start_time)

predict_time_optimized['MLPClassifier'] = total_time

print (classification_report(test_labels, preds))

print (estimator.best_estimator_)
print (estimator.best_params_)

"""Having run multiple versions of the hyperparameters, clearly the solver that gives the best results in our case is *Adam* with threshold 0.002."""

report_dict = classification_report(test_labels, preds, output_dict = True)
f1_macro_optimized['MLPClassifier'] = report_dict['macro avg']['f1-score']
f1_micro_optimized['MLPClassifier'] = report_dict['accuracy']

print(f1_macro_default)
print(f1_macro_optimized)
print(f1_micro_default)
print(f1_micro_optimized)

print(train_time_default)
print(predict_time_default)
print(train_time_optimized)
print(predict_time_optimized)

"""### Final Results & Comparisons

Since, we have run and taken all the metrics we need from multiple Classifiers, we can now plot them and compare them.
"""

times = [train_time_default, train_time_optimized]
print("Train time in (s):")
pd.DataFrame(times, index=['default', 'optimized'])

times = [predict_time_default, predict_time_optimized]
print("Predict time in (s):")
pd.DataFrame(times, index=['default', 'optimized'])

import matplotlib.pyplot as plt

N = 4
time_default = list(train_time_default.values())

ind = np.arange(N)  # the x locations for the groups
width = 0.4       # the width of the bars

fig, ax = plt.subplots()
rects1 = ax.bar(ind, time_default, width, color='m')

time_optimized = time_optimized = list(train_time_optimized.values())

rects2 = ax.bar(ind + width, time_optimized, width, color='c')

# add some text for labels, title and axes ticks
ax.set_ylabel('Train time (s)')
ax.set_title('Train time default vs optimized (s)')
ax.set_xticks(ind + width / 2)
ax.set_xticklabels(list(train_time_default.keys()))

ax.legend((rects1[0], rects2[0]), ('default', 'optimized'))

# Turn on the grid
#ax.minorticks_on()
#ax.grid(which='major', linestyle='-', linewidth='0.5', color='red')
# Customize the minor grid
#ax.grid(which='minor', linestyle=':', linewidth='0.5', color='black')

def autolabel(rects):
    """
    Attach a text label above each bar displaying its height
    """
    for rect in rects:
        height = rect.get_height()
        ax.text(rect.get_x() + rect.get_width()/2., 1.01*height,
                "{:.4f}".format(height),
                ha='center', va='bottom')

autolabel(rects1)
autolabel(rects2)

plt.show()

f1_scores = [f1_micro_default, f1_micro_optimized]
print("F1 micro scores:")
pd.DataFrame(f1_scores, index=['default', 'optimized'])

N = 4
f1_default = list(f1_micro_default.values())

ind = np.arange(N)  # the x locations for the groups
width = 0.4       # the width of the bars

fig, ax = plt.subplots()
rects1 = ax.bar(ind, f1_default, width, color='g')

f1_optimized = time_optimized = list(f1_micro_optimized.values())

rects2 = ax.bar(ind + width, f1_optimized, width, color='b')

# add some text for labels, title and axes ticks
ax.set_ylabel('f1_micro score')
ax.set_title('F1 micro score default vs optimized')
ax.set_xticks(ind + width / 2)
ax.set_xticklabels(list(f1_micro_default.keys()))

ax.legend((rects1[0], rects2[0]), ('default', 'optimized'))

# Turn on the grid
#ax.minorticks_on()
#ax.grid(which='major', linestyle='-', linewidth='0.5', color='red')
# Customize the minor grid
#ax.grid(which='minor', linestyle=':', linewidth='0.5', color='black')

def autolabel(rects):
    """
    Attach a text label above each bar displaying its height
    """
    for rect in rects:
        height = rect.get_height()
        ax.text(rect.get_x() + rect.get_width()/2., 1.01*height,
                "{:.4f}".format(height),
                ha='center', va='bottom')

autolabel(rects1)
autolabel(rects2)

plt.show()

f1_scores = [f1_macro_default, f1_macro_optimized]
print("F1 macro scores:")
pd.DataFrame(f1_scores, index=['default', 'optimized'])

N = 4
f1_default = list(f1_macro_default.values())

ind = np.arange(N)  # the x locations for the groups
width = 0.4       # the width of the bars

fig, ax = plt.subplots()
rects1 = ax.bar(ind, f1_default, width, color='g')

f1_optimized = time_optimized = list(f1_macro_optimized.values())

rects2 = ax.bar(ind + width, f1_optimized, width, color='b')

# add some text for labels, title and axes ticks
ax.set_ylabel('f1_macro score')
ax.set_title('F1 macro score default vs optimized')
ax.set_xticks(ind + width / 2)
ax.set_xticklabels(list(f1_macro_default.keys()))

ax.legend((rects1[0], rects2[0]), ('default', 'optimized'))

# Turn on the grid
#ax.minorticks_on()
#ax.grid(which='major', linestyle='-', linewidth='0.5', color='red')
# Customize the minor grid
#ax.grid(which='minor', linestyle=':', linewidth='0.5', color='black')

def autolabel(rects):
    """
    Attach a text label above each bar displaying its height
    """
    for rect in rects:
        height = rect.get_height()
        ax.text(rect.get_x() + rect.get_width()/2., 1.01*height,
                "{:.4f}".format(height),
                ha='center', va='bottom')

autolabel(rects1)
autolabel(rects2)

plt.show()